{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWMFEF5bSAhs"
      },
      "source": [
        "## In this notebook, we assume users are using GPU-enabled environment <br>(T4 on Google Colab is enough)\n",
        "- consider run this file on Google Colab\n",
        "- requirements.txt was prepared for environment on Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Jb_G2UukSKzT",
        "outputId": "1c0b9506-1a63-4b69-c1bf-95a767244182"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX5WLtiXrWcQ"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cYfIdjwGIFR",
        "outputId": "633c995d-7624-4114-ddf9-3ab6485eed63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'FRATTVAE' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/slab-it/FRATTVAE.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S3RNXCGrE7a"
      },
      "source": [
        "## installing libraries with pip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Lgs4M92Bwxg"
      },
      "source": [
        "Be careful. Here, downgrading scipy causes restarting session on Google Colab due to Numpy's dependancy(Numpy 2.0 ->Numpy.1.11.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUGNQ_P_DvYP",
        "outputId": "e6f75d16-5159-4b38-bcfb-d48143713935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy==1.11.3 in /usr/local/lib/python3.11/dist-packages (1.11.3)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from scipy==1.11.3) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install scipy==1.11.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hosXGnybFKZ",
        "outputId": "9d44c179-f525-4072-fec5-c2afb4a4cfcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.11/dist-packages (2.2.0+cu118)\n",
            "Requirement already satisfied: torchvision==0.17.0 in /usr/local/lib/python3.11/dist-packages (0.17.0+cu118)\n",
            "Requirement already satisfied: torchaudio==2.2.0 in /usr/local/lib/python3.11/dist-packages (2.2.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (11.8.86)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (2.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17.0) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17.0) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17.0) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17.0) (2025.7.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk4GsiUPbI8B",
        "outputId": "f4026629-cb69-4ae0-ba99-5546282ad880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/torch-2.2/cu118/repo.html\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.11/dist-packages (2.4.0+cu118)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/dist-packages (from dgl) (3.5)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from dgl) (24.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from dgl) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (2.11.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from dgl) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (1.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from dgl) (4.67.1)\n",
            "Requirement already satisfied: torch<=2.4.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (2.2.0+cu118)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dgl) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dgl) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dgl) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dgl) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (11.8.86)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (2.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->dgl) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->dgl) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->dgl) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<=2.4.0->dgl) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<=2.4.0->dgl) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install  dgl -f https://data.dgl.ai/wheels/torch-2.2/cu118/repo.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tivsgBGgV1oD",
        "outputId": "180fcea4-8761-4f40-d37a-6d115c082d06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.11/dist-packages (2025.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.2.1)\n"
          ]
        }
      ],
      "source": [
        "# !pip install rdkit==2023.9.1\n",
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da6F0y4VWDMa",
        "outputId": "1aad7781-7149-4835-d5fb-aee9b70d19e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timeout-decorator in /usr/local/lib/python3.11/dist-packages (0.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install timeout-decorator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpoWVkl3WL8b",
        "outputId": "60680378-5607-41cb-da32-cf0747087b1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: molvs in /usr/local/lib/python3.11/dist-packages (0.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from molvs) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install molvs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsXsQ5NrW1FL",
        "outputId": "e0dbef0d-e012-49bc-a5d6-1c1874437965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fcd-torch in /usr/local/lib/python3.11/dist-packages (1.0.7)\n",
            "Requirement already satisfied: guacamol in /usr/local/lib/python3.11/dist-packages (0.5.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from fcd-torch) (2.2.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fcd-torch) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from fcd-torch) (1.11.3)\n",
            "Requirement already satisfied: joblib>=0.12.5 in /usr/local/lib/python3.11/dist-packages (from guacamol) (1.5.1)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.11/dist-packages (from guacamol) (4.67.1)\n",
            "Requirement already satisfied: FCD>=1.1 in /usr/local/lib/python3.11/dist-packages (from guacamol) (1.2.2)\n",
            "Requirement already satisfied: rdkit-pypi>=2021.9.2.1 in /usr/local/lib/python3.11/dist-packages (from guacamol) (2022.9.5)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.11/dist-packages (from FCD>=1.1->guacamol) (2025.9.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi>=2021.9.2.1->guacamol) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (11.8.86)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->fcd-torch) (2.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->fcd-torch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->fcd-torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install fcd-torch guacamol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiRGTH-cz4HA",
        "outputId": "3711845f-5962-41ce-be96-119e150bd145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: botorch in /usr/local/lib/python3.11/dist-packages (0.16.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from botorch) (4.14.1)\n",
            "Requirement already satisfied: pyre_extensions in /usr/local/lib/python3.11/dist-packages (from botorch) (0.0.32)\n",
            "Requirement already satisfied: gpytorch>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from botorch) (1.15.1)\n",
            "Requirement already satisfied: linear_operator>=0.6 in /usr/local/lib/python3.11/dist-packages (from botorch) (0.6)\n",
            "Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from botorch) (2.2.0+cu118)\n",
            "Requirement already satisfied: pyro-ppl>=1.8.4 in /usr/local/lib/python3.11/dist-packages (from botorch) (1.9.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from botorch) (1.11.3)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.11/dist-packages (from botorch) (1.0.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from botorch) (3.6.0)\n",
            "Requirement already satisfied: jaxtyping in /usr/local/lib/python3.11/dist-packages (from gpytorch>=1.14.2->botorch) (0.3.6)\n",
            "Requirement already satisfied: mpmath<=1.3,>=0.19 in /usr/local/lib/python3.11/dist-packages (from gpytorch>=1.14.2->botorch) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from gpytorch>=1.14.2->botorch) (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (3.4.0)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (0.1.2)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (11.8.86)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (2.2.0)\n",
            "Requirement already satisfied: typing-inspect in /usr/local/lib/python3.11/dist-packages (from pyre_extensions->botorch) (0.9.0)\n",
            "Requirement already satisfied: wadler-lindig>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from jaxtyping->gpytorch>=1.14.2->botorch) (0.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.1->botorch) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->gpytorch>=1.14.2->botorch) (1.5.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect->pyre_extensions->botorch) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install botorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oBRT2s8W_WK",
        "outputId": "498c650a-c499-49ce-8c1c-9abd50c80545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting molsets\n",
            "  Using cached molsets-0.3.1-py3-none-any.whl.metadata (581 bytes)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.11/dist-packages (from molsets) (4.67.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from molsets) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.11/dist-packages (from molsets) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.11/dist-packages (from molsets) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from molsets) (1.11.3)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from molsets) (2.2.0+cu118)\n",
            "Requirement already satisfied: fcd-torch>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from molsets) (1.0.7)\n",
            "Requirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from molsets) (0.13.2)\n",
            "Collecting pomegranate==0.12.0 (from molsets)\n",
            "  Using cached pomegranate-0.12.0.tar.gz (3.3 MB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install molsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oae_O8pKXfAD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDKBveU3pLnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352aaf79-f73e-429d-8ef6-9d36b54f3773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gpu4pyscf-cuda12x in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: pyscf>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from gpu4pyscf-cuda12x) (2.12.0)\n",
            "Requirement already satisfied: pyscf-dispersion in /usr/local/lib/python3.11/dist-packages (from gpu4pyscf-cuda12x) (1.3.0)\n",
            "Requirement already satisfied: cupy-cuda12x!=13.4.0,>=13.0 in /usr/local/lib/python3.11/dist-packages (from gpu4pyscf-cuda12x) (13.3.0)\n",
            "Requirement already satisfied: geometric in /usr/local/lib/python3.11/dist-packages (from gpu4pyscf-cuda12x) (1.1)\n",
            "Requirement already satisfied: gpu4pyscf-libxc-cuda12x==0.5 in /usr/local/lib/python3.11/dist-packages (from gpu4pyscf-cuda12x) (0.5)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x!=13.4.0,>=13.0->gpu4pyscf-cuda12x) (1.26.4)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x!=13.4.0,>=13.0->gpu4pyscf-cuda12x) (0.8.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pyscf>=2.8.0->gpu4pyscf-cuda12x) (1.11.3)\n",
            "Requirement already satisfied: h5py>=2.7 in /usr/local/lib/python3.11/dist-packages (from pyscf>=2.8.0->gpu4pyscf-cuda12x) (3.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyscf>=2.8.0->gpu4pyscf-cuda12x) (75.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from geometric->gpu4pyscf-cuda12x) (3.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from geometric->gpu4pyscf-cuda12x) (1.17.0)\n",
            "Requirement already satisfied: pyscf in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: numpy!=1.16,!=1.17,>=1.13 in /usr/local/lib/python3.11/dist-packages (from pyscf) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pyscf) (1.11.3)\n",
            "Requirement already satisfied: h5py>=2.7 in /usr/local/lib/python3.11/dist-packages (from pyscf) (3.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyscf) (75.2.0)\n",
            "Requirement already satisfied: geometric in /usr/local/lib/python3.11/dist-packages (1.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.11/dist-packages (from geometric) (1.26.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from geometric) (3.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from geometric) (1.17.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from geometric) (1.11.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install gpu4pyscf-cuda12x\n",
        "!pip install pyscf\n",
        "!pip install geometric\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvThcSBZBHyr"
      },
      "outputs": [],
      "source": [
        "!pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SFHIC52BHyr"
      },
      "source": [
        "# In this section, codes were cited from https://github.com/slab-it/FRATTVAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TncmAIl5Sc3L"
      },
      "source": [
        "## scripts/utils/apps.py\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf1vyAF6SZ0Z"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "def torch_fix_seed(seed= 42):\n",
        "    # Python random\n",
        "    random.seed(seed)\n",
        "    # Numpy\n",
        "    np.random.seed(seed)\n",
        "    # Pytorch\n",
        "    torch.manual_seed(seed)\n",
        "    torch.use_deterministic_algorithms = True\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def second2date(seconds: int) -> str:\n",
        "    seconds = int(seconds)\n",
        "    d = seconds // (3600*24)\n",
        "    h = (seconds - 3600*24*d) // 3600\n",
        "    m = (seconds - 3600*24*d - 3600*h) // 60\n",
        "    s = seconds - 3600*24*d - 3600*h - 60*m\n",
        "\n",
        "    return f'{d:0>2}:{h:0>2}:{m:0>2}:{s:0>2}'\n",
        "\n",
        "def list2pdData(loss_list: list, metrics: list) -> pd.DataFrame:\n",
        "    loss_dict = {}\n",
        "    for key, values in zip(metrics, loss_list):\n",
        "        loss_dict[key] = values\n",
        "    return pd.DataFrame(loss_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW8HFAwpSkI6"
      },
      "source": [
        "## scripts/utils/chem_metrics.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JD-GeduSnFs"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "# from moses import metrics\n",
        "import networkx as nx\n",
        "\n",
        "from guacamol.distribution_matching_generator import DistributionMatchingGenerator\n",
        "from guacamol.distribution_learning_benchmark import KLDivBenchmark\n",
        "from guacamol.frechet_benchmark import FrechetBenchmark\n",
        "\n",
        "\n",
        "def normalize(props: np.ndarray, pname: str):\n",
        "    if pname not in NORM_PARAMS.keys():\n",
        "        return props.tolist()\n",
        "    else:\n",
        "        low, high = NORM_PARAMS[pname]\n",
        "        return (props - low) / (high - low)\n",
        "\n",
        "\n",
        "def get_all_metrics(mol) -> dict:\n",
        "    if type(mol) == str:\n",
        "        mol = Chem.MolFromSmiles(mol)\n",
        "    if mol is None:\n",
        "        return [float('nan')] * len(METRICS_DICT)\n",
        "    return [func(mol) for func in METRICS_DICT.values()]\n",
        "\n",
        "\n",
        "def get_metrics(mol, key: str) -> dict:\n",
        "    if type(mol) == str:\n",
        "        mol = Chem.MolFromSmiles(mol)\n",
        "    if mol is None:\n",
        "        return float('nan')\n",
        "    return METRICS_DICT[key](mol)\n",
        "\n",
        "\n",
        "class MockGenerator(DistributionMatchingGenerator):\n",
        "    \"\"\"\n",
        "    Mock generator that returns pre-defined molecules,\n",
        "    possibly split in several calls\n",
        "    \"\"\"\n",
        "    def __init__(self, molecules: List[str]) -> None:\n",
        "        self.molecules = molecules\n",
        "        self.cursor = 0\n",
        "\n",
        "    def generate(self, number_samples: int) -> List[str]:\n",
        "        end = self.cursor + number_samples\n",
        "\n",
        "        sampled_molecules = self.molecules[self.cursor:end]\n",
        "        self.cursor = end\n",
        "        return sampled_molecules\n",
        "\n",
        "\n",
        "def physchem_divergence(smiles: list, reference: list, seed: int= 0):\n",
        "    \"\"\"\n",
        "    smiles: list of generated smiles\n",
        "    reference: list of training/test smiles\n",
        "\n",
        "    return average physchem kl-divergence\n",
        "    \"\"\"\n",
        "    generator = MockGenerator(smiles)\n",
        "    if len(reference) < len(smiles):\n",
        "        random.seed(seed)\n",
        "        reference += random.choices(reference, k= len(smiles)-len(reference))\n",
        "    benchmark = KLDivBenchmark(number_samples= len(smiles), training_set= reference)\n",
        "\n",
        "    return benchmark.assess_model(generator).score\n",
        "\n",
        "\n",
        "def guacamol_fcd(smiles: list, reference: list, seed: int= 0):\n",
        "    \"\"\"\n",
        "    smiles: list of generated smiles\n",
        "    reference: list of training/test smiles\n",
        "\n",
        "    rerurn standardize fcd [exp(-0.2 * fcd)]\n",
        "    \"\"\"\n",
        "    generator = MockGenerator(smiles)\n",
        "    if len(reference) < len(smiles):\n",
        "        random.seed(seed)\n",
        "        reference += random.choices(reference, k= len(smiles)-len(reference))\n",
        "    benchmark = FrechetBenchmark(sample_size= len(smiles), training_set= reference)\n",
        "    try:\n",
        "        score = benchmark.assess_model(generator).score\n",
        "        return score\n",
        "    except Exception as e:\n",
        "        print(f'[WARNING] can\\'t calculate fcd score because of {e}...', flush= True)\n",
        "        return float('nan')\n",
        "\n",
        "\n",
        "def penalized_logp(mol):\n",
        "    \"\"\"\n",
        "    Reward that consists of log p penalized by SA and # long cycles,\n",
        "    as described in (Kusner et al. 2017). Scores are normalized based on the\n",
        "    statistics of 250k_rndm_zinc_drugs_clean.smi dataset\n",
        "    :param mol: rdkit mol object\n",
        "    :return: float\n",
        "\n",
        "    Reference: 'https://github.com/bowenliu16/rl_graph_generation/blob/master/gym-molecule/gym_molecule/envs/molecule.py'\n",
        "    \"\"\"\n",
        "    # normalization constants, statistics from 250k_rndm_zinc_drugs_clean.smi\n",
        "    logP_mean = 2.4570953396190123\n",
        "    logP_std = 1.434324401111988\n",
        "    SA_mean = -3.0525811293166134\n",
        "    SA_std = 0.8335207024513095\n",
        "    cycle_mean = -0.0485696876403053\n",
        "    cycle_std = 0.2860212110245455\n",
        "\n",
        "    log_p = metrics.logP(mol)\n",
        "    SA = -metrics.SA(mol)\n",
        "\n",
        "    # cycle score\n",
        "    cycle_list = nx.cycle_basis(nx.Graph(\n",
        "        Chem.rdmolops.GetAdjacencyMatrix(mol)))\n",
        "    if len(cycle_list) == 0:\n",
        "        cycle_length = 0\n",
        "    else:\n",
        "        cycle_length = max([len(j) for j in cycle_list])\n",
        "    if cycle_length <= 6:\n",
        "        cycle_length = 0\n",
        "    else:\n",
        "        cycle_length = cycle_length - 6\n",
        "    cycle_score = -cycle_length\n",
        "\n",
        "    normalized_log_p = (log_p - logP_mean) / logP_std\n",
        "    normalized_SA = (SA - SA_mean) / SA_std\n",
        "    normalized_cycle = (cycle_score - cycle_mean) / cycle_std\n",
        "\n",
        "    return normalized_log_p + normalized_SA + normalized_cycle\n",
        "\n",
        "\n",
        "NORM_PARAMS = {'MW': [0, 1000],\n",
        "               'logP': [-10, 10],\n",
        "               'QED': [0, 1],\n",
        "               'SA': [10, 0],\n",
        "               'NP': [-5, 5],\n",
        "               'TPSA': [0, 300],\n",
        "            #    'BertzCT': [0, 2000],\n",
        "            #    'PlogP': [-20, 0]\n",
        "               }\n",
        "\n",
        "# METRICS_DICT = {'MW': metrics.weight,\n",
        "#                 'logP': metrics.logP,\n",
        "#                 'QED': metrics.QED,\n",
        "#                 'SA': metrics.SA,\n",
        "#                 'NP': metrics.NP,\n",
        "#                 'TPSA': Chem.Descriptors.TPSA,\n",
        "#                 # 'BertzCT': Chem.Descriptors.BertzCT,\n",
        "#                 # 'PlogP': penalized_logp\n",
        "#                 }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p8-TLECSoyr"
      },
      "source": [
        "## scripts/utils/construct.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5XetefuSrDi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "from itertools import chain\n",
        "\n",
        "import timeout_decorator\n",
        "\n",
        "from rdkit import Chem, rdBase, RDLogger\n",
        "from rdkit.Chem import RWMol, AllChem, DataStructs\n",
        "from rdkit.Chem.EnumerateStereoisomers import EnumerateStereoisomers, StereoEnumerationOptions\n",
        "# from molvs import Standardizer\n",
        "\n",
        "BONDTYPES = {1: Chem.rdchem.BondType.SINGLE,\n",
        "             2: Chem.rdchem.BondType.DOUBLE,\n",
        "             3: Chem.rdchem.BondType.TRIPLE}\n",
        "\n",
        "\n",
        "def isomer_search(smiles, ecfp: np.ndarray, radius: int= 2):\n",
        "    if type(ecfp) == list:\n",
        "        ecfp = np.array(ecfp)\n",
        "    if smiles is None:\n",
        "        return None\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    n_bits = len(ecfp)\n",
        "    opts = StereoEnumerationOptions(unique= True, onlyUnassigned= True)\n",
        "    isomers = list(EnumerateStereoisomers(mol, options=opts))\n",
        "    if len(isomers) == 0:\n",
        "        return smiles\n",
        "    else:\n",
        "        isomers += [mol]\n",
        "    euclids = []\n",
        "    for isomer in isomers:\n",
        "        iso_ecfp = np.array(AllChem.GetMorganFingerprintAsBitVect(isomer, radius, n_bits, useChirality= True))\n",
        "        euclids.append(np.linalg.norm(ecfp-iso_ecfp))\n",
        "\n",
        "    return Chem.MolToSmiles(isomers[np.argmin(euclids)])\n",
        "\n",
        "\n",
        "def calc_tanimoto(smi1, smi2, useChiral: bool= True):\n",
        "    if (smi1 is None) | (smi2 is None):\n",
        "        return float('nan')\n",
        "    ecfp1 = AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smi1), 2, 2048, useChirality= useChiral)\n",
        "    ecfp2 = AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smi2), 2, 2048, useChirality= useChiral)\n",
        "    return DataStructs.TanimotoSimilarity(ecfp1, ecfp2)\n",
        "\n",
        "\n",
        "def reconstructMol(smiles, frags, adj, ecfp: list= None,\n",
        "                   useChiral: bool= True, verbose: bool= False):\n",
        "    # hasChiral = bool(Chem.FindMolChiralCenters(Chem.MolFromSmiles(smiles))) if useChiral else False\n",
        "    hasChiral = bool(len(Chem.FindPotentialStereo(Chem.MolFromSmiles(smiles), flagPossible= False))) if useChiral else False\n",
        "    try:\n",
        "        # rev_smiles = MolFromFragments(frags, adj, asMol= False, useChiral= hasChiral)\n",
        "        rev_smiles = constructMol(frags, adj, asMol= False, useChiral= hasChiral)\n",
        "        if rev_smiles is None:\n",
        "            raise ValueError()\n",
        "\n",
        "        if hasChiral & (ecfp is not None):\n",
        "            rev_smiles = isomer_search(rev_smiles, ecfp)\n",
        "\n",
        "        if Chem.CanonSmiles(smiles, useChiral= int(hasChiral)) != Chem.CanonSmiles(rev_smiles, useChiral= int(hasChiral)):\n",
        "            if Chem.CanonSmiles(smiles, useChiral= 0) == Chem.CanonSmiles(rev_smiles, useChiral= 0):\n",
        "                correct = 2\n",
        "            else:\n",
        "                correct = 0\n",
        "                if verbose: print(f'[UNMATCH] {smiles}, {rev_smiles}', flush= True)\n",
        "        else:\n",
        "            correct = 3 if hasChiral else 1\n",
        "    except:\n",
        "        rev_smiles = None\n",
        "        correct = 0\n",
        "        if verbose: print(f'[ERROR] {smiles}', flush= True)\n",
        "\n",
        "    return rev_smiles, correct\n",
        "\n",
        "\n",
        "def constructMol(frag_smiles: list, adj: list, asMol: bool= False, useChiral: bool= True):\n",
        "    \"\"\"\n",
        "        frag_smiles: list of fragments as SMILES,\n",
        "        adj: torch.Tensor or list shape= (len(frag_smiles), len(frag_smiles)), 0: none, 1: single, 2: double, 3: triple\n",
        "        validity correction: choose largest fragments and check Valence\n",
        "    \"\"\"\n",
        "    # process options\n",
        "    blg = rdBase.BlockLogs()\n",
        "    lg = RDLogger.logger()\n",
        "    lg.setLevel(RDLogger.CRITICAL)\n",
        "    # stand = Standardizer()\n",
        "    remover = Chem.RemoveHsParameters()\n",
        "    remover.removeDegreeZero = False\n",
        "\n",
        "    # one node\n",
        "    if len(adj) < 2:\n",
        "        mol = AllChem.ReplaceSubstructs(Chem.MolFromSmiles(frag_smiles[0]), Chem.MolFromSmiles('*'), Chem.MolFromSmiles('[H]'), replaceAll= True)[0]\n",
        "        mol = Chem.RemoveHs(mol, remover, sanitize= False)\n",
        "        # mol = stand.standardize(mol)\n",
        "        smi = Chem.MolToSmiles(mol)\n",
        "        try:\n",
        "            if Chem.SanitizeMol(mol, catchErrors= True) == Chem.rdmolops.SanitizeFlags.SANITIZE_KEKULIZE:\n",
        "                # print(smi, flush= True)\n",
        "                smi = smi.replace('[n+]', '[n]')\n",
        "            smi = Chem.CanonSmiles(smi)\n",
        "            if asMol: smi = Chem.MolFromSmiles(smi)\n",
        "        except:\n",
        "            smi = None\n",
        "        return smi\n",
        "    else:\n",
        "        adj = np.array(adj)\n",
        "\n",
        "    # smiles to mol\n",
        "    fragments = [Chem.MolFromSmiles(s) for s in frag_smiles]\n",
        "\n",
        "    # assign AtomMapNum and combine fragments\n",
        "    for i, frag in enumerate(fragments):\n",
        "        n = delta = 0.25\n",
        "        for atom in frag.GetAtoms():\n",
        "            if atom.GetAtomicNum() == 0:\n",
        "                if atom.GetAtomMapNum() == 0:\n",
        "                    assert n < 10\n",
        "                    atom.SetDoubleProp('dummyMapNumber', n + 10*i)\n",
        "                    n += delta\n",
        "                else:\n",
        "                    atom.SetDoubleProp('dummyMapNumber', delta * atom.GetAtomMapNum() + 10*i)\n",
        "        if i == 0:\n",
        "            combo = frag\n",
        "        else:\n",
        "            combo = Chem.CombineMols(combo, frag)\n",
        "    rwcombo = RWMol(combo)\n",
        "\n",
        "    tril = np.tril(adj)\n",
        "    indices = list(map(list, np.where(tril)))\n",
        "    bond_types = tril[tril!=0].tolist()\n",
        "    stereos = [list(bond.GetStereoAtoms()) for bond in rwcombo.GetBonds() if bond.GetStereo() != Chem.rdchem.BondStereo.STEREONONE]\n",
        "    stereo_atoms = list(chain.from_iterable(stereos))\n",
        "\n",
        "    # add Bond between fragments\n",
        "    for i1, i2, b in zip(*indices, bond_types):\n",
        "        start_end = [i1, i2]\n",
        "        connect_idxs = []\n",
        "        dummy_idxs = []\n",
        "        bonds = []\n",
        "        for idx in start_end:\n",
        "            for i, a in enumerate(rwcombo.GetAtoms()):\n",
        "                if a.HasProp('dummyMapNumber'):\n",
        "                    mapnum = a.GetDoubleProp('dummyMapNumber')\n",
        "                    if mapnum == 10*idx + delta:\n",
        "                        a.ClearProp('dummyMapNumber')\n",
        "                        if len(a.GetNeighbors()) == 1:\n",
        "                            neighbor = a.GetNeighbors()[0]\n",
        "                            dummy_idxs.append(a.GetIdx())\n",
        "                            connect_idxs.append(neighbor.GetIdx())\n",
        "                            bonds.append(int(rwcombo.GetBondBetweenAtoms(a.GetIdx(), neighbor.GetIdx()).GetBondTypeAsDouble()))\n",
        "                    elif (mapnum > 10*idx+delta) & (mapnum < 10*(idx+1)):\n",
        "                        a.SetDoubleProp('dummyMapNumber', mapnum - delta)\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "        if len(connect_idxs) == 2:\n",
        "            c1, c2 = connect_idxs\n",
        "            b = min(bonds)\n",
        "            rwcombo.AddBond(c1, c2, BONDTYPES[b])\n",
        "            for c, d in zip(connect_idxs, dummy_idxs):\n",
        "                rwcombo.RemoveBond(c, d)\n",
        "            if (dummy_idxs[0] in stereo_atoms) | (dummy_idxs[1] in stereo_atoms):\n",
        "                idxs = {dummy_idxs[0]: c2, dummy_idxs[1]: c1}\n",
        "                for bn, aids in enumerate(stereos):\n",
        "                    stereos[bn] = [idxs[a] if a in idxs.keys() else a for a in aids]\n",
        "\n",
        "    # assign cis/trans stereo\n",
        "    i = 0\n",
        "    for bond in rwcombo.GetBonds():\n",
        "        if bond.GetStereo() != Chem.rdchem.BondStereo.STEREONONE:\n",
        "            bond.SetStereoAtoms(*stereos[i])\n",
        "            i += 1\n",
        "\n",
        "    # remove dummy atoms\n",
        "    try:\n",
        "        mol = AllChem.ReplaceSubstructs(rwcombo, Chem.MolFromSmiles('*'), Chem.MolFromSmiles('[H]'), replaceAll= True)[0]\n",
        "        mol = Chem.RemoveHs(mol, remover, sanitize= False)\n",
        "        mol = AllChem.ReplaceSubstructs(mol, Chem.MolFromSmiles('[H]'), Chem.MolFromSmiles('*'), replaceAll= True)[0]\n",
        "        mol = AllChem.DeleteSubstructs(mol, Chem.MolFromSmiles('*'))\n",
        "        for _ in range(len(fragments)):\n",
        "            if Chem.SanitizeMol(mol, catchErrors= True) == Chem.rdmolops.SanitizeFlags.SANITIZE_NONE:\n",
        "                break\n",
        "\n",
        "        mol.UpdatePropertyCache(strict=True)\n",
        "        if useChiral:\n",
        "            chirals = Chem.FindMolChiralCenters(mol)\n",
        "            if chirals:\n",
        "                tmpmol = Chem.MolFromSmiles(Chem.MolToSmiles(mol, canonical= True))\n",
        "                try:\n",
        "                    tmpmol = Chem.RenumberAtoms(tmpmol, tmpmol.GetSubstructMatch(mol))\n",
        "                    for (a1, c1), (a2, c2) in zip(chirals, Chem.FindMolChiralCenters(tmpmol)):\n",
        "                        if (a1 == a2) & (c1 != c2):\n",
        "                            mol.GetAtomWithIdx(a1).InvertChirality()\n",
        "                except Exception as e:\n",
        "                    pass\n",
        "        # mol = stand.standardize(mol)    # sanitize\n",
        "        smi = Chem.MolToSmiles(mol, canonical= True)\n",
        "        tmpmol = deepcopy(mol)\n",
        "        err = Chem.SanitizeMol(tmpmol, catchErrors= True)\n",
        "        if err == Chem.rdmolops.SanitizeFlags.SANITIZE_KEKULIZE:\n",
        "            smi = smi.replace('[n+]', '[n]')\n",
        "        smi = Chem.CanonSmiles(smi)\n",
        "    except Exception as e:\n",
        "        print(str(e), flush= True)\n",
        "        return None\n",
        "\n",
        "    if asMol:\n",
        "        return Chem.MolFromSmiles(smi)\n",
        "    else:\n",
        "        return smi\n",
        "\n",
        "\n",
        "def constructMolwithECFP(frag_smiles: list, adj: list, ecfp: list, radius: int):\n",
        "    smi = constructMol(frag_smiles, adj, asMol= False)\n",
        "\n",
        "    return isomer_search(smi, ecfp, radius)\n",
        "\n",
        "\n",
        "def constructMolwithTimeout(frag_smiles: list, adj: list, asMol: bool= False, useChiral: bool= True, timeout: int= 300):\n",
        "    @timeout_decorator.timeout(timeout, use_signals= False)\n",
        "    def construct(frag_smiles: list, adj: list, asMol: bool= False, useChiral: bool= True):\n",
        "        return constructMol(frag_smiles, adj, asMol, useChiral)\n",
        "    try:\n",
        "        smi = construct(frag_smiles, adj, asMol, useChiral)\n",
        "    except Exception as e:\n",
        "        print(e, flush= True)\n",
        "        smi = None\n",
        "    return smi\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbBqeVPySz2j"
      },
      "source": [
        "## scripts/utils/data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxTJbUraS3Mj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "class ListDataset(Dataset):\n",
        "    def __init__(self, frag_indices: list , positions: list, prop: torch.Tensor) -> None:\n",
        "        \"\"\"\n",
        "        frag_indices, positions: list of torch.Tensors with different lengths\n",
        "        ecfps, prop: torch.Tensor\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.ecfps = None\n",
        "        self.frag_indices = frag_indices\n",
        "        self.positions = positions\n",
        "        self.prop = prop\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.frag_indices)\n",
        "\n",
        "    def __getitem__(self, index) -> [torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        if self.ecfps is None:\n",
        "            return self.frag_indices[index], self.positions[index], self.prop[index]\n",
        "        else:\n",
        "            return self.ecfps[index], self.frag_indices[index], self.positions[index], self.prop[index]\n",
        "\n",
        "    def set_stereo(self, ecfps):\n",
        "        self.ecfps = ecfps\n",
        "\n",
        "\n",
        "def collate_pad_fn(batch):\n",
        "    frag_indices, positions, props = zip(*batch)\n",
        "    frag_indices = pad_sequence(frag_indices, batch_first= True, padding_value= 0)\n",
        "    positions = pad_sequence(positions, batch_first= True, padding_value= 0)\n",
        "    props = torch.stack(props)\n",
        "\n",
        "    return frag_indices, positions, props\n",
        "\n",
        "def collate_stereo_fn(batch):\n",
        "    ecfps, frag_indices, positions, props = zip(*batch)\n",
        "    ecfps = torch.stack(ecfps)\n",
        "    frag_indices = pad_sequence(frag_indices, batch_first= True, padding_value= 0)\n",
        "    positions = pad_sequence(positions, batch_first= True, padding_value= 0)\n",
        "    props = torch.stack(props)\n",
        "\n",
        "    return ecfps, frag_indices, positions, props"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmVqKMNDeZW5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reXVzBmUeZhL"
      },
      "source": [
        "## scripts/utils/fragmentation.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5psEOE_eZhM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from itertools import chain\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import RWMol, BRICS\n",
        "\n",
        "# from utils.medchemfrag import decomposition\n",
        "\n",
        "\n",
        "def FindBRICS(mol, bonds: list= None, AtomDone: set= None):\n",
        "    bonds = bonds if bonds is not None else []\n",
        "    AtomDone = AtomDone if AtomDone is not None else set([])\n",
        "\n",
        "    for idxs, _ in BRICS.FindBRICSBonds(mol):\n",
        "        idxs = sorted(idxs)\n",
        "        if (idxs in bonds) or (len(set(idxs) & AtomDone) > 1):  # both atoms have already been searched.\n",
        "            continue\n",
        "        else:\n",
        "            bonds.append(sorted(idxs))\n",
        "            AtomDone = AtomDone | set(idxs)\n",
        "    return bonds, AtomDone\n",
        "\n",
        "\n",
        "def FindRings(mol, bonds: list= None, AtomDone: set= None):\n",
        "    bonds = bonds if bonds is not None else []\n",
        "    AtomDone = AtomDone if AtomDone is not None else set([])\n",
        "    for bond in mol.GetBonds():\n",
        "        begin = bond.GetBeginAtom()\n",
        "        end = bond.GetEndAtom()\n",
        "\n",
        "        if (begin.GetIdx() in AtomDone) & (end.GetIdx() in AtomDone):\n",
        "            continue\n",
        "\n",
        "        # bond between rings, ring and C-ANY\n",
        "        if (begin.IsInRing() | end.IsInRing()) & (not bond.IsInRing()) & (bond.GetBondTypeAsDouble() < 2):\n",
        "            if begin.IsInRing() & end.IsInRing():\n",
        "                neighbor = 1\n",
        "            elif begin.IsInRing():\n",
        "                neighbor = len(end.GetNeighbors()) - 1\n",
        "            elif end.IsInRing():\n",
        "                neighbor = len(begin.GetNeighbors()) - 1\n",
        "            else:\n",
        "                neighbor = 0\n",
        "\n",
        "            if neighbor > 0:\n",
        "                idxs = sorted([begin.GetIdx(), end.GetIdx()])\n",
        "                if idxs not in bonds:\n",
        "                    bonds.append(idxs)\n",
        "                    AtomDone = AtomDone | set(idxs)\n",
        "    return bonds, AtomDone\n",
        "\n",
        "\n",
        "# def FindStereo(mol, bonds: list= None):\n",
        "#     \"\"\"\n",
        "#     find cis/trans stereo type\n",
        "#     \"\"\"\n",
        "#     bonds = bonds if bonds is not None else []\n",
        "#     for bond in mol.GetBonds():\n",
        "#         if bond.GetStereo() != Chem.rdchem.BondStereo.STEREONONE:\n",
        "#             stereo_atoms = list(bond.GetStereoAtoms())\n",
        "#             atom_idxs = [bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()]\n",
        "#             for aid in atom_idxs:\n",
        "#                 neighbors = mol.GetAtomWithIdx(aid).GetNeighbors()\n",
        "#                 if len(neighbors) > 2:\n",
        "#                     idx = [n.GetIdx() for n in neighbors if (n.GetIdx() not in stereo_atoms) & (n.GetIdx() not in atom_idxs)][0]\n",
        "#                     idxs = sorted([aid, idx])\n",
        "#                     if idxs not in bonds:\n",
        "#                         bonds.append(idxs)\n",
        "#     return bonds\n",
        "\n",
        "def find_BRICSbonds(mol) -> list:\n",
        "    return sorted([sorted(idxs) for idxs, _ in BRICS.FindBRICSBonds(mol)], key= lambda idxs: idxs[1])\n",
        "\n",
        "def find_rings(mol) -> list:\n",
        "    return sorted(FindRings(mol)[0], key= lambda idxs: idxs[1])\n",
        "\n",
        "def find_MedChemFrag(mol) -> list:\n",
        "    return sorted([sorted(idxs) for idxs in decomposition(mol)], key= lambda idxs: idxs[1])\n",
        "\n",
        "def find_BRICSbonds_and_rings(mol) -> list:\n",
        "    \"\"\"\n",
        "    Find bonds which are BRICS bonds or single bonds between rings.\n",
        "    \"\"\"\n",
        "    # bonds, AtomDone = FindBRICS(mol)\n",
        "    bonds = find_BRICSbonds(mol)\n",
        "    return sorted(FindRings(mol, bonds= bonds)[0], key= lambda idxs: idxs[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljMVTE5FS4za"
      },
      "source": [
        "## scripts/utils/decompose.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-tow5mJS7cX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0201bbc8-bc8d-4016-ce4a-a6753931aaf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COc1ccccc1/C=C/C=C(\\C#N)C(=O)Nc1ccc(C(=O)N(C)C)cc1\n",
            "COc1ccccc1C=C/C=C(\\C#N)C(=O)Nc1ccc(C(=O)N(C)C)cc1\n"
          ]
        }
      ],
      "source": [
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "from itertools import chain\n",
        "\n",
        "from rdkit import Chem, RDLogger\n",
        "from rdkit.Chem import RWMol, AllChem\n",
        "\n",
        "# from utils.fragmentation import find_BRICSbonds, find_BRICSbonds_and_rings, find_MedChemFrag\n",
        "\n",
        "lg = RDLogger.logger()\n",
        "lg.setLevel(RDLogger.CRITICAL)\n",
        "\n",
        "BONDTYPES = {1: Chem.rdchem.BondType.SINGLE,\n",
        "             2: Chem.rdchem.BondType.DOUBLE,\n",
        "             3: Chem.rdchem.BondType.TRIPLE}\n",
        "\n",
        "\n",
        "def setAtomMapNumsWithIdxs(mol, indexs= None):\n",
        "    indexs = indexs if indexs else range(mol.GetNumAtoms())\n",
        "    for i, atom in zip(indexs, mol.GetAtoms()):\n",
        "        atom.SetAtomMapNum(i)\n",
        "\n",
        "def clearAtomMapNums(mol):\n",
        "    for atom in mol.GetAtoms():\n",
        "        atom.SetAtomMapNum(0)\n",
        "\n",
        "def check_fragSize(mol, minSize: int= 1, maxDegree: int= 32):\n",
        "    frags = Chem.GetMolFrags(mol, asMols= True, sanitizeFrags= False)\n",
        "    cut = True\n",
        "    for f in frags:\n",
        "        Chem.SanitizeMol(f, catchErrors= True)\n",
        "        f = Chem.MolFromSmiles(Chem.MolToSmiles(f))\n",
        "        # check atom num exclude dummy atom\n",
        "        dummynum = sum([a.GetAtomicNum() == 0 for a in f.GetAtoms()])\n",
        "        atomnum = f.GetNumAtoms() - dummynum\n",
        "        if (atomnum < minSize) | (dummynum > maxDegree):\n",
        "            cut = False\n",
        "            break\n",
        "\n",
        "    return cut\n",
        "\n",
        "def HydrogenMatch(f, f_dash, uniquify: bool= True):\n",
        "    orders = f_dash.GetSubstructMatches(f, uniquify= uniquify)\n",
        "    canonOrder = None\n",
        "    for order in orders:\n",
        "        f_ordered = Chem.RenumberAtoms(f_dash, order)\n",
        "        assert f.GetNumAtoms() == f_ordered.GetNumAtoms()\n",
        "        for a, a_dash in zip(f.GetAtoms(), f_ordered.GetAtoms()):\n",
        "            if a.GetAtomicNum() != a_dash.GetAtomicNum(): break\n",
        "            elif a.GetNumExplicitHs() != a_dash.GetNumExplicitHs(): break\n",
        "        else:\n",
        "            canonOrder = order\n",
        "            break\n",
        "\n",
        "    if (canonOrder is None) & uniquify:\n",
        "        canonOrder = HydrogenMatch(f, f_dash, uniquify= False)\n",
        "\n",
        "    if (canonOrder is None) & bool(orders):\n",
        "        canonOrder = orders[0]\n",
        "\n",
        "    return canonOrder\n",
        "\n",
        "def MapNumsToAdj(bondMapNums: list, bond_types: list):\n",
        "    n_frags = len(bondMapNums)\n",
        "    if n_frags == 1:\n",
        "        adj = [[0]]\n",
        "    else:\n",
        "        n_bonds = len(bond_types)\n",
        "        adj = [[0] * n_frags for _ in range(len(bondMapNums))]\n",
        "\n",
        "        for b in range(1, n_bonds+1):\n",
        "            i1, i2 = [i for i in range(n_frags) if b in bondMapNums[i]]\n",
        "            adj[i1][i2] = bond_types[b-1]\n",
        "            adj[i2][i1] = bond_types[b-1]\n",
        "\n",
        "    return adj\n",
        "\n",
        "\n",
        "def MolToBRICSfragments(mol, minFragSize: int= 1, maxDegree: int= 32, useChiral: bool= True, useStereo: bool= False):\n",
        "    rwmol = RWMol(mol)\n",
        "    numatoms = rwmol.GetNumAtoms()\n",
        "\n",
        "    # search break bonds\n",
        "    # matches = find_BRICSbonds(rwmol)\n",
        "    matches = find_BRICSbonds_and_rings(rwmol)\n",
        "    # matches = find_MedChemFrag(mol)\n",
        "\n",
        "    # decompose mol\n",
        "    bond_types = []\n",
        "    chiral_centers = []\n",
        "    stereos = [list(bond.GetStereoAtoms()) for bond in rwmol.GetBonds() if bond.GetStereo() != Chem.rdchem.BondStereo.STEREONONE]\n",
        "    stereo_atoms = list(chain.from_iterable(stereos))\n",
        "    i = 0\n",
        "    while i < len(matches):\n",
        "        match = matches[i]\n",
        "        a1, a2 = match[0], match[1]\n",
        "        bond = rwmol.GetBondBetweenAtoms(a1, a2)\n",
        "        bond_type = int(bond.GetBondTypeAsDouble())\n",
        "\n",
        "        # stereo chem\n",
        "        if useStereo & (bond.GetBondType() == BONDTYPES[2]):\n",
        "            matches.remove(match)\n",
        "            continue\n",
        "\n",
        "        # check whether fragment size is bigger than min-size\n",
        "        tmpmol = deepcopy(rwmol)\n",
        "        rwmol.RemoveBond(a1, a2)\n",
        "        for a in match:\n",
        "            rwmol.AddAtom(Chem.Atom(0))\n",
        "            rwmol.GetAtomWithIdx(numatoms).SetAtomMapNum(i+1)\n",
        "            # rwmol.AddBond(a, numatoms, BONDTYPES[1])\n",
        "            rwmol.AddBond(a, numatoms, BONDTYPES[bond_type])\n",
        "\n",
        "            numatoms += 1\n",
        "\n",
        "        if check_fragSize(rwmol.GetMol(), minSize= minFragSize, maxDegree= maxDegree):\n",
        "            i += 1\n",
        "            bond_types.append(bond_type)\n",
        "            chiral_centers += [a for a in match if tmpmol.GetAtomWithIdx(a).HasProp('_CIPCode')]\n",
        "            # fix cis/trans stereo\n",
        "            if (a1 in stereo_atoms) | (a2 in stereo_atoms):\n",
        "                idxs = {a1: numatoms-1, a2: numatoms-2}\n",
        "                for bn, aids in enumerate(stereos):\n",
        "                    stereos[bn] = [idxs[a] if a in idxs.keys() else a for a in aids]\n",
        "        else:\n",
        "            rwmol = deepcopy(tmpmol)      # role back\n",
        "            numatoms -= len(match)\n",
        "            matches.remove(match)\n",
        "\n",
        "    # assign cis/trans stereo\n",
        "    i = 0\n",
        "    for bond in rwmol.GetBonds():\n",
        "        if bond.GetStereo() != Chem.rdchem.BondStereo.STEREONONE:\n",
        "            try:\n",
        "                bond.SetStereoAtoms(*stereos[i])\n",
        "            except:\n",
        "                pass\n",
        "            i += 1\n",
        "\n",
        "    # fragmentation\n",
        "    fragments_numed = Chem.GetMolFrags(rwmol, asMols= True, sanitizeFrags= False)\n",
        "    fragments = [Chem.MolFromSmiles(Chem.MolToSmiles(f, canonical= True)) for f in Chem.GetMolFrags(rwmol, asMols= True, sanitizeFrags= False)]\n",
        "\n",
        "    # only one fragment\n",
        "    if len(fragments) == 1:\n",
        "        return [Chem.MolToSmiles(mol)], [0], [[0]]\n",
        "\n",
        "    # convert to canonical atom orders\n",
        "    bondMapNums = []\n",
        "    etc = 1\n",
        "    for f_numed, f in zip(fragments_numed, fragments):\n",
        "        Chem.SanitizeMol(f_numed, catchErrors= True)\n",
        "\n",
        "        # make connect map\n",
        "        bondMapNum = sorted([a.GetAtomMapNum() for a in f.GetAtoms() if a.GetAtomMapNum()])\n",
        "        if len(bondMapNum) == 0:\n",
        "            bondMapNum = [len(matches)+etc]\n",
        "            etc += 1\n",
        "        bondMapNums.append(bondMapNum)\n",
        "\n",
        "        # reset chirality\n",
        "        if useChiral:\n",
        "            canonOrderIdxs = HydrogenMatch(f, f_numed)\n",
        "            f_renumed = Chem.RenumberAtoms(f_numed, canonOrderIdxs)\n",
        "            chirals_f = Chem.FindMolChiralCenters(f)\n",
        "            chirals_f_renumed = Chem.FindMolChiralCenters(f_renumed)\n",
        "            if len(chirals_f) != len(chirals_f_renumed):\n",
        "                chirals_nums, _ = zip(*chirals_f) if chirals_f else ([], [])\n",
        "                for a, ctype in chirals_f_renumed:\n",
        "                    if a not in chirals_nums:\n",
        "                        f.GetAtomWithIdx(a).SetProp('_CIPCode', ctype)\n",
        "                        f.GetAtomWithIdx(a).SetChiralTag(f_renumed.GetAtomWithIdx(a).GetChiralTag())\n",
        "                Chem.AssignCIPLabels(f)\n",
        "                chirals_f = Chem.FindMolChiralCenters(f)\n",
        "            for (a1, c1), (a2, c2) in zip(chirals_f, chirals_f_renumed):\n",
        "                if (a1 == a2) & (c1 != c2):\n",
        "                    f.GetAtomWithIdx(a1).InvertChirality()\n",
        "\n",
        "            # assign cis/trans stereo\n",
        "            for bond in f_renumed.GetBonds():\n",
        "                if bond.GetStereo() != Chem.rdchem.BondStereo.STEREONONE:\n",
        "                    a1, a2 = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "                    try:\n",
        "                        f.GetBondBetweenAtoms(a1, a2).SetStereo(bond.GetStereo())\n",
        "                        f.GetBondBetweenAtoms(a1, a2).SetStereoAtoms(*list(bond.GetStereoAtoms()))\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "        # numbering dummy atoms\n",
        "        dummys = [(a.GetAtomMapNum(), a.GetIdx()) for a in f.GetAtoms() if a.GetAtomMapNum()]\n",
        "        sort_dummys = sorted(dummys, key= lambda dummys: dummys[0])\n",
        "        for n, (_, i) in enumerate(sort_dummys):\n",
        "            f.GetAtomWithIdx(i).SetAtomMapNum(n+1)\n",
        "\n",
        "    frag_smiles = []\n",
        "    for f in fragments:\n",
        "        # Chem.SanitizeMol(f)   # miss stereo chemistry\n",
        "        frag_smiles.append(Chem.MolToSmiles(f).replace('\\\\\\\\', '\\\\'))\n",
        "\n",
        "    return frag_smiles, bond_types, bondMapNums\n",
        "\n",
        "\n",
        "def MolFromFragments(frag_smiles: list, adj: list, asMol: bool= False, useChiral: bool= True):\n",
        "    \"\"\"\n",
        "    frag_smiles: list of fragments as SMILES,\n",
        "    adj: torch.Tensor or list shape= (len(frag_smiles), len(frag_smiles)), 0: none, 1: single, 2: double, 3: triple\n",
        "    \"\"\"\n",
        "    if len(frag_smiles) == 1:\n",
        "        mol = Chem.MolFromSmiles(Chem.CanonSmiles(frag_smiles[0])) if asMol else Chem.CanonSmiles(frag_smiles[0])\n",
        "        return mol\n",
        "\n",
        "    # remove padding\n",
        "    adj = np.array(adj)\n",
        "\n",
        "    # smiles to mol\n",
        "    fragments = [Chem.MolFromSmiles(s) for s in frag_smiles]\n",
        "\n",
        "    # assign AtomMapNum and combine fragments\n",
        "    for i, frag in enumerate(fragments):\n",
        "        n = delta = 0.25\n",
        "        for atom in frag.GetAtoms():\n",
        "            if atom.GetAtomicNum() == 0:\n",
        "                if atom.GetAtomMapNum() == 0:\n",
        "                    assert n < 10\n",
        "                    atom.SetDoubleProp('dummyMapNumber', n + 10*i)\n",
        "                    n += delta\n",
        "                else:\n",
        "                    atom.SetDoubleProp('dummyMapNumber', delta * atom.GetAtomMapNum() + 10*i)\n",
        "\n",
        "        if i == 0:\n",
        "            combo = frag\n",
        "        else:\n",
        "            combo = Chem.CombineMols(combo, frag)\n",
        "    rwcombo = RWMol(combo)\n",
        "\n",
        "    tril = np.tril(adj)\n",
        "    indices = list(map(list, np.where(tril)))\n",
        "    bond_types = tril[tril!=0].tolist()\n",
        "    stereos = [list(bond.GetStereoAtoms()) for bond in rwcombo.GetBonds() if bond.GetStereo() != Chem.rdchem.BondStereo.STEREONONE]\n",
        "    stereo_atoms = list(chain.from_iterable(stereos))\n",
        "\n",
        "    # add Bond between fragments\n",
        "    for i1, i2, b in zip(*indices, bond_types):\n",
        "        start_end = [i1, i2]\n",
        "        connect_idxs = []\n",
        "        dummy_idxs = []\n",
        "        bonds = []\n",
        "        for idx in start_end:\n",
        "            for i, a in enumerate(rwcombo.GetAtoms()):\n",
        "                if a.HasProp('dummyMapNumber'):\n",
        "                    mapnum = a.GetDoubleProp('dummyMapNumber')\n",
        "                    if mapnum == 10*idx + delta:\n",
        "                        a.ClearProp('dummyMapNumber')\n",
        "                        assert len(a.GetNeighbors()) == 1\n",
        "                        neighbor = a.GetNeighbors()[0]\n",
        "                        dummy_idxs.append(a.GetIdx())\n",
        "                        connect_idxs.append(neighbor.GetIdx())\n",
        "                        bonds.append(int(rwcombo.GetBondBetweenAtoms(a.GetIdx(), neighbor.GetIdx()).GetBondTypeAsDouble()))\n",
        "                    elif (mapnum > 10*idx+delta) & (mapnum < 10*(idx+1)):\n",
        "                        a.SetDoubleProp('dummyMapNumber', mapnum - delta)\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "        assert len(connect_idxs) == 2\n",
        "        c1, c2 = connect_idxs\n",
        "        b = min(bonds)\n",
        "        rwcombo.AddBond(c1, c2, BONDTYPES[b])\n",
        "        for c, d in zip(connect_idxs, dummy_idxs):\n",
        "            rwcombo.RemoveBond(c, d)\n",
        "        if (dummy_idxs[0] in stereo_atoms) | (dummy_idxs[1] in stereo_atoms):\n",
        "            idxs = {dummy_idxs[0]: c2, dummy_idxs[1]: c1}\n",
        "            for bn, aids in enumerate(stereos):\n",
        "                stereos[bn] = [idxs[a] if a in idxs.keys() else a for a in aids]\n",
        "\n",
        "    # assign cis/trans stereo\n",
        "    i = 0\n",
        "    for bond in rwcombo.GetBonds():\n",
        "        if bond.GetStereo() != Chem.rdchem.BondStereo.STEREONONE:\n",
        "            bond.SetStereoAtoms(*stereos[i])\n",
        "            i += 1\n",
        "\n",
        "    # remove dummy atoms\n",
        "    remover = Chem.RemoveHsParameters()\n",
        "    remover.removeDegreeZero = False\n",
        "    mol = AllChem.ReplaceSubstructs(rwcombo, Chem.MolFromSmiles('*'), Chem.MolFromSmiles('[H]'), replaceAll= True)[0]\n",
        "    mol = Chem.RemoveHs(mol, remover, sanitize= False)\n",
        "    mol = AllChem.ReplaceSubstructs(mol, Chem.MolFromSmiles('[H]'), Chem.MolFromSmiles('*'), replaceAll= True)[0]\n",
        "    mol = AllChem.DeleteSubstructs(mol, Chem.MolFromSmiles('*'))\n",
        "\n",
        "    # sanitize fragments\n",
        "    for _ in range(len(fragments)):\n",
        "        if Chem.SanitizeMol(mol, catchErrors= True) == Chem.rdmolops.SanitizeFlags.SANITIZE_NONE:\n",
        "            break\n",
        "\n",
        "    # check chirality\n",
        "    if useChiral:\n",
        "        chirals = Chem.FindMolChiralCenters(mol)\n",
        "        if chirals:\n",
        "            tmpmol = Chem.MolFromSmiles(Chem.MolToSmiles(mol, canonical= True))\n",
        "            tmpmol = Chem.RenumberAtoms(tmpmol, tmpmol.GetSubstructMatch(mol))\n",
        "            for (a1, c1), (a2, c2) in zip(chirals, Chem.FindMolChiralCenters(tmpmol)):\n",
        "                if (a1 == a2) & (c1 != c2):\n",
        "                    mol.GetAtomWithIdx(a1).InvertChirality()\n",
        "\n",
        "    # mol = stand.standardize(mol)\n",
        "    # Chem.SanitizeMol(mol)\n",
        "    smi = Chem.MolToSmiles(mol, canonical= True)\n",
        "\n",
        "    if asMol:\n",
        "        return Chem.MolFromSmiles(smi)\n",
        "    else:\n",
        "        return smi\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    smi = 'COc1ccccc1/C=C/C=C(\\C#N)C(=O)Nc1ccc(C(=O)N(C)C)cc1'\n",
        "    frag_smiles, bond_types, bondMapNums = MolToBRICSfragments(Chem.MolFromSmiles(smi), useStereo= True)\n",
        "    # n_frags = len(frag_smiles)\n",
        "    # tmp_ecfps = [[0, 0] for _ in range(len(frag_smiles))]\n",
        "    # tree = make_DFStree(list(range(n_frags)), tmp_ecfps, bond_types, bondMapNums)\n",
        "    # fids = tree.dgl_graph.ndata['fid'].squeeze(-1)\n",
        "    # adj = tree.adjacency_matrix().to_dense()\n",
        "    # frag_smiles = [frag_smiles[fid] for fid in fids]\n",
        "    adj = MapNumsToAdj(bondMapNums, bond_types)\n",
        "    smi_rev = MolFromFragments(frag_smiles, adj)\n",
        "    print(smi)\n",
        "    print(smi_rev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OQGqUXgS901"
      },
      "source": [
        "## scripts/utils/fragmentation.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnDWSdRUS_yz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from itertools import chain\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import RWMol, BRICS\n",
        "\n",
        "# from utils.medchemfrag import decomposition\n",
        "\n",
        "\n",
        "def FindBRICS(mol, bonds: list= None, AtomDone: set= None):\n",
        "    bonds = bonds if bonds is not None else []\n",
        "    AtomDone = AtomDone if AtomDone is not None else set([])\n",
        "\n",
        "    for idxs, _ in BRICS.FindBRICSBonds(mol):\n",
        "        idxs = sorted(idxs)\n",
        "        if (idxs in bonds) or (len(set(idxs) & AtomDone) > 1):  # both atoms have already been searched.\n",
        "            continue\n",
        "        else:\n",
        "            bonds.append(sorted(idxs))\n",
        "            AtomDone = AtomDone | set(idxs)\n",
        "    return bonds, AtomDone\n",
        "\n",
        "\n",
        "def FindRings(mol, bonds: list= None, AtomDone: set= None):\n",
        "    bonds = bonds if bonds is not None else []\n",
        "    AtomDone = AtomDone if AtomDone is not None else set([])\n",
        "    for bond in mol.GetBonds():\n",
        "        begin = bond.GetBeginAtom()\n",
        "        end = bond.GetEndAtom()\n",
        "\n",
        "        if (begin.GetIdx() in AtomDone) & (end.GetIdx() in AtomDone):\n",
        "            continue\n",
        "\n",
        "        # bond between rings, ring and C-ANY\n",
        "        if (begin.IsInRing() | end.IsInRing()) & (not bond.IsInRing()) & (bond.GetBondTypeAsDouble() < 2):\n",
        "            if begin.IsInRing() & end.IsInRing():\n",
        "                neighbor = 1\n",
        "            elif begin.IsInRing():\n",
        "                neighbor = len(end.GetNeighbors()) - 1\n",
        "            elif end.IsInRing():\n",
        "                neighbor = len(begin.GetNeighbors()) - 1\n",
        "            else:\n",
        "                neighbor = 0\n",
        "\n",
        "            if neighbor > 0:\n",
        "                idxs = sorted([begin.GetIdx(), end.GetIdx()])\n",
        "                if idxs not in bonds:\n",
        "                    bonds.append(idxs)\n",
        "                    AtomDone = AtomDone | set(idxs)\n",
        "    return bonds, AtomDone\n",
        "\n",
        "\n",
        "# def FindStereo(mol, bonds: list= None):\n",
        "#     \"\"\"\n",
        "#     find cis/trans stereo type\n",
        "#     \"\"\"\n",
        "#     bonds = bonds if bonds is not None else []\n",
        "#     for bond in mol.GetBonds():\n",
        "#         if bond.GetStereo() != Chem.rdchem.BondStereo.STEREONONE:\n",
        "#             stereo_atoms = list(bond.GetStereoAtoms())\n",
        "#             atom_idxs = [bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()]\n",
        "#             for aid in atom_idxs:\n",
        "#                 neighbors = mol.GetAtomWithIdx(aid).GetNeighbors()\n",
        "#                 if len(neighbors) > 2:\n",
        "#                     idx = [n.GetIdx() for n in neighbors if (n.GetIdx() not in stereo_atoms) & (n.GetIdx() not in atom_idxs)][0]\n",
        "#                     idxs = sorted([aid, idx])\n",
        "#                     if idxs not in bonds:\n",
        "#                         bonds.append(idxs)\n",
        "#     return bonds\n",
        "\n",
        "def find_BRICSbonds(mol) -> list:\n",
        "    return sorted([sorted(idxs) for idxs, _ in BRICS.FindBRICSBonds(mol)], key= lambda idxs: idxs[1])\n",
        "\n",
        "def find_rings(mol) -> list:\n",
        "    return sorted(FindRings(mol)[0], key= lambda idxs: idxs[1])\n",
        "\n",
        "def find_MedChemFrag(mol) -> list:\n",
        "    return sorted([sorted(idxs) for idxs in decomposition(mol)], key= lambda idxs: idxs[1])\n",
        "\n",
        "def find_BRICSbonds_and_rings(mol) -> list:\n",
        "    \"\"\"\n",
        "    Find bonds which are BRICS bonds or single bonds between rings.\n",
        "    \"\"\"\n",
        "    # bonds, AtomDone = FindBRICS(mol)\n",
        "    bonds = find_BRICSbonds(mol)\n",
        "    return sorted(FindRings(mol, bonds= bonds)[0], key= lambda idxs: idxs[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTr5_b7pTF9N"
      },
      "source": [
        "## scripts/utils/mask.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uW1-xDaRTDh1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Reference from https://github.com/pytorch/tutorials/blob/main/beginner_source/translation_transformer.py\n",
        "def generate_square_subsequent_mask(length: int, device: torch.device= 'cpu'):\n",
        "    mask = (torch.triu(torch.ones((length, length), device= device)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "def create_mask(src: torch.Tensor, tgt: torch.Tensor, pad_idx: int= 0, batch_first: bool= True):\n",
        "    device = src.device\n",
        "    src_seq_len = src.shape[1] if batch_first else src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[1] if batch_first else tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len, device)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len), device= device).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = src == pad_idx if batch_first else (src == pad_idx).transpose(0, 1)\n",
        "    tgt_padding_mask = tgt == pad_idx if batch_first else (tgt == pad_idx).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A21MuAC5TInc"
      },
      "source": [
        "## scripts/utils/medchemfrag.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgXd_AC8TMUM"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors, AllChem\n",
        "\n",
        "\"\"\"\n",
        "Reference: http://molmodel.com/hg/medchem_fragment_splitter (2023/02/13)\n",
        "\"\"\"\n",
        "\n",
        "rules = [\n",
        "    \"[R]-!@[$([CX4;H2,H1,H0])]\",  # 1\n",
        "    \"[a]-!@[$([NX3;H1,H0]),$([OX2;H0]),$([SX2;H0])]-!@[$([C;H2,H1,H0]);!$([CX3]=[OX1])]\",  # 2\n",
        "    \"[a]-!@[$([NX3;H1,H0]),$([OX2;H0]),$([SX2;H0])]-!@[a]\",  # 3\n",
        "    \"[a]-!@[$([CX3]=[OX1,NX2,SX1,CX3])]-!@[$([CX4;H2,H1,H0])]\",  # 4\n",
        "    \"[c]-!@[$([CX3]=[OX1,NX2,SX1,$([CX3;H2])])]-!@[c]\",  # 5.1\n",
        "    \"[n]-!@[$([CX3]=[OX1,NX2,SX1,$([CX3;H2])])]-!@[c]\",  # 5.2\n",
        "    \"[$([CX4;H2,H1,H0])]-!@[CX3](=[OX1])[OX2;H0]\",  # 6\n",
        "    \"[$([CX4;H2,H1,H0])]-!@[OX2;H0][CX3](=[OX1])\",  # 7\n",
        "    \"[a]-!@[CX3](=[OX1])O-!@[$([CX4;H2,H1,H0])]\",  # 8\n",
        "    \"[a]-!@[CX3](=[OX1])O-!@[a]\",  # 9\n",
        "    \"[a]-!@[NX2;H0]=[NX2;H0]-!@[$([CX4;H2,H1,H0])]\",  # 10\n",
        "    \"[a]-!@[NX2;H0]=[NX2;H0]-!@[a]\",  # 11\n",
        "    \"[a]-!@[NX3;H1]-!@[$([CX3;H0](=[OX1]))]-!@[$([CX4;H2,H1,H0])]\",  # 12\n",
        "    \"[a]-!@[$([CX3;H0](=[OX1]))]-!@[NX3;H1]-!@[$([CX4;H2,H1,H0])]\",  # 13\n",
        "    \"[a]-!@[NX3;H1]-!@[$([CX3;H0](=[OX1]))]-!@[a]\",  # 14\n",
        "    \"[a]-!@[$([CX3;H0](=[OX1]))]-!@[NX3;H1]-!@[a]\",  # 15\n",
        "    \"[a]-!@[SX4](=[OX1])(=[OX1])[NX3;H1]-!@[$([CX4;H2,H1,H0])]\",  # 16\n",
        "    \"[a]-!@[NX3;H1][SX4](=[OX1])(=[OX1])-!@[$([CX4;H2,H1,H0])]\",  # 17\n",
        "    \"[a]-!@[SX4](=[OX1])(=[OX1])[NX3;H1]-!@[a]\",  # 18\n",
        "    \"[a]-!@[NX3;H1][SX4](=[OX1])(=[OX1])-!@[NX3;H1]-!@[a]\",  # 19\n",
        "    \"[$([CX4;H2,H1,H0])]-!@[NX3][CX3](=[OX1])\",  # 20\n",
        "    \"[$([CX4;H2,H1,H0])]-!@[CX3](=[OX1])[NX3]\",  # 21\n",
        "    \"[$([CX4;H2,H1,H0])]-!@[$([NX3;H1,H0])]\",  # 22\n",
        "    \"[$([CX4;H2,H1,H0])]-!@[$([OX2;H0])]\",  # 23\n",
        "    \"[$([CX4;H2,H1,H0])]-!@[$([SX2;H0])]\",  # 24\n",
        "    \"[$([CX4;H2,H1,H0])]-!@[SX4](=[OX1])(=[OX1])[NX3;H1]\",  # 25\n",
        "    \"[$([CX4;H2,H1,H0])]-!@[NX3;H1][SX4](=[OX1])(=[OX1])\"  # 26\n",
        "]\n",
        "\n",
        "index_all = [\n",
        "    [(0, 1)],  # 1\n",
        "    [(1, 2)],  # 2\n",
        "    [(0, 1), (1, 2)],  # 3\n",
        "    [(1, 2)],  # 4\n",
        "    [(0, 1), (1, 2)],  # 5.1\n",
        "    [(1, 2)],  # 5.2\n",
        "    [(0, 1)],  # 6\n",
        "    [(0, 1)],  # 7\n",
        "    [(3, 4)],  # 8\n",
        "    [(0, 1), (3, 4)],  # 9\n",
        "    [(2, 3)],  # 10\n",
        "    [(0, 1), (2, 3)],  # 11\n",
        "    [(2, 3)],  # 12\n",
        "    [(2, 3)],  # 13\n",
        "    [(0, 1), (2, 3)],  # 14\n",
        "    [(0, 1), (2, 3)],  # 15\n",
        "    [(4, 5)],  # 16\n",
        "    [(4, 5)],  # 17\n",
        "    [(0, 1), (4, 5)],  # 18\n",
        "    [(0, 1), (4, 5)],  # 19\n",
        "    [(0, 1)],  # 20\n",
        "    [(0, 1)],  # 21\n",
        "    [(0, 1)],  # 22\n",
        "    [(0, 1)],  # 23\n",
        "    [(0, 1)],  # 24\n",
        "    [(0, 1)],  # 25\n",
        "    [(0, 1)],  # 26\n",
        "]\n",
        "\n",
        "def decomposition(molecule, smarts: list= None):\n",
        "    only_smarts = (smarts is None)\n",
        "\n",
        "    atomPairs = []\n",
        "    if not only_smarts:\n",
        "        for index in range(len(smarts)):\n",
        "            smartFragment = Chem.MolFromSmiles(smarts[index])\n",
        "            atomPairsLoc = molecule.GetSubstructMatches(smartFragment)\n",
        "            for atomPair in atomPairsLoc:\n",
        "                atomPairs.append(atomPair)\n",
        "    else:\n",
        "        for index in range(len(rules)):\n",
        "            atomPairsLoc = molecule.GetSubstructMatches(Chem.MolFromSmarts(rules[index]))\n",
        "            for nb in range(len(index_all[index])):\n",
        "                index1 = index_all[index][nb][0]\n",
        "                index2 = index_all[index][nb][1]\n",
        "                for atomPair in atomPairsLoc:\n",
        "                    atomIndex1 = atomPair[index1]\n",
        "                    atomIndex2 = atomPair[index2]\n",
        "                    atomPairs.append((atomIndex1, atomIndex2))\n",
        "\n",
        "    if (len(atomPairs) == 0):\n",
        "        return []\n",
        "\n",
        "    atomPairs = list(set(atomPairs))\n",
        "    bonds = list()\n",
        "    if not only_smarts:\n",
        "        flag = False\n",
        "        for atomIndexes1 in atomPairs:\n",
        "            for atomIndexes2 in atomPairs:\n",
        "                if atomIndexes1 == atomIndexes2:\n",
        "                    continue\n",
        "                else:\n",
        "                    for a1 in atomIndexes1:\n",
        "                        for a2 in atomIndexes2:\n",
        "                            if a1 == a2:\n",
        "                                flag = True\n",
        "                                if len(atomIndexes1) > len(atomIndexes2):\n",
        "                                    if atomIndexes2 in atomPairs:\n",
        "                                        atomPairs.remove(atomIndexes2)\n",
        "                                else:\n",
        "                                    if atomIndexes1 in atomPairs:\n",
        "                                        atomPairs.remove(atomIndexes1)\n",
        "                                    break\n",
        "                        if flag:\n",
        "                            break\n",
        "                flag = False\n",
        "\n",
        "    for atomIndexes in atomPairs:\n",
        "        for a1 in atomIndexes:\n",
        "            for a2 in atomIndexes:\n",
        "                if a1 == a2:\n",
        "                    continue\n",
        "                else:\n",
        "                    bond = molecule.GetBondBetweenAtoms(a1, a2)\n",
        "                    if (bond != None):\n",
        "                        idxs = sorted([a1, a2])\n",
        "                        if idxs not in bonds:\n",
        "                            bonds.append(idxs)\n",
        "    # bonds = list(set(bonds))\n",
        "    return bonds\n",
        "\n",
        "\n",
        "def add_nitrogen_charges(m):\n",
        "    m.UpdatePropertyCache(strict=False)\n",
        "    ps = Chem.DetectChemistryProblems(m)\n",
        "    if not ps:\n",
        "        Chem.SanitizeMol(m)\n",
        "        return m\n",
        "    for p in ps:\n",
        "        if p.GetType()=='AtomValenceException':\n",
        "            at = m.GetAtomWithIdx(p.GetAtomIdx())\n",
        "            if at.GetAtomicNum()==7 and at.GetFormalCharge()==0 and at.GetExplicitValence()==4:\n",
        "                at.SetFormalCharge(1)\n",
        "    Chem.SanitizeMol(m)\n",
        "    return m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqHAJjbJTNFT"
      },
      "source": [
        "## scripts/utils/metrics.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZ7Gp9xfTPyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72853b9a-5c80-4fb4-f03f-fdb0cec1d4de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0741,  0.1183, -0.2023, -0.0021],\n",
            "        [ 0.0837, -0.0818,  0.0504,  0.0357],\n",
            "        [ 0.1158, -0.1204, -0.0305,  0.0752]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def batched_kl_divergence(mu: torch.Tensor, ln_var: torch.Tensor):\n",
        "        return (- 0.5 * torch.sum(1 + ln_var - mu.pow(2) - ln_var.exp(), dim= -1)).mean(dim= 0)\n",
        "\n",
        "def cosine_matrix(a: torch.Tensor, b: torch.Tensor, p: int= 2, dim: int= 1):\n",
        "    \"\"\"\n",
        "    a.shape = (*, dim)\n",
        "    b.shape = (*, dim)\n",
        "    a.dim == b.dim\n",
        "\n",
        "    return matrix.shape= (a.shape[0], b.shape[0])\n",
        "    \"\"\"\n",
        "    return torch.matmul(F.normalize(a, p=p, dim= dim), F.normalize(b, p=p, dim= dim).T)\n",
        "\n",
        "def cosine_similarity(a: torch.Tensor, b: torch.Tensor, p: int= 2, dim: int= 1):\n",
        "    \"\"\"\n",
        "    a.shape = (*, dim)\n",
        "    b.shape = (*, dim)\n",
        "    a.dim == b.dim\n",
        "\n",
        "    return diag of matrix\n",
        "    \"\"\"\n",
        "    return cosine_matrix(a, b, p, dim).diag()\n",
        "\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, input: torch.Tensor, target: torch.Tensor):\n",
        "        loss = torch.sqrt(self.mse(input, target) + self.eps)\n",
        "        return loss\n",
        "\n",
        "CRITERION = {'mse': nn.MSELoss,\n",
        "             'mae': nn.L1Loss,\n",
        "             'bce': nn.BCEWithLogitsLoss,\n",
        "             'crs': nn.CrossEntropyLoss,\n",
        "             'rmse': RMSELoss}\n",
        "\n",
        "\n",
        "def euclid_distance(a: torch.Tensor, b: torch.Tensor, p: int= 2, dim: int= 1):\n",
        "    \"\"\"\n",
        "    a.shape = (*, dim)\n",
        "    b.shape = (*, dim)\n",
        "    a.dim == b.dim\n",
        "\n",
        "    return norm vector\n",
        "    \"\"\"\n",
        "    return torch.norm(a - b, p= p, dim= dim)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "      a = torch.randn(3, 128)\n",
        "      b = torch.randn(4, 128)\n",
        "\n",
        "      tmp = cosine_matrix(a, b)\n",
        "      print(tmp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyYN66epTSeb"
      },
      "source": [
        "## scripts/utils/preprocess.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5P-W0HP7TVg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f8adb2-8471-4dc1-aac6-5dc1e9b94c52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2H]C([2H])([2H])c1ccnc2c1NC(=O)c1cccnc1N2C1CC1\n",
            "[2H]C([2H])([2H])c1ccnc2c1NC(=O)c1cccnc1N2C1CC1\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from collections import Counter\n",
        "from copy import deepcopy\n",
        "from itertools import chain\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "from molvs import standardize_smiles\n",
        "from rdkit import Chem, RDLogger\n",
        "from rdkit.Chem import AllChem, DataStructs\n",
        "from tqdm import tqdm\n",
        "\n",
        "# from utils.decompose import MolFromFragments, MolToBRICSfragments, MapNumsToAdj\n",
        "\n",
        "lg = RDLogger.logger()\n",
        "lg.setLevel(RDLogger.CRITICAL)\n",
        "\n",
        "\n",
        "def smiles2mol(s):\n",
        "    m = Chem.MolFromSmiles(s)\n",
        "    if m is None:\n",
        "        print(f'[ERROR] {s} is not valid.', flush= True)\n",
        "    return m\n",
        "\n",
        "def frag2ecfp(frag, radius: int= 2, n_bits: int= 2048, useChiral: bool= True, ignore_dummy: bool= False):\n",
        "    if ignore_dummy:\n",
        "        frag = Chem.RemoveHs(AllChem.ReplaceSubstructs(frag, Chem.MolFromSmiles('*'), Chem.MolFromSmiles('[H]'), replaceAll= True)[0])\n",
        "    return AllChem.GetMorganFingerprintAsBitVect(frag, radius, n_bits, useChirality= useChiral)\n",
        "\n",
        "def FragmentsToIndices(fragments_list: list, fragment_idxs: dict, verbose: int= 0):\n",
        "    if verbose:\n",
        "        return [[fragment_idxs[f] for f in frags] for frags in tqdm(fragments_list)]\n",
        "    else:\n",
        "        return [[fragment_idxs[f] for f in frags] for frags in fragments_list]\n",
        "\n",
        "\n",
        "def MolsToBRICSfragments(mols: list, debug: bool= True,\n",
        "                         useChiral: bool= True, ignore_double: bool= False,\n",
        "                         minFragSize: int= 1, maxFragNums: int= 50, maxDegree: int= 32,\n",
        "                         uni_fragments: list= None, asFragments: bool= False,):\n",
        "    fragments_list = []\n",
        "    bondtypes_list = []\n",
        "    bondMapNums_list = []\n",
        "    all_fragments = []\n",
        "    recon_flag = []\n",
        "\n",
        "    # decompose mol\n",
        "    for i, mol in enumerate(mols):\n",
        "        s = Chem.MolToSmiles(mol)\n",
        "        # hasChiral = bool(Chem.FindMolChiralCenters(mol)) if useChiral else False\n",
        "        hasChiral = bool(len(Chem.FindPotentialStereo(mol, flagPossible= False))) if useChiral else False\n",
        "        frags, bond_types, bondMapNums = MolToBRICSfragments(mol, minFragSize= minFragSize, maxDegree= maxDegree, useChiral= useChiral, useStereo= ignore_double)\n",
        "        min_size = minFragSize\n",
        "        while len(frags) > maxFragNums:\n",
        "            min_size += 1\n",
        "            frags, bond_types, bondMapNums = MolToBRICSfragments(mol, minFragSize= minFragSize, maxDegree= maxDegree, useChiral= hasChiral, useStereo= ignore_double)\n",
        "            print(f\"{s} has over {maxFragNums} fragments. min_size:{min_size-1} -> {min_size}\", flush= True)\n",
        "        if debug:\n",
        "            try:\n",
        "                adj = MapNumsToAdj(bondMapNums, bond_types)\n",
        "                s1 = Chem.MolToSmiles(mol, isomericSmiles= hasChiral)\n",
        "                s2 = Chem.MolToSmiles(MolFromFragments(frags, adj, asMol= True), isomericSmiles= hasChiral)\n",
        "                if (s1 != s2) & (s1 != standardize_smiles(s2)):\n",
        "                    if hasChiral:\n",
        "                        s1_dash = Chem.CanonSmiles(s1, useChiral= 0)\n",
        "                        s2_dash = Chem.CanonSmiles(s2, useChiral= 0)\n",
        "                        if (s1_dash == s2_dash) | (s1_dash == standardize_smiles(s2_dash)):\n",
        "                            recon = 2\n",
        "                            print(f\"[{i}] {s1}, {s2} is 3D unreconstructable.\", flush= True)\n",
        "                        else:\n",
        "                            recon = 0\n",
        "                            print(f\"[{i}] {s1_dash}, {s2_dash} is 2D unreconstructable.\", flush= True)\n",
        "                    else:\n",
        "                        recon = 0\n",
        "                        print(f\"[{i}] {s1}, {s2} is unreconstructable.\", flush= True)\n",
        "                else:\n",
        "                    recon = 3 if hasChiral else 1\n",
        "            except:\n",
        "                recon = 0\n",
        "                print(f'[{i}] {s} is an ERROR.')\n",
        "\n",
        "        if recon > 0:\n",
        "            all_fragments += frags\n",
        "            fragments_list.append(frags)\n",
        "            bondtypes_list.append(bond_types)\n",
        "            bondMapNums_list.append(bondMapNums)\n",
        "            recon_flag.append(recon)\n",
        "\n",
        "    # calculate frequency and Uniqueness\n",
        "    if uni_fragments is None:\n",
        "        frag_freq = Counter(all_fragments)\n",
        "        uni_fragments, freq_list = map(list, zip(*frag_freq.items()))\n",
        "        df = pd.DataFrame({'SMILES': uni_fragments, 'frequency': freq_list})\n",
        "        df = df.assign(length= df.SMILES.str.len())\n",
        "        df = df.sort_values(['frequency', 'length'], ascending= [False, True])\n",
        "        uni_fragments = df.SMILES.tolist()\n",
        "        freq_list = df.frequency.tolist()\n",
        "        uni_fragments = ['*'] + uni_fragments\n",
        "        fragments_list = [0] + freq_list\n",
        "    else:\n",
        "        freq_list = None\n",
        "\n",
        "    if not asFragments:\n",
        "        fragment_idxs = dict(zip(uni_fragments, range(len(uni_fragments))))\n",
        "        fragments_list = FragmentsToIndices(fragments_list, fragment_idxs)\n",
        "\n",
        "    return fragments_list, bondtypes_list, bondMapNums_list, recon_flag, uni_fragments, freq_list\n",
        "\n",
        "\n",
        "def debugMolToBRICSfragments(mol,\n",
        "                             useChiral: bool= True, ignore_double: bool= False,\n",
        "                             minFragSize: int= 1, maxFragNums: int= 50, maxDegree: int= 32):\n",
        "    recon = 1\n",
        "    iters = 0\n",
        "    max_iters = 30\n",
        "    try:\n",
        "        # decompose\n",
        "        s = Chem.MolToSmiles(mol) if mol is not None else None\n",
        "        Chem.FindMolChiralCenters(mol)  # assign chirality\n",
        "        hasChiral = bool(len(Chem.FindPotentialStereo(mol, flagPossible= False))) if useChiral else False\n",
        "        frags, bond_types, bondMapNums = MolToBRICSfragments(mol, minFragSize= minFragSize, maxDegree= maxDegree, useChiral= hasChiral, useStereo= ignore_double)\n",
        "        while (len(frags) > maxFragNums):\n",
        "            iters += 1\n",
        "            minFragSize += 1\n",
        "            frags, bond_types, bondMapNums = MolToBRICSfragments(mol, minFragSize= minFragSize, maxDegree= maxDegree, useChiral= hasChiral, useStereo= ignore_double)\n",
        "            # print(f\"{s} has over {maxFragNums} fragments. min_size:{minFragSize-1} -> {minFragSize}\", flush= True\n",
        "            if iters > max_iters:\n",
        "                raise ValueError(f'Over max iteration; {max_iters}. Remove it or increse max_nfrags.')\n",
        "\n",
        "        # reconstruct\n",
        "        adj = MapNumsToAdj(bondMapNums, bond_types)\n",
        "        s1 = Chem.MolToSmiles(mol, isomericSmiles= hasChiral)\n",
        "        s2 = Chem.MolToSmiles(MolFromFragments(frags, adj, asMol= True), isomericSmiles= hasChiral)\n",
        "        if (s1 != s2) & (s1 != standardize_smiles(s2)):\n",
        "            if hasChiral:\n",
        "                s1_dash = Chem.CanonSmiles(s1, useChiral= 0)\n",
        "                s2_dash = Chem.CanonSmiles(s2, useChiral= 0)\n",
        "                if (s1_dash == s2_dash) | (s1_dash == standardize_smiles(s2_dash)):\n",
        "                    recon = 2\n",
        "                    # print(f\"{s1}, {s2} is 3D unreconstructable.\", flush= True)\n",
        "                else:\n",
        "                    recon = 0\n",
        "                    print(f\"{s1_dash}, {s2_dash} is 2D unreconstructable.\", flush= True)\n",
        "            else:\n",
        "                recon = 0\n",
        "                print(f\"{s}, {s2} is unreconstructable.\", flush= True)\n",
        "        else:\n",
        "            recon = 3 if hasChiral else 1\n",
        "    except Exception as e:\n",
        "        recon = 0\n",
        "        print(f'{s} is an ERROR; {str(e)}', flush= True)\n",
        "\n",
        "    if recon == 0:\n",
        "        frags, bond_types, bondMapNums = None, None, None\n",
        "\n",
        "    return frags, bond_types, bondMapNums, recon\n",
        "\n",
        "\n",
        "def parallelMolsToBRICSfragments(mols: list,\n",
        "                                 useChiral: bool= True, ignore_double: bool= False,\n",
        "                                 minFragSize: int= 1, maxFragNums: int= 50, maxDegree: int= 32,\n",
        "                                 df_frag: pd.DataFrame= {}, asFragments: bool= False,\n",
        "                                 n_jobs: int= -1, verbose: int= 0):\n",
        "    # decompose mol\n",
        "    results = Parallel(n_jobs= n_jobs, verbose= verbose)(\n",
        "        delayed(debugMolToBRICSfragments)(mol, minFragSize= minFragSize, maxFragNums= maxFragNums, maxDegree= maxDegree, useChiral= useChiral, ignore_double= ignore_double) for mol in mols)\n",
        "    fragments_list, bondtypes_list, bondMapNums_list, recon_flag = zip(*results)\n",
        "    fragments_list, bondtypes_list, bondMapNums_list, recon_flag = list(fragments_list), list(bondtypes_list), list(bondMapNums_list), list(recon_flag)\n",
        "\n",
        "    # remove None\n",
        "    for _ in range(fragments_list.count(None)):\n",
        "        fragments_list.remove(None)\n",
        "        bondtypes_list.remove(None)\n",
        "        bondMapNums_list.remove(None)\n",
        "\n",
        "    # calculate frequency and Uniqueness\n",
        "    all_fragments = list(chain.from_iterable(fragments_list))\n",
        "    frag_freq = Counter(all_fragments)\n",
        "    uni_fragments, freq_list = map(list, zip(*frag_freq.items()))\n",
        "    df = pd.DataFrame({'SMILES': uni_fragments, 'frequency': freq_list})\n",
        "    df = df.assign(length= df.SMILES.str.len())\n",
        "    df = df.sort_values(['frequency', 'length'], ascending= [False, True])\n",
        "\n",
        "    # merge origin fragments list\n",
        "    if len(df_frag):\n",
        "        df = pd.concat([df_frag, df]).drop_duplicates(subset= 'SMILES', keep= 'first').reset_index(drop= True)\n",
        "        uni_fragments = df.SMILES.tolist()\n",
        "        freq_list = df.frequency.tolist()\n",
        "    else:\n",
        "        uni_fragments = df.SMILES.tolist()\n",
        "        freq_list = df.frequency.tolist()\n",
        "        uni_fragments = ['*'] + uni_fragments\n",
        "        freq_list = [0] + freq_list\n",
        "\n",
        "    # index\n",
        "    if not asFragments:\n",
        "        fragment_idxs = dict(zip(uni_fragments, range(len(uni_fragments))))\n",
        "        fragments_list = FragmentsToIndices(fragments_list, fragment_idxs, verbose= verbose)\n",
        "\n",
        "    return fragments_list, bondtypes_list, bondMapNums_list, recon_flag, uni_fragments, freq_list\n",
        "\n",
        "\n",
        "def _smilesToMorganFingarPrintsAsBitVect(smiles, radius: int, n_bits: int, useChiral: bool= True, ignore_dummy: bool= True):\n",
        "    ecfp = frag2ecfp(Chem.MolFromSmiles(smiles), radius, n_bits, useChiral= useChiral, ignore_dummy= ignore_dummy)\n",
        "    ecfp_bits = np.array(ecfp, dtype= int).tolist()\n",
        "\n",
        "    return ecfp, ecfp_bits\n",
        "\n",
        "\n",
        "def SmilesToMorganFingetPrints(fragments: list, n_bits: int, dupl_bits: int= 0, radius: int= 2,\n",
        "                               ignore_dummy: bool= True, useChiral: bool= True, n_jobs: int= 20):\n",
        "    \"\"\"\n",
        "    fragments: a list of fragment smiles.\n",
        "    distinct_ecfp: If fragments list includes same ecfp, add bits to distinguish ecfp.\n",
        "    \"\"\"\n",
        "    results = Parallel(n_jobs= n_jobs)(delayed(_smilesToMorganFingarPrintsAsBitVect)(f, radius, n_bits, useChiral= useChiral, ignore_dummy= ignore_dummy) for f in fragments)\n",
        "    ecfps, ecfp_list = map(list, zip(*results))\n",
        "\n",
        "    if dupl_bits > 0:\n",
        "        _, indices = np.unique(ecfp_list, axis= 0, return_index= True)\n",
        "        uni_ecfps = [ecfps[i] for i in indices]\n",
        "        dupl_idxs = []\n",
        "        for e in uni_ecfps:\n",
        "            dupl = np.where(np.array(DataStructs.BulkTanimotoSimilarity(e, ecfps)) == 1)[0]\n",
        "            if len(dupl) >= 2:\n",
        "                dupl_idxs.append(sorted(dupl.tolist()))\n",
        "\n",
        "        if len(dupl_idxs) != 0:\n",
        "            # add bits to ecfp\n",
        "            max_len = max(list(map(len, dupl_idxs)))\n",
        "            if max_len > 2**dupl_bits:\n",
        "                raise ValueError(f'the number of duplicated ecfp {max_len} is greater than 2**{dupl_bits}')\n",
        "            bits = [list(map(lambda x: int(x), list(f\"{i:0{dupl_bits}b}\"))) for i in range(max_len)]\n",
        "            distinct_ecfp_list = [ecfp_list + bits[0] for ecfp_list in ecfp_list]\n",
        "            for dupl in dupl_idxs:\n",
        "                for i, d in enumerate(dupl):\n",
        "                    distinct_ecfp_list[d] = distinct_ecfp_list[d][:-dupl_bits] + bits[i]\n",
        "            ecfp_list = distinct_ecfp_list\n",
        "        print(f'the number of duplicated ecfp is {len(dupl_idxs)}', flush= True)\n",
        "\n",
        "    return ecfp_list\n",
        "\n",
        "\n",
        "def IndicesToFeatures(indices_mols: list, features: list):\n",
        "    mol_features_list = []\n",
        "    for indices in indices_mols:\n",
        "        mol_features_list.append([features[i] for i in indices])\n",
        "\n",
        "    return mol_features_list\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    smi = '[2H]C([2H])([2H])c1ccnc2c1NC(=O)c1cccnc1N2C1CC1'\n",
        "    frag, bond, maps, recon = debugMolToBRICSfragments(Chem.MolFromSmiles(smi), ignore_double= False)\n",
        "    adj = MapNumsToAdj(maps, bond)\n",
        "    smi_rev = MolFromFragments(frag, adj)\n",
        "    print(smi)\n",
        "    print(smi_rev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n76hg4whTXt7"
      },
      "source": [
        "## scripts/utils/standardize_smiles.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3OKAJrQTd8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d95b25-b790-4a34-ab21-492a6c0a4352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded: /content/FRATTVAE/data/example.csv\n",
            "[BEFORE] 500\n",
            "[AFTER] 500\n",
            "removed:  0 (error: 0, dupl: 0, keep_dupls: True)\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import copy\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors, AllChem\n",
        "\n",
        "# import moses\n",
        "from molvs import  Standardizer\n",
        "\n",
        "\n",
        "# parser = argparse.ArgumentParser(description= 'please enter paths')\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--data_path', type= str, help= 'csv file', default=\"/content/FRATTVAE/data/example.csv\")\n",
        "parser.add_argument('--keep_dupls', action= 'store_true', default=True)\n",
        "parser.add_argument('--n_jobs', type= int, default= 24, help= 'the number of cpu for parallel, default 24')\n",
        "args, unknown = parser.parse_known_args()\n",
        "data_path = args.data_path\n",
        "df = pd.read_csv(data_path)\n",
        "if 'SMILES' not in df.columns:\n",
        "    raise ValueError('Please change the name of column smiles to \"SMILES\"')\n",
        "fname = data_path.rsplit('.csv')[0]\n",
        "print(f'loaded: {args.data_path}', flush= True)\n",
        "\n",
        "stand = Standardizer()\n",
        "\n",
        "def clearAtomMapNums(mol):\n",
        "    for atom in mol.GetAtoms():\n",
        "        atom.SetAtomMapNum(0)\n",
        "\n",
        "def standardize_and_metrics(smi):\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smi)\n",
        "        mol = copy.deepcopy(mol)\n",
        "        clearAtomMapNums(mol)\n",
        "        Chem.SanitizeMol(mol)\n",
        "        mol = Chem.RemoveHs(mol)\n",
        "        # mol = stand.disconnect_metals(mol)\n",
        "        mol = stand.normalize(mol)\n",
        "        mol = stand.reionize(mol)\n",
        "        # Chem.AssignStereochemistry(mol, force=True, cleanIt=True)\n",
        "        smi_std = Chem.MolToSmiles(mol)\n",
        "\n",
        "        natom = mol.GetNumAtoms()\n",
        "        # mw = moses.metrics.weight(mol)\n",
        "        # logP = moses.metrics.logP(mol)\n",
        "        # qed = moses.metrics.QED(mol)\n",
        "        # sa = moses.metrics.SA(mol)\n",
        "        # npl = moses.metrics.NP(mol)\n",
        "        tpsa = Chem.Descriptors.TPSA(mol)\n",
        "        ct = Descriptors.BertzCT(mol)\n",
        "    except:\n",
        "        mol = smi_std = None\n",
        "        # natom = mw = logP = qed = sa = npl = tpsa = ct =  None\n",
        "        natom = tpsa = ct =  None\n",
        "\n",
        "    if smi_std is None:\n",
        "        print('none', flush= True)\n",
        "\n",
        "    # return smi, smi_std, natom, mw, logP, qed, sa, npl, tpsa, ct\n",
        "    return smi, smi_std, natom, tpsa, ct\n",
        "\n",
        "# standardize\n",
        "results = Parallel(n_jobs= args.n_jobs)(delayed(standardize_and_metrics)(s) for s in df.SMILES)\n",
        "# smiles, smiles_std, natoms_list, mw_list, logP_list, qed_list, sa_list, npl_list, tpsa_list, ct_list = map(list, zip(*results))\n",
        "smiles, smiles_std, natoms_list, tpsa_list, ct_list = map(list, zip(*results))\n",
        "\n",
        "# train-test split\n",
        "assert len(df) == len(smiles_std)\n",
        "try:\n",
        "    test = df.test.tolist()\n",
        "except:\n",
        "    random.seed(0)\n",
        "    test = random.choices([0, 1, -1], k= len(df), weights= [0.90, 0.05, 0.05])\n",
        "    print('random train-valid-test split. train:valid:test= 0.90:0.05:0.05', flush= True)\n",
        "\n",
        "# add columns\n",
        "df['SMILES'] = smiles_std\n",
        "df['test'] = test\n",
        "# df_tmp = pd.DataFrame({'natoms': natoms_list, 'MW': mw_list, 'logP': logP_list, 'QED': qed_list,\n",
        "#                        'SA': sa_list, 'NP': npl_list, 'TPSA': tpsa_list, 'BertzCT': ct_list})\n",
        "\n",
        "df_tmp = pd.DataFrame({'natoms': natoms_list, 'TPSA': tpsa_list, 'BertzCT': ct_list})\n",
        "df_new = pd.concat([df, df_tmp], axis= 1)\n",
        "\n",
        "# remove errors\n",
        "df_error = df_new.loc[df_new['SMILES'].isnull()]\n",
        "n_errors = len(df_error)\n",
        "df_new = df_new.loc[~df_new['SMILES'].isnull()].reset_index(drop= True)\n",
        "\n",
        "# check duplications\n",
        "dupls = df_new.duplicated(subset= 'SMILES', keep= 'first')\n",
        "n_dupls = sum(dupls)\n",
        "if not args.keep_dupls:\n",
        "    df_error = pd.concat([df_error, df_new.loc[dupls]])\n",
        "    df_new = df_new.loc[~dupls].reset_index(drop= True)\n",
        "\n",
        "# save\n",
        "df_new.to_csv(f'{fname}_standardized.csv', index= False)\n",
        "if len(df_error) > 0:\n",
        "    df_error.to_csv(f'{fname}_removed.csv', index= False)\n",
        "\n",
        "# output\n",
        "with open(f'{fname}_stats.txt', 'a') as f:\n",
        "    for col in df_tmp.columns:\n",
        "        f.write(f'-{col}: {np.nanmean(df_tmp[col]):.4f}±{np.nanstd(df_tmp[col]):.4f} ({np.nanmin(df_tmp[col]):.4f}-{np.nanmax(df_tmp[col]):.4f})')\n",
        "\n",
        "print(f'[BEFORE] {len(df)}', flush= True)\n",
        "print(f'[AFTER] {len(df_new)}', flush= True)\n",
        "print(f'removed:  {len(df_error)} (error: {n_errors}, dupl: {n_dupls}, keep_dupls: {args.keep_dupls})', flush= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqdnvtbLo-UM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f22df2-5ea0-4567-f640-a65a588283bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DGL backend set to: pytorch\n"
          ]
        }
      ],
      "source": [
        "# Set the DGLBACKEND environment variable to 'pytorch'\n",
        "os.environ['DGLBACKEND'] = 'pytorch'\n",
        "\n",
        "# (Optional) Verify the setting\n",
        "print(f\"DGL backend set to: {os.environ.get('DGLBACKEND')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch5XYzWUTlQN"
      },
      "source": [
        "## scripts/utils/tree.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKABnuwxTn-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2122e9b8-29e5-4761-b329-407e373ad779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.FragmentTree object at 0x789a6cbbdd50>\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import dgl\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"Recommend creating\")\n",
        "\n",
        "\"\"\"\n",
        "Reference: https://github.com/microsoft/icecaps/blob/master/icecaps/util/trees.py\n",
        "           https://github.com/inyukwo1/tree-lstm/blob/master/tree_lstm/tree_lstm.py (2023/07/07)\n",
        "\"\"\"\n",
        "\n",
        "class FragmentTree:\n",
        "    def __init__(self, dgl_graph= None):\n",
        "        self.dgl_graph = dgl_graph if dgl_graph else dgl.DGLGraph()\n",
        "        self.max_depth = 0\n",
        "        self.max_degree = 0\n",
        "\n",
        "    def add_node(self, parent_id=None, feature: torch.Tensor = torch.Tensor(), fid: int= -1, bondtype: int= 1, data: dict= None):\n",
        "        if data is None:\n",
        "            data = {'x': feature.unsqueeze(0),\n",
        "                    'fid': torch.tensor([fid]).unsqueeze(0)}\n",
        "        self.dgl_graph.add_nodes(1, data= data)\n",
        "        added_node_id = self.dgl_graph.number_of_nodes() - 1\n",
        "\n",
        "        if parent_id is not None:\n",
        "            self.dgl_graph.ndata['level'][added_node_id] = self.dgl_graph.ndata['level'][parent_id] + 1\n",
        "            self.dgl_graph.add_edges(added_node_id, parent_id, data= {'w': torch.tensor([bondtype]).unsqueeze(0)})\n",
        "            self.max_degree = max(self.max_degree, len(self.dgl_graph.predecessors(parent_id)))\n",
        "        elif added_node_id > 0:\n",
        "            self.dgl_graph.ndata['level'][added_node_id] = torch.tensor([0]).int()\n",
        "        else:\n",
        "            self.dgl_graph.ndata['level'] = torch.tensor([0]).int()\n",
        "\n",
        "        self.max_depth = self.dgl_graph.ndata['level'].max().item()\n",
        "        # self.max_width = max([self.width(level) for level in range(self.max_depth+1)]).item()\n",
        "\n",
        "        return added_node_id\n",
        "\n",
        "    def add_link(self, child_id, parent_id, bondtype: int= 1):\n",
        "        self.dgl_graph.add_edges(child_id, parent_id, data= {'w': torch.tensor([bondtype]).unsqueeze(0)})\n",
        "\n",
        "    def remove_node(self, node_id: int):\n",
        "        self.dgl_graph.remove_nodes(node_id)\n",
        "\n",
        "    def remove_edge(self, edge_id: int):\n",
        "        self.dgl_graph.remove_edges(edge_id)\n",
        "\n",
        "    def adjacency_matrix(self):\n",
        "        n_node = self.dgl_graph.num_nodes()\n",
        "        if n_node < 2:\n",
        "            adj = torch.tensor([[0]])\n",
        "        else:\n",
        "            indices = torch.stack(self.dgl_graph.all_edges())\n",
        "            values = self.dgl_graph.edata['w'].squeeze()\n",
        "            adj = torch.sparse_coo_tensor(indices, values, size= (n_node, n_node)).to_dense()\n",
        "\n",
        "        return adj\n",
        "\n",
        "    def to(self, device: str= 'cpu'):\n",
        "        self.dgl_graph = self.dgl_graph.to(device)\n",
        "        return self\n",
        "\n",
        "    def reverse(self):\n",
        "        self.dgl_graph = dgl.reverse(self.dgl_graph, copy_ndata= True, copy_edata= True)\n",
        "        return self\n",
        "\n",
        "    def set_all_positional_encoding(self, d_pos: int= None, n: int= None):\n",
        "        \"\"\"\n",
        "        if n is not None, encoding as all nodes have n children.\n",
        "        \"\"\"\n",
        "        d_pos = d_pos if d_pos else self.max_depth * self.max_degree\n",
        "        self.dgl_graph.ndata['pos'] = torch.zeros(self.dgl_graph.num_nodes(), d_pos)\n",
        "        for nid in self.dgl_graph.nodes()[1:]:\n",
        "            parent = self.dgl_graph.successors(nid)\n",
        "            if len(parent) > 0:\n",
        "                parent = parent[0]\n",
        "            else:\n",
        "                continue\n",
        "            children = self.dgl_graph.predecessors(parent).tolist()\n",
        "\n",
        "            n = n if n else len(children)\n",
        "            assert n >= len(children)\n",
        "            positional_encoding = [0.0 for _ in range(n)]\n",
        "            positional_encoding[children.index(nid)] = 1.0\n",
        "            positional_encoding += self.dgl_graph.ndata['pos'][parent].tolist()\n",
        "\n",
        "            self.dgl_graph.ndata['pos'][nid] = torch.tensor(positional_encoding)[:d_pos]\n",
        "\n",
        "    def set_positional_encoding(self, nid: int, num_sibling: int= None, d_pos: int= None):\n",
        "        d_pos = d_pos if d_pos else self.max_depth * self.max_degree\n",
        "\n",
        "        parents = self.dgl_graph.successors(nid)\n",
        "        if len(parents) == 0:\n",
        "            self.dgl_graph.ndata['pos'] = torch.zeros(self.dgl_graph.num_nodes(), d_pos)\n",
        "            positional_encoding = [0.0] * d_pos\n",
        "        else:\n",
        "            parent = parents[0]\n",
        "            sibling = self.dgl_graph.predecessors(parent).tolist()\n",
        "            num_sibling = num_sibling if num_sibling is not None else len(sibling)\n",
        "            assert num_sibling >= len(sibling)\n",
        "\n",
        "            positional_encoding = [0.0 for _ in range(num_sibling)]\n",
        "            positional_encoding[sibling.index(nid)] = 1.0\n",
        "            positional_encoding += self.dgl_graph.ndata['pos'][parent].tolist()\n",
        "\n",
        "        self.dgl_graph.ndata['pos'][nid] = torch.tensor(positional_encoding)[:d_pos]\n",
        "\n",
        "    def width(self, level: int):\n",
        "        return (self.dgl_graph.ndata['level'] == level).sum()\n",
        "\n",
        "\n",
        "class BatchedFragmentTree:\n",
        "    def __init__(self, tree_list, max_depth: int= None, max_degree: int= None):\n",
        "        graph_list = []\n",
        "        depth_list, degree_list = zip(*[(tree.max_depth, tree.max_degree) for tree in tree_list])\n",
        "        if (max_depth is None) | (max_degree is None):\n",
        "            self.max_depth = max(depth_list)\n",
        "            self.max_degree = max(degree_list)\n",
        "        else:\n",
        "            if (max_depth < max(depth_list)) | (max_degree < max(degree_list)):\n",
        "                print(f'[WARNING] max depth:{max_depth} < {max(depth_list)} or max degree:{max_degree} < {max(degree_list)}', flush= True)\n",
        "            self.max_depth = max_depth\n",
        "            self.max_degree = max_degree\n",
        "\n",
        "        for tree in tree_list:\n",
        "            tree.set_all_positional_encoding(d_pos= self.max_depth * self.max_degree)\n",
        "            graph_list.append(tree.dgl_graph)\n",
        "        self.batch_dgl_graph = dgl.batch(graph_list)\n",
        "\n",
        "    def get_ndata(self, key: str, node_ids: list= None, pad_value: int= 0):\n",
        "        graph_list = dgl.unbatch(self.batch_dgl_graph)\n",
        "        ndatas = []\n",
        "        max_nodes_num = max([graph.num_nodes() for graph in graph_list])\n",
        "        for i, graph in enumerate(graph_list):\n",
        "            if node_ids:\n",
        "                node_id = node_ids[i] if i < len(node_ids) else node_ids[0]\n",
        "                states = graph.ndata[key][node_id]\n",
        "            else:\n",
        "                states = graph.ndata[key]\n",
        "                node_num, state_num = states.size()\n",
        "                if len(states) < max_nodes_num:\n",
        "                    padding = states.new_full((max_nodes_num - node_num, state_num), pad_value)\n",
        "                    states = torch.cat((states, padding), dim=0)\n",
        "            ndatas.append(states)\n",
        "        return torch.stack(ndatas)\n",
        "\n",
        "    def get_edata(self, key: str= 'w', edge_ids: list= None, pad_value: int= 0):\n",
        "        graph_list = dgl.unbatch(self.batch_dgl_graph)\n",
        "        edatas = []\n",
        "        max_edges_num = max([graph.num_edges() for graph in graph_list])\n",
        "        for i, graph in enumerate(graph_list):\n",
        "            if edge_ids:\n",
        "                edge_id = edge_ids[i] if i < len(edge_ids) else edge_ids[0]\n",
        "                states = graph.edata[key][edge_id]\n",
        "            else:\n",
        "                states = graph.edata[key]\n",
        "                edge_num, state_num = states.size()\n",
        "                if len(states) < max_edges_num:\n",
        "                    padding = states.new_full((max_edges_num - edge_num, state_num), pad_value)\n",
        "                    states = torch.cat((states, padding), dim=0)\n",
        "            edatas.append(states)\n",
        "        return torch.stack(edatas)\n",
        "\n",
        "    def get_tree_list(self):\n",
        "        graph_list = dgl.unbatch(self.batch_dgl_graph)\n",
        "        return [FragmentTree(dgl_graph= graph) for graph in graph_list]\n",
        "\n",
        "    def to(self, device: str= 'cpu'):\n",
        "        self.batch_dgl_graph = self.batch_dgl_graph.to(device)\n",
        "        return self\n",
        "\n",
        "    def reverse(self):\n",
        "        reverse_graph_list = [dgl.reverse(g, copy_ndata= True, copy_edata= True) for g in dgl.unbatch(self.batch_dgl_graph)]\n",
        "        self.batch_dgl_graph = dgl.batch(reverse_graph_list)\n",
        "\n",
        "        return self\n",
        "\n",
        "\n",
        "def make_tree(frag_indices: list, ecfps: torch.Tensor, bond_types: list, bondMapNums: list, d_pos: int= None) -> FragmentTree:\n",
        "    \"\"\"\n",
        "    frag_indices: a list of fragments indices\n",
        "    ecfps: ecfps of fragments, shape= (len(frag_indices), n_bits)\n",
        "    bond_types: a list of bondtype (1: single, 2: double, 3: triple)\n",
        "    bondMapNums: a list of connection order lists.\n",
        "                 ex. [[1], [1, 2], [2]] -> first connect frag0 and 1, next frag1 and 2.\n",
        "    d_pos: dimension of positional encoding\n",
        "    \"\"\"\n",
        "    if type(ecfps) == list:\n",
        "        ecfps = torch.tensor(ecfps).float()\n",
        "\n",
        "    tree = FragmentTree()\n",
        "    tree.add_node(parent_id= None, feature= ecfps[0], fid= frag_indices[0], bondtype= 0)\n",
        "\n",
        "    stack = [0]\n",
        "    node_ids = [0] * len(frag_indices)\n",
        "    while max(map(len, bondMapNums)) > 0:\n",
        "        if stack:\n",
        "            parent = stack[-1]\n",
        "            pid = node_ids[parent]\n",
        "            if bondMapNums[parent]:\n",
        "                b = bondMapNums[parent].pop(0)\n",
        "            else:\n",
        "                stack.pop(-1)\n",
        "                continue\n",
        "        else:\n",
        "            # accept partial trees\n",
        "            idx = [i for i in range(len(frag_indices)) if len(bondMapNums[i]) > 0][0]\n",
        "            stack.append(idx)\n",
        "            add_node_id = tree.add_node(parent_id= None, feature= ecfps[idx], fid= frag_indices[idx], bondtype= 0)\n",
        "            node_ids[idx] = add_node_id\n",
        "            continue\n",
        "\n",
        "        child_list = [b in mapnums for mapnums in bondMapNums]\n",
        "        if np.any(child_list):\n",
        "            c = child_list.index(True)\n",
        "            add_node_id = tree.add_node(parent_id= pid, feature= ecfps[c], fid= frag_indices[c], bondtype= bond_types[b-1])\n",
        "            node_ids[c] = add_node_id\n",
        "            stack.append(c)\n",
        "\n",
        "    if d_pos:\n",
        "        tree.set_all_positional_encoding(d_pos)\n",
        "\n",
        "    return tree\n",
        "\n",
        "\n",
        "def get_tree_features(frag_indices: list, ecfps: torch.Tensor, bond_types: list, bondMapNums: list,\n",
        "                      max_depth: int= None, max_degree: int= None, free_n: bool= False):\n",
        "    tree = make_tree(frag_indices, ecfps, bond_types, bondMapNums)\n",
        "\n",
        "    max_depth = max_depth if max_depth else tree.max_depth\n",
        "    max_degree = max_degree if max_degree else tree.max_degree\n",
        "\n",
        "    if (max_depth < tree.max_depth) | (max_degree < tree.max_degree):\n",
        "        print(f'[WARNING] max depth:{max_depth} < {tree.max_depth} or max degree:{max_degree} < {tree.max_degree}', flush= True)\n",
        "\n",
        "    n = None if free_n else max_degree\n",
        "    tree.set_all_positional_encoding(d_pos= max_depth * max_degree, n= n)\n",
        "    fids = tree.dgl_graph.ndata['fid'].squeeze(-1)\n",
        "    positions = tree.dgl_graph.ndata['pos']\n",
        "    features = tree.dgl_graph.ndata['x']\n",
        "\n",
        "    return fids, features, positions\n",
        "\n",
        "\n",
        "def get_pad_features(tree_list, key: str, max_nodes_num: int):\n",
        "    ndatas = []\n",
        "    for tree in tree_list:\n",
        "        states = tree.dgl_graph.ndata[key]\n",
        "        node_num, state_num = states.size()\n",
        "        if len(states) < max_nodes_num:\n",
        "            padding = states.new_full((max_nodes_num - node_num, state_num), 0)\n",
        "            states = torch.cat((states, padding), dim=0)\n",
        "        ndatas.append(states)\n",
        "    return torch.stack(ndatas)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    frag_indice = [0, 1, 2, 3]\n",
        "    ecfps = torch.ones(4, 12).float()\n",
        "    bondtypes = [1, 1, 1]\n",
        "    bondMapNum = [[1], [1, 2], [2, 3]]\n",
        "\n",
        "    tree = make_tree(frag_indice, ecfps, bondtypes, bondMapNum, d_pos= 16)\n",
        "    print(tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq6ECyuCRfdK"
      },
      "source": [
        "## scripts/models/frattvae.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwO__vVJRNqL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# from utils.tree import FragmentTree, get_pad_features\n",
        "# from utils.mask import generate_square_subsequent_mask\n",
        "# from utils.construct import constructMol, constructMolwithTimeout\n",
        "\n",
        "\n",
        "class TreePositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Reference: https://github.com/microsoft/icecaps/blob/master/icecaps/estimators/abstract_transformer_estimator.py\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model: int, d_pos: int, depth: int, width: int) -> None:\n",
        "        super().__init__()\n",
        "        self.d_params = d_pos // (depth * width)\n",
        "        self.d_model = d_model\n",
        "        self.depth = depth\n",
        "        self.width = width\n",
        "        self.params = nn.Parameter(torch.randn(self.d_params), requires_grad= True)\n",
        "        self.fc = nn.Linear(self.d_params * self.depth * self.width, d_model)\n",
        "\n",
        "        # initialization\n",
        "        self.tree_weights = None\n",
        "\n",
        "    def forward(self, positions: torch.Tensor):\n",
        "        \"\"\"\n",
        "        positions: shape= (Batch_size, Length, depth * width)\n",
        "        \"\"\"\n",
        "        if self.training | (self.tree_weights is None):\n",
        "            self._update_weights()\n",
        "        treeified = positions.unsqueeze(-1) * self.tree_weights.to(positions.device)     # (B, L, depth*width, d_param)\n",
        "        treeified = treeified.flatten(start_dim= 2)                                      # (B, L, depth*width*d_param = d_pos)\n",
        "        if treeified.shape[-1] != self.d_model:\n",
        "            treeified = self.fc(treeified)\n",
        "\n",
        "        return treeified\n",
        "\n",
        "    def _update_weights(self):\n",
        "        params = torch.tanh(self.params)\n",
        "        tiled_tree_params = params.view(1, 1, -1).repeat(self.depth, self.width, 1)\n",
        "        tiled_depths = torch.arange(self.depth, dtype=torch.float32, device= params.device).view(-1, 1, 1).repeat(1, self.width, self.d_params)\n",
        "        tree_norm = torch.sqrt((1 - params.square()) * self.d_model / 2)\n",
        "        self.tree_weights = (tiled_tree_params ** tiled_depths) * tree_norm\n",
        "        self.tree_weights = self.tree_weights.view(self.depth * self.width, self.d_params)\n",
        "\n",
        "\n",
        "class FRATTVAE(nn.Module):\n",
        "    def __init__(self, num_tokens: int, depth: int, width: int,\n",
        "                 feat_dim: int= 2048, latent_dim: int= 256,\n",
        "                 d_model: int= 512, d_ff: int= 2048, num_layers: int= 6, nhead: int= 8,\n",
        "                 activation: str= 'gelu', dropout: float= 0.1, n_jobs: int= 4) -> None:\n",
        "        super().__init__()\n",
        "        assert activation in ['relu', 'gelu']\n",
        "        self.d_model = d_model\n",
        "        self.latent_dim = latent_dim\n",
        "        self.dropout = dropout\n",
        "        self.depth = depth\n",
        "        self.width = width\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "        self.embed = nn.Embedding(num_embeddings= 1, embedding_dim= d_model)      # <root>\n",
        "        self.fc_ecfp = nn.Sequential(nn.Linear(feat_dim, feat_dim//2),\n",
        "                                     nn.Linear(feat_dim//2, d_model))\n",
        "        self.PE = TreePositionalEncoding(d_model= d_model, d_pos= max(d_model, depth*width), depth= depth, width= width)\n",
        "\n",
        "        # transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model= d_model, nhead= nhead, dim_feedforward= d_ff,\n",
        "                                                   dropout= self.dropout, activation= activation, batch_first= True)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers= num_layers)\n",
        "\n",
        "        # vae\n",
        "        self.fc_vae = nn.Sequential(nn.Linear(d_model, latent_dim),\n",
        "                                    nn.Linear(latent_dim, 2*latent_dim))\n",
        "\n",
        "        # transformer decoder\n",
        "        self.fc_memory = nn.Linear(latent_dim, d_model)\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model= d_model, nhead= nhead, dim_feedforward= d_ff,\n",
        "                                                   dropout= self.dropout, activation= activation, batch_first= True)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers= num_layers)\n",
        "        self.fc_dec = nn.Linear(d_model, num_tokens)\n",
        "\n",
        "        # for decode smiles\n",
        "        self.labels = None\n",
        "\n",
        "    def forward(self, features: torch.Tensor, positions: torch.Tensor,\n",
        "                src_mask: torch.Tensor= None, src_pad_mask: torch.Tensor= None,\n",
        "                tgt_mask: torch.Tensor= None, tgt_pad_mask: torch.Tensor= None,\n",
        "                frag_ecfps: torch.Tensor= None, ndummys: torch.Tensor= None,\n",
        "                max_nfrags: int= 20, free_n: bool= False, sequential: bool= None, conditions: torch.Tensor= None):\n",
        "        \"\"\"\n",
        "        encode and decode\n",
        "        Decode in parallel when training process.\n",
        "        \"\"\"\n",
        "        sequential = not self.training if sequential is None else sequential\n",
        "\n",
        "        z, mu, ln_var = self.encode(features, positions, src_mask, src_pad_mask, conditions)\n",
        "        if sequential:\n",
        "            output = self.sequential_decode(z, frag_ecfps, ndummys, conditions= conditions, max_nfrags= max_nfrags, free_n= free_n)\n",
        "        else:\n",
        "            output = self.decode(z, features, positions, tgt_mask, tgt_pad_mask, conditions)\n",
        "\n",
        "        return z, mu, ln_var, output\n",
        "\n",
        "\n",
        "    def encode(self, features: torch.Tensor, positions: torch.Tensor,\n",
        "               src_mask: torch.Tensor= None, src_pad_mask: torch.Tensor= None, conditions: torch.Tensor= None):\n",
        "        \"\"\"\n",
        "        features: shape= (Batch_size, Length, feat_dim)\n",
        "        positions: shape= (Batch_size, Length, depth * width)\n",
        "        condtions: shape= (Batch_size, num_conditions, d_model) if conditional vae.\n",
        "        src_mask: source mask for masked attention, shape= (Length+num_conditions+1, Length+num_conditions+1)\n",
        "        src_pad_mask: shape = (Batch_size, Length+num_conditions+1)\n",
        "        \"\"\"\n",
        "        num_conditions = conditions.shape[1] if conditions is not None else 0\n",
        "\n",
        "        # positional embbeding\n",
        "        src = self.fc_ecfp(features) + self.PE(positions)           # (B, L, d_model),  * math.sqrt(self.d_model)?\n",
        "\n",
        "        # attach super root\n",
        "        root_embed = self.embed(src.new_zeros(src.shape[0], 1).long())\n",
        "        if num_conditions > 0:\n",
        "            src = torch.cat([conditions, root_embed, src], dim= 1)  # (B, L+num_conditions+1, d_model)\n",
        "        else:\n",
        "            src = torch.cat([root_embed, src], dim= 1)              # (B, L+1, d_model)\n",
        "\n",
        "        # transformer encoding\n",
        "        out = self.encoder(src, mask= src_mask, src_key_padding_mask= src_pad_mask)\n",
        "        out = out[:, num_conditions, :].squeeze(1)\n",
        "\n",
        "        # vae\n",
        "        mu, ln_var = self.fc_vae(out).chunk(2, dim= -1)\n",
        "        z = self.reparameterization_trick(mu, ln_var)               # (B, latent_dim)\n",
        "\n",
        "        return z, mu, ln_var\n",
        "\n",
        "\n",
        "    def decode(self, z: torch.Tensor, features: torch.Tensor, positions: torch.Tensor,\n",
        "               tgt_mask: torch.Tensor= None, tgt_pad_mask: torch.Tensor= None, conditions: torch.Tensor= None):\n",
        "        \"\"\"\n",
        "        z: encoder output. shape= (Batch_size, latent_dim)\n",
        "        features: shape= (Batch_size, Length, feat_dim)\n",
        "        positions: shape= (Batch_size, Length, depth * width)\n",
        "        condtions: shape= (Batch_size, num_conditions, d_model) if conditional vae.\n",
        "        tgt_mask: target mask for masked attention, shape= (Length+1, Length+1)\n",
        "        tgt_pad_mask: target mask for padding, shape= (Batch_size, Length+1)\n",
        "\n",
        "        output: logits of label preditions, shape= (Batch_size, Length+1, num_labels)\n",
        "        \"\"\"\n",
        "        num_conditions = conditions.shape[1] if conditions is not None else 0\n",
        "\n",
        "        # latent variable to memory\n",
        "        memory = self.fc_memory(z).unsqueeze(1)                     # (B, 1, d_model)\n",
        "\n",
        "        # postional embedding\n",
        "        tgt = self.fc_ecfp(features) + self.PE(positions)           # (B, L, d_model)\n",
        "\n",
        "        # attach supur root\n",
        "        root_embed = self.embed(tgt.new_zeros(tgt.shape[0], 1).long())\n",
        "        if num_conditions > 0:\n",
        "            tgt = torch.cat([conditions, root_embed, tgt], dim= 1)  # (B, L+num_conditions+1, d_model)\n",
        "        else:\n",
        "            tgt = torch.cat([root_embed, tgt], dim= 1)              # (B, L+1, d_model)\n",
        "\n",
        "        # transformer decoding\n",
        "        out = self.decoder(tgt, memory, tgt_mask= tgt_mask, tgt_key_padding_mask= tgt_pad_mask)\n",
        "        out = self.fc_dec(out[:, num_conditions:])                  # (B, L+1, num_tokens)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def sequential_decode(self, z: torch.Tensor, frag_ecfps: torch.Tensor, ndummys: torch.Tensor,\n",
        "                          max_nfrags: int= 30, free_n: bool= False, asSmiles: bool= False, conditions: torch.Tensor= None) -> list:\n",
        "        \"\"\"\n",
        "        z: latent variable. shape= (Batch_size, latent_dim)\n",
        "        frag_ecfps: fragment ecfps. shape= (num_labels, feat_dim)\n",
        "        ndummys: The degree of a fragment means how many children it has. shape= (num_labels, )\n",
        "        max_nfrags: the maximum number of fragments\n",
        "        free_n: if False, tree positional encoding as all nodes have n children.\n",
        "\n",
        "        output: list of fragment tree\n",
        "        \"\"\"\n",
        "        batch_size = z.shape[0]\n",
        "        device = z.device\n",
        "        num_conditions = conditions.shape[1] if conditions is not None else 0\n",
        "\n",
        "        # latent variabel to memory\n",
        "        memory = self.fc_memory(z).unsqueeze(1)\n",
        "\n",
        "        # root prediction\n",
        "        root_embed = self.embed(torch.zeros(batch_size, 1, device= device).long())\n",
        "        if num_conditions > 0:\n",
        "            root_embed = torch.cat([conditions, root_embed], dim= 1)    # (B, num_conditions+1, d_model)\n",
        "        tgt_pad_mask = torch.all(root_embed==0, dim= -1).to(device)     # (B, num_conditions+1)\n",
        "        out = self.decoder(root_embed, memory, tgt_key_padding_mask= tgt_pad_mask)\n",
        "        out = self.fc_dec(out[:, num_conditions:])\n",
        "        root_idxs = out.argmax(dim= -1).flatten()      # (B, )\n",
        "        # out = out.argsort(dim= -1, descending= True).squeeze(1)\n",
        "        # root_idxs = torch.where(out[:,0]!=0, out[:,0], out[:,1])    # (B, )\n",
        "\n",
        "        continues = []\n",
        "        target_ids = [0] * batch_size\n",
        "        target_ids_list = [[0] for _ in range(batch_size)]\n",
        "        tree_list = [FragmentTree() for _ in range(batch_size)]\n",
        "        for i, idx in enumerate(root_idxs):\n",
        "            parent_id = tree_list[i].add_node(parent_id= None, feature= frag_ecfps[idx], fid= idx.item(), bondtype= 0)\n",
        "            assert parent_id == 0\n",
        "            tree_list[i].set_positional_encoding(parent_id, d_pos= self.depth * self.width)\n",
        "            continues.append(ndummys[idx].item() > 0)\n",
        "\n",
        "        nfrags = 1\n",
        "        while (nfrags < max_nfrags) & (sum(continues) > 0):\n",
        "            # features\n",
        "            tgt_mask = generate_square_subsequent_mask(length= nfrags+num_conditions+1).to(device)\n",
        "            tgt_mask[:, :num_conditions+1] = 0      # no sequence mask of conditions\n",
        "            tgt_pad_mask = torch.hstack([tgt_pad_mask, tgt_pad_mask.new_full(size= (batch_size, 1), fill_value= False)])\n",
        "            features = get_pad_features(tree_list, key= 'x', max_nodes_num= nfrags).to(device)\n",
        "            positions = get_pad_features(tree_list, key= 'pos', max_nodes_num= nfrags).to(device)\n",
        "            assert features.shape[0] == positions.shape[0]\n",
        "\n",
        "            # forward\n",
        "            tgt = self.fc_ecfp(features) + self.PE(positions)\n",
        "            tgt = torch.cat([root_embed, tgt], dim= 1)          # (B, nfrags+num_conditions+1, d_model)\n",
        "\n",
        "            out = self.decoder(tgt, memory, tgt_mask= tgt_mask, tgt_key_padding_mask= tgt_pad_mask)\n",
        "            out = self.fc_dec(out[:, num_conditions:])              # (B, nfrags+1, num_labels)\n",
        "\n",
        "            new_idxs = out[:, -1, :].argmax(dim= -1).flatten()      # (B,)\n",
        "\n",
        "            # add node\n",
        "            for i, idx in enumerate(new_idxs):\n",
        "                if continues[i]:\n",
        "                    if ndummys[idx] == 0:   # don't generate salt compounds.\n",
        "                        idx = torch.tensor(0)\n",
        "                    if idx != 0:\n",
        "                        parent_id = target_ids[i]\n",
        "                        add_node_id = tree_list[i].add_node(parent_id= parent_id, feature= frag_ecfps[idx], fid= idx.item(), bondtype= 1)\n",
        "                        parent_fid = tree_list[i].dgl_graph.ndata['fid'][parent_id].item()\n",
        "                        num_sibling = ndummys[parent_fid].item() - 1 if parent_id > 0 else ndummys[parent_fid].item()\n",
        "                        if free_n:\n",
        "                            tree_list[i].set_positional_encoding(add_node_id, num_sibling= num_sibling, d_pos= self.depth * self.width)\n",
        "                        else:\n",
        "                            tree_list[i].set_positional_encoding(add_node_id, num_sibling= self.width, d_pos= self.depth * self.width)\n",
        "                        level = tree_list[i].dgl_graph.ndata['level'][add_node_id].item()\n",
        "\n",
        "                        # compare the current number of siblings with the ideal number of siblings\n",
        "                        if (len(tree_list[i].dgl_graph.predecessors(parent_id)) >= num_sibling):\n",
        "                            target_ids_list[i].pop(-1)\n",
        "\n",
        "                        # whether the node has children\n",
        "                        if (ndummys[idx] > 1) & (self.depth > level):\n",
        "                            target_ids_list[i].append(add_node_id)\n",
        "\n",
        "                    continues[i] = bool(target_ids_list[i]) if (idx != 0) else False\n",
        "                    target_ids[i] = target_ids_list[i][-1] if continues[i] else 0\n",
        "            nfrags += 1\n",
        "\n",
        "        if asSmiles:\n",
        "            if self.labels is not None:\n",
        "                # outputs = [constructMol(self.labels[tree.dgl_graph.ndata['fid'].squeeze(-1).tolist()], tree.adjacency_matrix().tolist()) for tree in tree_list]\n",
        "                outputs = Parallel(n_jobs= self.n_jobs)(delayed(constructMol)(self.labels[tree.dgl_graph.ndata['fid'].squeeze(-1).tolist()], tree.adjacency_matrix().tolist()) for tree in tree_list)\n",
        "                # outputs = Parallel(n_jobs= self.n_jobs, backend='threading')(delayed(constructMolwithTimeout)(self.labels[tree.dgl_graph.ndata['fid'].squeeze(-1).tolist()], tree.adjacency_matrix().tolist()) for tree in tree_list)\n",
        "            else:\n",
        "                raise ValueError('If asSmiles= True, please set labels. exaple; self.set_labels(labels)')\n",
        "        else:\n",
        "            outputs = tree_list\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def reparameterization_trick(self, mu, ln_var):\n",
        "        eps = torch.randn_like(mu)\n",
        "        z = mu + torch.exp(ln_var / 2) * eps if self.training else mu\n",
        "\n",
        "        return z\n",
        "\n",
        "    def set_labels(self, labels):\n",
        "        if type(labels) == np.ndarray:\n",
        "            self.labels = labels\n",
        "        else:\n",
        "            self.labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpo1Pm03RlY6"
      },
      "source": [
        "## scripts/models/property.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsBCxNeXRsLC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class propLinear(nn.Module):\n",
        "    def __init__(self, input_dim: int, output_dim: int, hidden_dim: int= 64) -> None:\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, z: torch.tensor):\n",
        "        return self.linear2(self.linear1(z))\n",
        "\n",
        "\n",
        "class propRank(nn.Module):\n",
        "    def __init__(self, input_dim: int, output_dim: int) -> None:\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(input_dim, 64)\n",
        "        self.linear2 = nn.Linear(64, output_dim)\n",
        "        self.sm = nn.Softmax(dim= 1)\n",
        "\n",
        "    def forward(self, z: torch.tensor):\n",
        "        x = self.linear2(self.linear1(z))\n",
        "        return self.sm(x)\n",
        "\n",
        "\n",
        "class PairWiseLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.sp = nn.Softplus()\n",
        "\n",
        "    def forward(self, s1: float, s2: float, t: float):\n",
        "        # t = 1 if x1 > x2\n",
        "        #     0 if x2 > x1\n",
        "        #     0.5 otherwise\n",
        "        o = s1 - s2\n",
        "        return torch.mean(-t * o + self.sp(o))\n",
        "\n",
        "\n",
        "PROPMDL = {\n",
        "    'linear': propLinear,\n",
        "    'rank': propRank\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtBYslUOksKS"
      },
      "source": [
        "## unzip prerequisity available at https://drive.google.com/drive/folders/16LAR-wDdsNEAYbVT8KcG_DJtm6a7GhVP (FRATTVAE's authors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd51yUHgkr1p"
      },
      "outputs": [],
      "source": [
        "# # Google Colab に zip ファイルをアップロード\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()  # ファイル選択ダイアログが表示される"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tzC6Zi0RrPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "744f4a60-2548-4d4a-ba21-99e8391e736e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzipped at : /content/extracted\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "# ZIPファイル名\n",
        "# zip_file = \"your_file.zip\"\n",
        "# zip_file = \"/content/ZINC_JTVAE_standardized_struct.zip\"\n",
        "zip_file = \"/content/Polymer_standardized_struct.zip\"\n",
        "# 解凍先フォルダ\n",
        "extract_folder = \"/content/extracted\"\n",
        "\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "print(f\"unzipped at : {extract_folder}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h07vTc1noFsy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "edcea7f5-fe71-4bcd-91a1-f797aef9c53c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZMaTJPvqjXj"
      },
      "source": [
        "## scripts/process.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGj5t948qmCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc497d4-0831-4f32-dbfe-ae05a4c70797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.0061e-01,  2.8346e-01,  6.2736e-01,  6.3229e-01, -3.1397e-02,\n",
            "          4.6346e-01,  5.6554e-01,  8.3171e-01,  3.7000e-01, -9.8776e-02,\n",
            "         -2.6858e-01,  1.2034e+00,  4.8364e-01,  3.3301e-01,  7.2608e-02,\n",
            "          4.6348e-01,  2.0385e-02,  3.3629e-01,  8.7015e-03,  6.8050e-01,\n",
            "         -2.4289e-01,  1.0903e+00, -1.4920e-01,  6.2988e-02,  1.1061e+00,\n",
            "          4.0537e-01,  8.9739e-01,  4.3760e-01,  5.0841e-02,  5.9734e-01,\n",
            "          8.6879e-01,  4.0403e-01,  7.2367e-01,  9.6358e-01,  5.0858e-01,\n",
            "          6.1279e-01,  5.6733e-01,  5.6515e-01,  1.0285e+00,  5.4998e-01,\n",
            "          5.7119e-01,  8.8476e-01, -2.2863e-01,  3.4330e-01,  4.6614e-02,\n",
            "         -1.2995e-01,  7.6173e-01,  4.9361e-01,  5.8316e-01,  9.3524e-01,\n",
            "          3.9067e-01,  1.2880e+00,  6.1557e-01,  4.1987e-01,  4.3492e-03,\n",
            "          4.6465e-01,  5.0646e-01,  9.4691e-01,  8.4681e-01, -2.7711e-01,\n",
            "          6.4369e-03,  1.0989e+00,  5.9787e-01,  1.8777e-02,  2.8824e-01,\n",
            "          6.0414e-01,  5.7607e-01,  1.0060e+00,  6.2575e-01,  5.1001e-01,\n",
            "          5.1551e-01, -2.1914e-01,  5.4621e-01,  9.0595e-01,  6.9179e-01,\n",
            "          1.1371e+00, -2.5714e-01,  1.6495e-01,  6.5325e-02,  7.9447e-01,\n",
            "          1.2920e+00,  5.8986e-01,  3.1552e-01,  8.6816e-01,  6.9918e-01,\n",
            "          6.1563e-02,  6.1779e-01,  1.2864e-02,  1.2315e+00,  4.0302e-01,\n",
            "          7.5427e-01,  8.3547e-01, -1.8605e-01,  3.5705e-01,  7.8013e-01,\n",
            "          4.6495e-01,  1.1163e+00,  2.4501e-01,  4.6939e-01, -2.3976e-01,\n",
            "          5.0942e-01,  4.3171e-01,  5.6745e-01, -2.6656e-01,  8.9874e-01,\n",
            "         -1.7362e-01,  3.1349e-01,  1.4536e-02,  1.2426e+00,  1.6756e-01,\n",
            "          1.4205e-02,  8.0025e-01,  1.2403e+00,  7.1856e-01,  1.1117e+00,\n",
            "          1.2705e+00,  1.0252e+00,  8.6360e-01, -2.7634e-01,  6.2552e-01,\n",
            "          4.5199e-01, -8.4636e-02,  5.6061e-01,  1.2808e+00,  2.9475e-01,\n",
            "          6.8193e-01,  6.9029e-01,  3.4965e-02],\n",
            "        [ 6.6130e-01,  6.4782e-01, -2.5074e-01,  7.1925e-01,  1.5031e-01,\n",
            "          3.3834e-01,  4.1276e-01,  7.2462e-01,  1.2671e+00,  2.7364e-01,\n",
            "          5.7907e-01,  1.1736e+00,  3.3854e-01,  1.2797e+00,  4.2145e-02,\n",
            "         -1.0441e-01,  6.3755e-01, -1.2639e-01,  4.5546e-03,  6.0955e-01,\n",
            "          5.1567e-01,  1.1948e+00,  2.0029e-01, -1.5018e-01,  8.9971e-01,\n",
            "          2.4453e-01,  1.2807e+00,  4.3873e-02, -5.6919e-02,  2.8708e-02,\n",
            "          8.0202e-01,  4.7785e-01,  5.5242e-01,  8.3878e-01,  8.6735e-01,\n",
            "          1.1438e-01,  2.1056e-01,  1.2922e+00,  1.1804e+00,  7.7940e-01,\n",
            "          4.2320e-01,  6.0631e-01,  2.1183e-01, -2.4228e-01,  1.2560e-01,\n",
            "          1.5223e-01,  1.0360e+00,  2.5815e-02,  3.6102e-01,  7.9592e-01,\n",
            "          4.3388e-01,  5.5957e-01,  5.7439e-01,  4.0120e-01, -2.8867e-01,\n",
            "          4.3466e-01,  8.4969e-01,  8.7256e-01,  7.2163e-01,  6.6088e-01,\n",
            "          6.1518e-01,  3.3403e-01,  4.7171e-01,  3.5065e-01,  1.2757e-01,\n",
            "          7.4665e-01,  5.9348e-01,  8.3359e-01,  3.3368e-01,  1.5321e-01,\n",
            "          9.9222e-01,  6.7090e-01,  6.2012e-01,  9.2521e-01,  6.7791e-01,\n",
            "          5.9352e-01, -2.2619e-01,  2.8581e-01,  3.6563e-01,  1.1545e+00,\n",
            "          8.9840e-01,  1.0455e-01,  1.1038e+00,  4.0776e-01,  7.7461e-01,\n",
            "          3.5843e-01,  1.9443e-01,  2.7339e-02,  8.9469e-01,  5.0263e-01,\n",
            "          8.2750e-01,  6.9401e-01,  5.8129e-01,  5.0148e-01,  8.6335e-01,\n",
            "          8.9410e-01,  1.1601e+00,  2.6723e-01,  3.4089e-01, -1.9026e-01,\n",
            "          1.0980e+00, -1.0497e-01,  4.6027e-01,  1.8410e-01,  5.4912e-01,\n",
            "         -3.9799e-02, -2.4054e-01,  4.8599e-01,  6.1194e-01,  5.7861e-01,\n",
            "          2.9438e-01,  7.5462e-01,  4.1254e-01,  1.1441e+00,  1.1369e+00,\n",
            "          1.1529e+00,  4.7936e-01,  5.3757e-01,  6.0107e-01,  4.5450e-01,\n",
            "          7.3856e-01,  1.5247e-01,  2.8077e-01,  1.2461e+00,  6.3033e-01,\n",
            "          1.1849e+00,  1.2884e+00,  2.1888e-01],\n",
            "        [ 3.7379e-01,  5.7227e-01,  6.7979e-01,  8.9371e-01,  6.9780e-02,\n",
            "          8.6485e-03,  5.9872e-01,  1.1046e+00,  1.1377e+00,  5.0546e-01,\n",
            "         -2.2793e-01,  1.0979e+00,  2.1521e-01,  8.3819e-01, -1.2220e-01,\n",
            "          9.9289e-02,  5.9516e-03,  6.4968e-01, -2.9614e-01,  4.7568e-01,\n",
            "         -2.7479e-01,  5.6561e-01,  3.5715e-01,  3.4115e-01,  8.7272e-01,\n",
            "         -1.5306e-01,  5.5150e-01, -1.5288e-01,  1.5196e-01,  3.2449e-01,\n",
            "          1.0681e+00,  6.2649e-01,  1.2598e+00,  5.6557e-01,  9.2125e-01,\n",
            "          6.1872e-01,  1.8189e-01,  7.0842e-01,  9.5168e-01,  1.0155e+00,\n",
            "          1.2292e+00,  9.6216e-01,  3.0108e-01,  3.4402e-01,  1.1637e-01,\n",
            "          6.6335e-01,  5.6983e-01,  6.5088e-01,  1.1980e+00,  1.2991e+00,\n",
            "          9.0476e-02,  7.2353e-01,  4.9827e-01,  7.5146e-01, -2.7588e-01,\n",
            "          5.1331e-01,  1.1471e+00,  4.4319e-01,  8.7997e-01,  3.1417e-01,\n",
            "          2.6373e-01,  5.1527e-01,  3.8368e-01,  5.3954e-02,  4.3637e-01,\n",
            "          7.4777e-01,  1.2788e+00,  1.1381e+00,  6.2548e-01, -2.2212e-01,\n",
            "          4.9923e-01,  5.7226e-02,  3.7951e-01,  3.2306e-01,  8.8747e-01,\n",
            "          4.0826e-01,  3.2814e-01, -2.8075e-01,  4.7245e-01,  6.6525e-01,\n",
            "          1.1113e+00,  1.9532e-01,  9.8986e-01,  3.7648e-01,  6.1357e-01,\n",
            "          4.4388e-01,  6.0533e-01,  6.6707e-01,  5.2761e-01,  5.0247e-01,\n",
            "          1.0994e+00,  3.2680e-01, -2.8239e-01,  9.9670e-01,  3.1889e-01,\n",
            "          1.1354e+00,  4.5999e-01,  5.8041e-01,  3.2564e-01,  8.8569e-02,\n",
            "          7.3350e-01,  3.1560e-01,  7.1864e-01,  5.2833e-02,  4.4976e-01,\n",
            "          4.3182e-01,  4.1255e-01,  4.1328e-01,  6.1978e-01,  2.6962e-01,\n",
            "         -7.3267e-02,  1.1386e+00,  7.4403e-01,  1.2302e+00,  8.0390e-01,\n",
            "          5.0943e-01,  8.9079e-01,  1.3081e+00,  5.5095e-01,  7.0161e-01,\n",
            "          1.2256e+00,  6.6523e-01, -1.9265e-01,  8.5465e-01,  1.0447e-01,\n",
            "          1.2429e+00,  9.7433e-01,  5.9990e-01],\n",
            "        [ 3.5719e-01,  2.3466e-02,  7.3690e-01,  1.1103e+00,  4.8214e-01,\n",
            "          4.1754e-01,  5.9710e-01,  1.2161e+00,  9.2708e-01, -2.1471e-01,\n",
            "          5.4638e-01,  7.3671e-01,  5.8817e-01,  6.0832e-01, -1.9181e-01,\n",
            "          2.2323e-01,  4.0702e-02,  7.4236e-01,  1.8433e-02, -1.3450e-01,\n",
            "          2.3072e-01,  7.6612e-01,  4.0728e-01,  4.4474e-01,  6.9221e-01,\n",
            "         -1.0284e-01,  7.0739e-01, -5.6381e-03, -5.5363e-03,  1.0936e-01,\n",
            "          9.6984e-01,  3.0124e-01,  8.1674e-01,  4.6555e-01,  6.7122e-01,\n",
            "         -2.0227e-01,  4.1560e-01,  8.3661e-01,  1.2402e+00,  1.1484e+00,\n",
            "          3.3133e-01,  9.8996e-01,  4.0843e-01,  2.5272e-01,  6.4363e-01,\n",
            "          7.2511e-01,  5.8976e-01,  4.8807e-01,  3.5290e-01,  8.9550e-01,\n",
            "          7.0663e-01,  5.0281e-01,  6.6136e-01,  1.0741e+00, -2.6017e-01,\n",
            "          3.8952e-01,  3.5980e-01,  5.3636e-01,  3.3192e-01,  4.8480e-01,\n",
            "          6.5918e-01,  3.6750e-01,  4.0585e-01,  1.4041e-01,  1.8695e-01,\n",
            "          8.7209e-01,  1.0581e+00, -7.7055e-03,  5.4316e-01,  5.4265e-01,\n",
            "          1.3820e-01, -1.4249e-01,  8.5733e-01,  3.3649e-01,  1.2431e+00,\n",
            "          1.1133e+00,  2.0341e-01,  3.9069e-01,  3.5870e-01,  2.7901e-01,\n",
            "          1.1701e+00, -1.0520e-01,  1.2210e+00,  4.8397e-01,  1.2399e+00,\n",
            "          1.9836e-01, -2.3752e-04,  2.5192e-01,  3.7148e-01,  6.1008e-01,\n",
            "          9.2749e-01,  1.0794e+00,  3.5662e-01,  1.2169e+00,  1.0586e+00,\n",
            "          1.2155e+00,  9.6241e-01,  1.5551e-01,  3.6019e-01,  2.7158e-01,\n",
            "          4.2811e-01, -2.3845e-01,  5.4927e-01,  1.6388e-01,  1.0206e+00,\n",
            "          1.7642e-01,  8.0444e-02,  7.0025e-01,  6.2901e-01,  2.5799e-01,\n",
            "         -1.8844e-01,  1.1686e+00,  3.9126e-01,  4.3919e-01,  5.7039e-02,\n",
            "          1.0469e+00,  4.9402e-01,  1.1295e+00,  4.2623e-01,  8.0176e-01,\n",
            "          9.8991e-01, -1.3715e-02, -2.2086e-01,  6.1095e-01,  5.3690e-01,\n",
            "          1.0814e+00,  1.2710e+00, -2.4445e-01],\n",
            "        [-2.7162e-01,  5.0689e-01,  6.9837e-01,  5.3685e-01, -2.5584e-01,\n",
            "         -3.0861e-01, -7.2650e-02,  1.2363e+00,  7.3585e-01, -2.2275e-01,\n",
            "          2.1434e-01,  7.1593e-01,  2.4213e-01,  5.8919e-01,  2.5308e-01,\n",
            "          3.1247e-02, -1.6672e-01, -1.9500e-01, -5.5616e-02,  6.4962e-01,\n",
            "          6.0324e-01,  1.0847e+00, -8.3858e-02,  1.1949e+00,  5.0623e-01,\n",
            "         -1.3787e-01,  7.6228e-01,  3.4802e-01, -8.7852e-02, -9.8295e-02,\n",
            "          5.0977e-01,  4.2068e-01,  5.0836e-01,  6.7548e-01,  9.0325e-01,\n",
            "          5.6610e-01,  2.9024e-01,  5.7562e-01,  9.3247e-01,  1.1418e+00,\n",
            "          2.8441e-01,  3.9477e-01,  2.6685e-01,  5.2604e-01,  4.9525e-01,\n",
            "          1.7657e-02,  7.3736e-01,  2.8407e-01,  8.1925e-01,  8.0190e-01,\n",
            "          2.1354e-01,  6.4692e-01,  5.2455e-01,  3.9043e-01,  2.5754e-01,\n",
            "          4.8182e-01,  9.4879e-01,  8.5676e-01,  3.0699e-01, -2.3055e-01,\n",
            "          3.4427e-01,  1.1964e+00,  7.1857e-01,  4.4951e-01, -5.8484e-02,\n",
            "         -4.7689e-02,  3.8684e-01,  6.2878e-01, -2.0944e-01,  3.1668e-01,\n",
            "          3.3596e-01,  1.2933e-01,  5.8047e-01,  1.1974e+00,  1.0331e+00,\n",
            "          2.1672e-01,  6.0827e-02, -1.2155e-01, -2.1355e-01,  9.6246e-01,\n",
            "          5.7224e-01,  4.7485e-01,  6.5469e-01,  4.6595e-01,  1.1780e+00,\n",
            "          4.6031e-01, -8.0916e-02, -2.2060e-01,  4.7882e-01,  3.6755e-01,\n",
            "          3.4823e-01,  7.9618e-01, -2.9344e-01,  5.0380e-01,  8.2954e-01,\n",
            "          2.9162e-01,  3.8818e-01,  7.8592e-02, -1.1206e-01,  2.4522e-01,\n",
            "          1.0725e+00,  2.7463e-01,  9.9810e-01,  1.1534e-01,  9.8862e-01,\n",
            "          2.4666e-01, -2.5236e-01,  2.8192e-01,  1.2148e+00,  6.5188e-01,\n",
            "          1.9561e-01,  1.0970e+00,  1.1492e+00,  7.7840e-01,  1.0707e+00,\n",
            "          6.6784e-01,  1.0262e+00,  1.2703e+00,  4.4589e-01,  4.2858e-01,\n",
            "          6.1257e-01,  6.1033e-01,  2.3740e-01,  7.7754e-01,  1.9761e-02,\n",
            "          6.0990e-01,  6.2661e-01, -6.1364e-02],\n",
            "        [ 2.6103e-01,  5.1333e-01,  2.5222e-01,  9.5486e-01,  1.8286e-01,\n",
            "          4.8186e-01,  1.2790e-01,  7.7871e-01,  1.2165e+00, -1.2824e-01,\n",
            "          5.4246e-01,  7.0038e-01, -2.2397e-01,  5.4273e-01,  5.8993e-01,\n",
            "         -8.8836e-02,  5.4110e-01, -2.2712e-01,  1.0642e-01, -1.3171e-01,\n",
            "         -6.1318e-02,  4.9195e-01,  2.4894e-01,  6.2890e-01,  4.3519e-01,\n",
            "         -2.1611e-01,  1.1694e+00,  5.6979e-01, -2.2307e-01,  3.5346e-01,\n",
            "          1.3058e+00,  6.1794e-01,  5.4849e-01,  3.5967e-01,  4.9390e-01,\n",
            "         -1.7587e-01,  6.3524e-01,  1.2747e+00,  7.4333e-01,  5.4458e-01,\n",
            "          3.1736e-01,  1.2177e+00,  1.5266e-01,  3.5686e-01, -7.5590e-02,\n",
            "         -1.3693e-01,  3.9221e-01, -2.0525e-02,  1.1928e+00,  7.1109e-01,\n",
            "          1.2140e-01, -1.8516e-01,  5.9938e-01,  1.1521e+00,  1.7306e-01,\n",
            "          1.2624e+00,  1.2788e+00,  1.1676e+00,  4.7839e-01,  2.2576e-01,\n",
            "          3.4740e-01,  3.9813e-01,  5.1446e-01,  2.2221e-01,  3.8677e-01,\n",
            "          8.2581e-01,  1.0371e+00, -6.7608e-04,  4.4315e-01,  6.4002e-01,\n",
            "          4.9166e-01,  3.7516e-01,  1.1062e+00,  1.2845e+00,  4.3712e-01,\n",
            "          5.5249e-01,  4.1778e-01, -8.6121e-02,  2.1479e-01,  1.0439e+00,\n",
            "          3.3601e-01, -2.7217e-01,  1.2514e+00,  1.2529e+00,  1.1660e+00,\n",
            "          4.7072e-01,  6.6058e-01,  7.0077e-02,  7.3016e-01, -2.1119e-01,\n",
            "          4.4620e-01,  4.6276e-01, -1.1907e-02,  6.6712e-01,  9.0682e-01,\n",
            "          9.6331e-01,  5.8872e-01,  2.1514e-01, -3.3934e-02,  5.1242e-01,\n",
            "          7.4158e-01,  5.1723e-01,  6.6317e-01,  4.7387e-01,  4.5155e-01,\n",
            "          5.7702e-02,  4.2477e-01,  4.2466e-01,  3.5789e-01, -5.9396e-02,\n",
            "          5.7476e-01,  1.0271e+00,  1.1351e+00,  5.5589e-01,  3.9960e-02,\n",
            "          6.7450e-01,  4.7033e-01,  1.0703e+00,  1.2185e+00,  5.4615e-01,\n",
            "          7.6771e-01,  1.7630e-01, -1.2314e-01,  8.1287e-01, -1.4752e-01,\n",
            "          5.7367e-01,  6.3937e-01,  1.2082e-01]])\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import datetime\n",
        "import gc\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "# from utils.apps import second2date, torch_fix_seed\n",
        "# from utils.mask import create_mask\n",
        "# from utils.tree import get_pad_features, get_tree_features\n",
        "# from utils.metrics import cosine_matrix, euclid_distance, CRITERION\n",
        "# from utils.preprocess import debugMolToBRICSfragments\n",
        "# from utils.construct import reconstructMol, constructMol, calc_tanimoto\n",
        "\n",
        "\n",
        "def reconstruct(dataloader,\n",
        "                smiles: list,\n",
        "                labels: list,\n",
        "                frag_ecfps: torch.Tensor,\n",
        "                ndummys: torch.Tensor,\n",
        "                model: nn.Module,\n",
        "                pmodel: nn.Module= None,\n",
        "                criterion= None,\n",
        "                max_nfrags: int= 30,\n",
        "                useChiral: bool= True,\n",
        "                free_n: bool= False,\n",
        "                n_jobs: int= -1,\n",
        "                device: torch.device= torch.device('cpu'),\n",
        "                seed: int= 0\n",
        "                ):\n",
        "    torch_fix_seed(seed)\n",
        "\n",
        "    labels = np.array(labels)\n",
        "    z_list, prop_list, pred_list = [], [], []\n",
        "    frag_idxs_list, adjs_list = [], []\n",
        "    label_acc, sims_list = 0, []\n",
        "    s = time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(dataloader):\n",
        "            frag_indices = data[0]\n",
        "            features = frag_ecfps[frag_indices.flatten()].reshape(frag_indices.shape[0], frag_indices.shape[1], -1).to(device)\n",
        "            positions = data[1].to(device)\n",
        "            prop = data[2].to(device)\n",
        "\n",
        "            # make mask\n",
        "            src = torch.hstack([torch.full((frag_indices.shape[0], 1), -1), frag_indices.detach()]).to(device)  # for super root\n",
        "            src_mask, _, src_pad_mask, _ = create_mask(src, src, pad_idx= 0, batch_first= True)\n",
        "\n",
        "            # encode & decode\n",
        "            z, _, _, tree_list = model(features, positions,\n",
        "                                       src_mask= src_mask, src_pad_mask= src_pad_mask,\n",
        "                                       frag_ecfps= frag_ecfps, ndummys= ndummys, max_nfrags= max_nfrags, free_n= free_n)\n",
        "\n",
        "            # property prediction\n",
        "            if pmodel:\n",
        "                pred_prop = pmodel(z.to(device))\n",
        "                prop_list.append(prop)\n",
        "                pred_list.append(pred_prop)\n",
        "\n",
        "            # stock in list\n",
        "            z_list.append(z.cpu())\n",
        "            frag_idxs, adjs = zip(*[(tree.dgl_graph.ndata['fid'].squeeze(-1).tolist(), tree.adjacency_matrix().tolist()) for tree in tree_list])\n",
        "            frag_idxs_list += list(frag_idxs)\n",
        "            adjs_list += list(adjs)\n",
        "\n",
        "            # calc accuracy\n",
        "            acc = 0\n",
        "            for idxs, true_idxs in zip(frag_idxs, frag_indices):\n",
        "                idxs = torch.tensor(idxs)\n",
        "                idxs_pad, true_idxs_pad = pad_sequence([idxs, true_idxs], batch_first= True, padding_value= 0).chunk(2, dim= 0)\n",
        "                acc += torch.mean(true_idxs_pad.eq(idxs_pad).float()).item()\n",
        "            label_acc += acc / frag_indices.shape[0]\n",
        "\n",
        "            # calc similarity of latent variables\n",
        "            recon_indices = get_pad_features(tree_list, key= 'fid', max_nodes_num= max_nfrags).squeeze(-1)\n",
        "            features = get_pad_features(tree_list, key= 'x', max_nodes_num= max_nfrags).to(device)\n",
        "            positions = get_pad_features(tree_list, key= 'pos', max_nodes_num= max_nfrags).to(device)\n",
        "            src = torch.hstack([torch.full((recon_indices.shape[0], 1), -1), recon_indices.detach()]).to(device)  # for super root\n",
        "            src_mask, _, src_pad_mask, _ = create_mask(src, src, pad_idx= 0, batch_first= True)\n",
        "            z_dash, _, _ = model.encode(features, positions, src_mask, src_pad_mask)\n",
        "            cosines = cosine_matrix(z, z_dash).diag()\n",
        "            sims_list += cosines.tolist()\n",
        "\n",
        "            if ((i+1) % 10 == 0) | (i == 0) | ((i+1) == len(dataloader)):\n",
        "                print(f'[{i+1:0=3}/{len(dataloader):0=3}] label_accuracy: {label_acc/(i+1):.6f}, cosine_similarity: {cosines.mean().item():.6f}, elapsed time: {second2date(time.time()-s)}', flush= True)\n",
        "                s = time.time()\n",
        "\n",
        "    # evaluate reconstruction\n",
        "    results = Parallel(n_jobs= n_jobs)(delayed(reconstructMol)(smi, labels[idxs].tolist(), adj, useChiral= useChiral) for smi, idxs, adj in zip(smiles, frag_idxs_list, adjs_list))\n",
        "    dec_smiles, correct = zip(*results)\n",
        "    dec_smiles = list(dec_smiles)\n",
        "    correct = np.array(correct)\n",
        "    if useChiral:\n",
        "        print(f'reconstruction-2D rate: {sum(correct > 0)/len(smiles):.6f} ({sum(correct > 0)}/{len(smiles)})', flush= True)\n",
        "        print(f'reconstruction-3D rate: {sum(correct == 3)/sum(correct > 1):.6f} ({sum(correct == 3)}/{sum(correct > 1)})', flush= True)\n",
        "    else:\n",
        "        print(f'reconstruction rate: {sum(correct > 0)/len(smiles):.6f} ({sum(correct > 0)}/{len(smiles)})', flush= True)\n",
        "\n",
        "    # evaluate tanimoto similarity\n",
        "    tanimotos = Parallel(n_jobs= n_jobs)(delayed(calc_tanimoto)(smi1, smi2, useChiral= useChiral) for smi1, smi2 in zip(smiles, dec_smiles))\n",
        "    print(f'tanimoto simirality: <mean> {np.nanmean(tanimotos):.6f}, <std> {np.nanstd(tanimotos):.6f}', flush= True)\n",
        "\n",
        "    # evaluate distribution learning\n",
        "    z_all = torch.vstack(z_list)\n",
        "    print(f'z-latent similarity: <mean> {np.mean(sims_list):.6f}, <std> {np.std(sims_list):.6f}', flush= True)\n",
        "\n",
        "    # evaluate property prediction\n",
        "    if pmodel:\n",
        "        ploss_list = []\n",
        "        prop = torch.vstack(prop_list)\n",
        "        pred = torch.vstack(pred_list)\n",
        "        assert prop.shape[0] == pred.shape[0]\n",
        "        prop_dim = prop.shape[-1]\n",
        "        with torch.no_grad():\n",
        "            for i in range(prop_dim):\n",
        "                mask = ~torch.isnan(prop[:, i])\n",
        "                ploss_list.append(criterion(input= pred[:, i][mask], target= prop[:, i][mask]).item())\n",
        "        pred_list = pred.tolist()\n",
        "        print(f'property prediction: ' + ', '.join([f'[{i}] {pl:.4f}' for i, pl in enumerate(ploss_list)]), flush= True)\n",
        "\n",
        "    return z_all.tolist(), dec_smiles, correct, tanimotos, pred_list\n",
        "\n",
        "\n",
        "def generate(dataloader,\n",
        "             labels: list,\n",
        "             frag_ecfps: torch.Tensor,\n",
        "             ndummys: torch.Tensor,\n",
        "             model: nn.Module,\n",
        "             pmodel: nn.Module= None,\n",
        "             max_nfrags: int= 30,\n",
        "             useChiral: bool= True,\n",
        "             free_n: bool= False,\n",
        "             n_jobs: int= -1,\n",
        "             device: torch.device= torch.device('cpu'),\n",
        "             seed: int= 0\n",
        "            ):\n",
        "    torch_fix_seed(seed)\n",
        "\n",
        "    labels = np.array(labels)\n",
        "    z_list, pred_list, cosine_list, rmse_list = [], [], [], []\n",
        "    frag_idxs_list, adjs_list = [], []\n",
        "    s = time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(dataloader):\n",
        "            z = data[0].to(device)\n",
        "\n",
        "            # decode\n",
        "            tree_list = model.sequential_decode(z, frag_ecfps, ndummys, max_nfrags= max_nfrags, free_n= free_n)\n",
        "\n",
        "            # property prediction\n",
        "            if pmodel:\n",
        "                pred_prop = pmodel(z.to(device))\n",
        "                pred_list.append(pred_prop)\n",
        "\n",
        "            # calc similarity of latent variables\n",
        "            recon_indices = get_pad_features(tree_list, key= 'fid', max_nodes_num= max_nfrags).squeeze(-1)\n",
        "            features = get_pad_features(tree_list, key= 'x', max_nodes_num= max_nfrags).to(device)\n",
        "            positions = get_pad_features(tree_list, key= 'pos', max_nodes_num= max_nfrags).to(device)\n",
        "            src = torch.hstack([torch.full((recon_indices.shape[0], 1), -1), recon_indices.detach()]).to(device)  # for super root\n",
        "            src_mask, _, src_pad_mask, _ = create_mask(src, src, pad_idx= 0, batch_first= True)\n",
        "            z_dash, _, _ = model.encode(features, positions, src_mask, src_pad_mask)\n",
        "            cosines = cosine_matrix(z, z_dash).diag()\n",
        "            rmses = euclid_distance(z, z_dash) / np.sqrt(model.latent_dim)\n",
        "\n",
        "            # stock in list\n",
        "            z_list.append(z_dash.cpu())\n",
        "            frag_idxs, adjs = zip(*[(tree.dgl_graph.ndata['fid'].squeeze(-1).tolist(), tree.adjacency_matrix().tolist()) for tree in tree_list])\n",
        "            frag_idxs_list += list(frag_idxs)\n",
        "            adjs_list += list(adjs)\n",
        "            cosine_list += cosines.tolist()\n",
        "            rmse_list += rmses.tolist()\n",
        "\n",
        "            if ((i+1) % 10 == 0) | (i == 0) | ((i+1) == len(dataloader)):\n",
        "                print(f'[{i+1:0=3}/{len(dataloader):0=3}] cosine_similarity: {cosines.mean().item():.4f}, RMSE: {rmses.mean().item():.4f}, elapsed time: {second2date(time.time()-s)}', flush= True)\n",
        "                s = time.time()\n",
        "\n",
        "    # constructMol\n",
        "    dec_smiles = Parallel(n_jobs= n_jobs)(delayed(constructMol)(labels[idxs].tolist(), adj, useChiral= useChiral) for idxs, adj in zip(frag_idxs_list, adjs_list))\n",
        "\n",
        "    z_list = torch.vstack(z_list).tolist()\n",
        "    if pmodel:\n",
        "        pred_list = torch.vstack(pred_list).tolist()\n",
        "\n",
        "    # evaluate distribution learning\n",
        "    print(f'z-latent similarity:', flush= True)\n",
        "    print(f'- cosine:  <mean> {np.mean(cosine_list):.6f}, <std> {np.std(cosine_list):.6f}', flush= True)\n",
        "    print(f'- RMSE:  <mean> {np.mean(rmse_list):.6f}, <std> {np.std(rmse_list):.6f}', flush= True)\n",
        "    del z, z_dash\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return z_list, dec_smiles, pred_list, cosine_list, rmse_list\n",
        "\n",
        "\n",
        "def interpolate_between_2points(mol0,\n",
        "                                mol1,\n",
        "                                model: nn.Module,\n",
        "                                labels: list,\n",
        "                                frag_ecfps: torch.Tensor,\n",
        "                                ndummys: torch.Tensor,\n",
        "                                min_size: int= 1,\n",
        "                                max_nfrags: int= 30,\n",
        "                                useChiral: bool= True,\n",
        "                                ignore_double: bool= True,\n",
        "                                num_intp: int= 100,\n",
        "                                free_n: bool= False,\n",
        "                                n_jobs: int= -1,\n",
        "                                device: torch.device= torch.device('cpu'),\n",
        "                                ):\n",
        "    # convert mol to latent variable and finger print\n",
        "    tmp = []\n",
        "    for mol in [mol0, mol1]:\n",
        "        frags, bond_types, bondMapNums, _ = debugMolToBRICSfragments(mol, minFragSize= min_size, maxFragNums= max_nfrags,\n",
        "                                                                     maxDegree= model.width, useChiral= useChiral, ignore_double= ignore_double)\n",
        "        frag_idxs = [labels.index(f) for f in frags]\n",
        "        frag_idxs, features, positions = get_tree_features(frag_idxs, frag_ecfps[frag_idxs], bond_types, bondMapNums, model.depth, model.width, free_n)\n",
        "        frag_idxs, features, positions = frag_idxs.unsqueeze(0), features.unsqueeze(0), positions.unsqueeze(0)\n",
        "        src = torch.hstack([torch.full((frag_idxs.shape[0], 1), -1), frag_idxs.detach()])\n",
        "        src_mask, _, src_pad_mask, _ = create_mask(src, src, pad_idx= 0, batch_first= True)\n",
        "        z, _, _ = model.encode(features.to(device), positions.to(device), src_mask.to(device), src_pad_mask.to(device))\n",
        "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, 2048, useChirality= useChiral)\n",
        "        tmp += [z, fp]\n",
        "    z0, fp0, z1, fp1 = tmp\n",
        "\n",
        "    # interpolate\n",
        "    labels = np.array(labels)\n",
        "    d = z1 - z0\n",
        "    similarity = DataStructs.TanimotoSimilarity(fp0, fp1)\n",
        "    z_intp = torch.vstack([z0 + ((i*d)/(num_intp+1)) for i in range(1, num_intp+1)]).float()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tree_list = model.sequential_decode(z_intp.to(device), frag_ecfps, ndummys, max_nfrags= max_nfrags)\n",
        "    frag_idxs_list, adjs_list = map(list, zip(*[(tree.dgl_graph.ndata['fid'].squeeze(-1).tolist(), tree.adjacency_matrix().tolist()) for tree in tree_list]))\n",
        "    smiles_intp = Parallel(n_jobs= n_jobs)(delayed(constructMol)(labels[idxs].tolist(), adj, useChiral= useChiral) for idxs, adj in zip(frag_idxs_list, adjs_list))\n",
        "    mols_intp = [Chem.MolFromSmiles(s) for s in smiles_intp]\n",
        "    similarity_intp = [DataStructs.TanimotoSimilarity(fp0, AllChem.GetMorganFingerprintAsBitVect(m, 2, 2048, useChirality= useChiral)) for m in mols_intp]\n",
        "\n",
        "    return smiles_intp, similarity_intp, similarity\n",
        "\n",
        "\n",
        "def eval_interpolate_between_2points(smiles: list,\n",
        "                                     model: nn.Module,\n",
        "                                     labels: list,\n",
        "                                     frag_ecfps: torch.Tensor,\n",
        "                                     ndummys: torch.Tensor,\n",
        "                                     min_size: int= 1,\n",
        "                                     max_nfrags: int= 30,\n",
        "                                     useChiral: bool= True,\n",
        "                                     ignore_double: bool= False,\n",
        "                                     num_intp: int= 100,\n",
        "                                     num_iters: int= 10000,\n",
        "                                     free_n: bool= False,\n",
        "                                     n_jobs: int= -1,\n",
        "                                     device: torch.device= torch.device('cpu'),\n",
        "                                     seed: int= 0,\n",
        "                                     ):\n",
        "    \"\"\"\n",
        "    Evaluate smoothness of latent space quantitatively\n",
        "    \"\"\"\n",
        "    torch_fix_seed(seed)\n",
        "    sample_list, unique_list, mae_list, corr_list = [], [], [], []\n",
        "    s = time.time()\n",
        "    for i in range(num_iters):\n",
        "        random.shuffle(smiles)\n",
        "        s0, s1 = smiles[:2]\n",
        "        smiles_intp, similarity_intp, similarity = interpolate_between_2points(Chem.MolFromSmiles(s0), Chem.MolFromSmiles(s1), model, labels, frag_ecfps, ndummys,\n",
        "                                                                               min_size, max_nfrags, useChiral, ignore_double,\n",
        "                                                                               num_intp, free_n, n_jobs, device)\n",
        "        d_sim = 1 - similarity\n",
        "        similarity_intp = torch.tensor(similarity_intp)\n",
        "        ideal_similarity_intp = torch.tensor([1 - (i*d_sim)/(num_intp+1) for i in range(1, num_intp+1)]).float()\n",
        "\n",
        "        sample_list.append((s0, s1, similarity))\n",
        "        unique_list.append(len(set([s for s in smiles_intp if s is not None]))/num_intp)\n",
        "        mae_list.append(F.l1_loss(similarity_intp, ideal_similarity_intp).item())\n",
        "        corr_list.append(torch.corrcoef(torch.vstack([similarity_intp, ideal_similarity_intp]))[0, 1].item())\n",
        "\n",
        "        if ((i+1) % 100 == 0):\n",
        "            print(f'[{i+1}/{num_iters}] unique: {np.mean(unique_list):.4f}, R: {np.mean(corr_list):.4f}, MAE: {np.mean(mae_list):.4f}, elapsed time: {second2date(time.time()-s)}', flush= True)\n",
        "            s = time.time()\n",
        "\n",
        "    print(f'[{i+1}/{num_iters}] unique: {np.mean(unique_list):.4f} (std; {np.std(unique_list):.4f}), R: {np.mean(corr_list):.4f} (std; {np.std(corr_list):.4f}),',\n",
        "           f'MAE: {np.mean(mae_list):.4f} (std; {np.std(mae_list):.4f}), elapsed time: {second2date(time.time()-s)}', flush= True)\n",
        "\n",
        "    return sample_list, unique_list, mae_list, corr_list\n",
        "\n",
        "\n",
        "def interpolate_around(mol,\n",
        "                       model: nn.Module,\n",
        "                       labels: list,\n",
        "                       frag_ecfps: torch.Tensor,\n",
        "                       ndummys: torch.Tensor,\n",
        "                       min_size: int= 1,\n",
        "                       max_nfrags: int= 30,\n",
        "                       useChiral: bool= True,\n",
        "                       ignore_double: bool= False,\n",
        "                       radius: int= 4,\n",
        "                       delta: int= 5,\n",
        "                       free_n: bool= False,\n",
        "                       n_jobs: int= -1,\n",
        "                       device: torch.device= torch.device('cpu'),\n",
        "                       seed: int= 0\n",
        "                        ):\n",
        "    \"\"\"\n",
        "    num_intp_per_axis: odd number\n",
        "    \"\"\"\n",
        "    torch_fix_seed(seed)\n",
        "\n",
        "    # convert mol to latent variable and finger print\n",
        "    frags, bond_types, bondMapNums, _ = debugMolToBRICSfragments(mol, minFragSize= min_size, maxFragNums= max_nfrags,\n",
        "                                                                 maxDegree= model.width, useChiral= useChiral, ignore_double= ignore_double)\n",
        "    frag_idxs = [labels.index(f) for f in frags]\n",
        "    frag_idxs, features, positions = get_tree_features(frag_idxs, frag_ecfps[frag_idxs], bond_types, bondMapNums, model.depth, model.width, free_n)\n",
        "    frag_idxs, features, positions = frag_idxs.unsqueeze(0), features.unsqueeze(0), positions.unsqueeze(0)\n",
        "    src = torch.hstack([torch.full((frag_idxs.shape[0], 1), -1), frag_idxs.detach()])\n",
        "    src_mask, _, src_pad_mask, _ = create_mask(src, src, pad_idx= 0, batch_first= True)\n",
        "    z, _, _ = model.encode(features.to(device), positions.to(device), src_mask.to(device), src_pad_mask.to(device))\n",
        "    z = z.cpu()\n",
        "    labels = np.array(labels)\n",
        "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, 2048, useChirality= useChiral)\n",
        "\n",
        "    # randomly generate 2 orthonormal axis x & y.\n",
        "    x = np.random.randn(z.shape[-1])\n",
        "    x /= np.linalg.norm(x)\n",
        "\n",
        "    y = np.random.randn(z.shape[-1])\n",
        "    y -= y.dot(x) * x\n",
        "    y /= np.linalg.norm(y)\n",
        "\n",
        "    x, y = torch.from_numpy(x).float(), torch.from_numpy(y).float()\n",
        "\n",
        "    z_intp = []\n",
        "    for dx in range(-radius, radius + 1):\n",
        "        for dy in range(-radius, radius + 1):\n",
        "            z_intp.append(z + x * delta * dx + y * delta * dy)\n",
        "            if (dx == 0) & (dy == 0):\n",
        "                center = len(z_intp) - 1\n",
        "    z_intp = torch.vstack(z_intp).float()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tree_list = model.sequential_decode(z_intp.to(device), frag_ecfps, ndummys, max_nfrags= max_nfrags)\n",
        "    frag_idxs_list, adjs_list = map(list, zip(*[(tree.dgl_graph.ndata['fid'].squeeze(-1).tolist(), tree.adjacency_matrix().tolist()) for tree in tree_list]))\n",
        "    smiles_intp = Parallel(n_jobs= n_jobs)(delayed(constructMol)(labels[idxs].tolist(), adj, useChiral= useChiral) for idxs, adj in zip(frag_idxs_list, adjs_list))\n",
        "    mols_intp = [Chem.MolFromSmiles(s) for s in smiles_intp]\n",
        "    # fp = AllChem.GetMorganFingerprintAsBitVect(mols_intp[center], 2, 2048, useChirality= useChiral)\n",
        "    similarity_intp = [DataStructs.TanimotoSimilarity(fp, AllChem.GetMorganFingerprintAsBitVect(m, 2, 2048, useChirality= useChiral)) for m in mols_intp]\n",
        "\n",
        "    return smiles_intp, similarity_intp\n",
        "\n",
        "\n",
        "def eval_interpolate_around(smiles: list,\n",
        "                            model: nn.Module,\n",
        "                            labels: list,\n",
        "                            frag_ecfps: torch.Tensor,\n",
        "                            ndummys: torch.Tensor,\n",
        "                            min_size: int= 1,\n",
        "                            max_nfrags: int= 30,\n",
        "                            useChiral: bool= True,\n",
        "                            ignore_double: bool= False,\n",
        "                            radius: int= 4,\n",
        "                            delta: int= 5,\n",
        "                            num_iters: int= 10000,\n",
        "                            free_n: bool= False,\n",
        "                            n_jobs: int= -1,\n",
        "                            device: torch.device= torch.device('cpu'),\n",
        "                            seed: int= 0,\n",
        "                            ):\n",
        "    \"\"\"\n",
        "    Evaluate smoothness of latent space quantitatively\n",
        "    \"\"\"\n",
        "    torch_fix_seed(seed)\n",
        "    sample_list, unique_dict, similarity_dict = [], {}, {}\n",
        "    s = time.time()\n",
        "    random.shuffle(smiles)\n",
        "    for i in range(num_iters):\n",
        "        s0 = smiles[i]\n",
        "        sample_list.append(s0)\n",
        "        for j in range(1, radius+1):\n",
        "            if i == 0:\n",
        "                unique_dict[f'unique:{delta*j}'] = []\n",
        "                similarity_dict[f'similarity:{delta*j}'] = []\n",
        "            smiles_intp, similarity_intp = interpolate_around(Chem.MolFromSmiles(s0), model, labels, frag_ecfps, ndummys,\n",
        "                                                              min_size, max_nfrags, useChiral, ignore_double,\n",
        "                                                              1, delta*j, free_n, n_jobs, device, seed)\n",
        "            unique_dict[f'unique:{delta*j}'].append((len(set([s for s in smiles_intp if s is not None]))-1) / (len(smiles_intp)-1))\n",
        "            similarity_dict[f'similarity:{delta*j}'].append((np.sum(similarity_intp)-1)/(len(similarity_intp)-1))\n",
        "\n",
        "        if ((i+1) % 100 == 0):\n",
        "            print(f'[{i+1}/{num_iters}] unique, similarity, elapsed time: {second2date(time.time()-s)}', flush= True)\n",
        "            for j in range(1, radius+1):\n",
        "                print(f'- delta[{delta*j}]: {np.mean(unique_dict[f\"unique:{delta*j}\"]):.4f}, {np.mean(similarity_dict[f\"similarity:{delta*j}\"]):.4f}', flush= True)\n",
        "            s = time.time()\n",
        "\n",
        "    print(f'[{i+1}/{num_iters}] unique, similarity, elapsed time: {second2date(time.time()-s)}', flush= True)\n",
        "    for j in range(1, radius+1):\n",
        "        print(f'- delta[{delta*j}]: {np.mean(unique_dict[f\"unique:{delta*j}\"]):.4f} (std; {np.std(unique_dict[f\"unique:{delta*j}\"]):.4f}),',\n",
        "              f'{np.mean(similarity_dict[f\"similarity:{delta*j}\"]):.4f} (std; {np.std(similarity_dict[f\"similarity:{delta*j}\"]):.4f})', flush= True)\n",
        "\n",
        "    return sample_list, unique_dict, similarity_dict\n",
        "\n",
        "\n",
        "def prop_optimize(z: torch.Tensor,\n",
        "                  target: torch.Tensor,\n",
        "                  pmodel: nn.Module,\n",
        "                  criterion: nn.Module= nn.MSELoss(reduction= 'none'),\n",
        "                  lr: float= 0.01,\n",
        "                  max_iter: int= 100,\n",
        "                  max_patient: int= 5,\n",
        "                  device: torch.device= torch.device('cpu')\n",
        "                  ) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    optimize latent-variables using gradient.\n",
        "    z: torch.Tensor, shape= (batch_size, z_dim)\n",
        "    target: torch.Tensor, shape= (batch_size, prop_dim)\n",
        "    \"\"\"\n",
        "    z_opt = z.detach().clone().to(device)\n",
        "    z_opt.requires_grad = True\n",
        "    target = target.to(device)\n",
        "    optimizer = torch.optim.Adam([z_opt], lr= lr)\n",
        "    best_z, best_loss = z_opt.clone().cpu(), torch.full(size= (z.shape[0], 1), fill_value= float('inf'))\n",
        "\n",
        "    patient = 0\n",
        "    for _ in range(max_iter):\n",
        "        pred = pmodel(z_opt)\n",
        "        loss = criterion(pred, target)\n",
        "        optimizer.zero_grad()\n",
        "        pmodel.zero_grad()\n",
        "        loss.mean().backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss = loss.mean(dim= -1, keepdim= True).cpu()\n",
        "        if torch.all(loss>=best_loss):\n",
        "            patient += 1\n",
        "        else:\n",
        "            best_z = torch.where(loss<best_loss, z_opt.clone().cpu(), best_z).detach()\n",
        "            best_loss = torch.where(loss<best_loss, loss, best_loss).detach()\n",
        "\n",
        "        if patient > max_patient:\n",
        "            break\n",
        "\n",
        "    return best_z\n",
        "\n",
        "\n",
        "def constrained_prop_optimize(mols: list,\n",
        "                              target: torch.Tensor,\n",
        "                              scoring_func,              # scoring_func(mol) -> score\n",
        "                              model: nn.Module,\n",
        "                              pmodel: nn.Module,\n",
        "                              labels: list,\n",
        "                              frag_ecfps: torch.Tensor,\n",
        "                              ndummys: torch.Tensor,\n",
        "                              min_size: int= 1,\n",
        "                              max_nfrags: int= 30,\n",
        "                              useChiral: bool= True,\n",
        "                              ignore_double: bool= False,\n",
        "                              criterion: nn.Module= nn.MSELoss(reduction= 'none'),\n",
        "                              thresholds: list= [0.2, 0.4, 0.6],\n",
        "                              lr: float= 0.01,\n",
        "                              max_iter: int= 80,\n",
        "                              device: torch.device= torch.device('cpu')\n",
        "                              ) -> list:\n",
        "    \"\"\"\n",
        "    Multiple properties not supported.\n",
        "    Pmodel outputs have shape= (batch_size, 1)\n",
        "    \"\"\"\n",
        "    z_all = []\n",
        "    for mol in mols:\n",
        "        frags, bond_types, bondMapNums, _ = debugMolToBRICSfragments(mol, minFragSize= min_size, maxFragNums= max_nfrags,\n",
        "                                                                     maxDegree= model.width, useChiral= useChiral, ignore_double= ignore_double)\n",
        "        frag_idxs = [labels.index(f) for f in frags]\n",
        "        frag_idxs, features, positions = get_tree_features(frag_idxs, frag_ecfps[frag_idxs], bond_types, bondMapNums, model.depth, model.width, False)\n",
        "        frag_idxs, features, positions = frag_idxs.unsqueeze(0), features.unsqueeze(0), positions.unsqueeze(0)\n",
        "        src = torch.hstack([torch.full((frag_idxs.shape[0], 1), -1), frag_idxs.detach()])\n",
        "        src_mask, _, src_pad_mask, _ = create_mask(src, src, pad_idx= 0, batch_first= True)\n",
        "        z, _, _ = model.encode(features.to(device), positions.to(device), src_mask.to(device), src_pad_mask.to(device))\n",
        "        z_all.append(z.cpu())\n",
        "    z_all = torch.vstack(z_all)\n",
        "\n",
        "    model.set_labels(labels)\n",
        "    smiles_opt = []\n",
        "    z_opt = z_all.clone()\n",
        "    for _ in range(max_iter):\n",
        "        z_opt = prop_optimize(z_opt, target, pmodel, criterion, lr= lr, max_iter= 1, device= device)\n",
        "        with torch.no_grad():\n",
        "            smis_opt = model.sequential_decode(z_opt.to(device), frag_ecfps, ndummys, max_nfrags= max_nfrags, asSmiles= True)\n",
        "            smiles_opt.append(smis_opt)\n",
        "\n",
        "    improved_smiles, improved_score = {f'thr-{thr}': [] for thr in thresholds}, {f'thr-{thr}': [] for thr in thresholds}\n",
        "    for mol, smis_opt in zip(mols, zip(*smiles_opt)):\n",
        "        ecfp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, 2048)\n",
        "        ecfps_opt = [AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(s), 2, 2048) for s in smis_opt]\n",
        "        tanimotos = DataStructs.BulkTanimotoSimilarity(ecfp, ecfps_opt)\n",
        "        tanimotos = np.where(tanimotos==1, 0, tanimotos)    # remove the same mols\n",
        "\n",
        "        orig_score = scoring_func(mol)\n",
        "        for thr in thresholds:\n",
        "            smis_cand = [smis_opt[i] for i in range(max_iter) if tanimotos[i] >= thr]\n",
        "            scores = np.array([scoring_func(Chem.MolFromSmiles(s)) for s in smis_cand])\n",
        "\n",
        "            if np.any(scores>orig_score):\n",
        "                max_improve = scores.max() - orig_score\n",
        "                improved_smi = smis_cand[np.argmax(scores)]\n",
        "            else:\n",
        "                max_improve = float('nan')\n",
        "                improved_smi = None\n",
        "            improved_smiles[f'thr-{thr}'].append(improved_smi)\n",
        "            improved_score[f'thr-{thr}'].append(max_improve)\n",
        "\n",
        "    return improved_smiles, improved_score\n",
        "\n",
        "\n",
        "def featurelize_fragments(dataloader,\n",
        "                          model: nn.Module,\n",
        "                          frag_ecfps: torch.Tensor,\n",
        "                          root: bool= False,\n",
        "                          device: torch.device= torch.device('cpu')\n",
        "                          ):\n",
        "    attn_dict = {i: [] for i in range(len(frag_ecfps))}\n",
        "    start = time.time()\n",
        "    with torch.no_grad():\n",
        "        for iter, data in enumerate(dataloader):\n",
        "            frag_indices = data[0]\n",
        "            features = frag_ecfps[frag_indices.flatten()].reshape(frag_indices.shape[0], frag_indices.shape[1], -1).to(device)\n",
        "            positions = data[1].to(device)\n",
        "\n",
        "            # make mask\n",
        "            src = torch.hstack([torch.full((frag_indices.shape[0], 1), -1), frag_indices.detach()]).to(device)  # for super root\n",
        "            src_mask, _, src_pad_mask, _ = create_mask(src, src, pad_idx= 0, batch_first= True)\n",
        "\n",
        "            # positional embbeding\n",
        "            src = model.fc_ecfp(features) + model.PE(positions)           # (B, L, d_model)\n",
        "\n",
        "            # attach super root\n",
        "            root_embed = model.embed(src.new_zeros(src.shape[0], 1).long())\n",
        "            src = torch.cat([root_embed, src], dim= 1)                    # (B, L+1, d_model)\n",
        "\n",
        "            x = src\n",
        "            attn_values = []\n",
        "            for layer in model.encoder.layers:\n",
        "                attn, attn_map = layer.self_attn(x, x, x, attn_mask= src_mask, key_padding_mask= src_pad_mask, need_weights= True)\n",
        "                x = layer(x, src_mask, src_pad_mask)\n",
        "                attn_value = attn_map[:, 0, :] if root else attn_map.mean(dim= 1)  # if True, use only root node values\n",
        "                attn_values.append(attn_value.unsqueeze(-1))\n",
        "            attn_values = torch.stack(attn_values, dim= -1)                  # (B, L+1, len(layers))\n",
        "\n",
        "            for idxs, attn in zip(frag_indices, attn_values):\n",
        "                for i, values in enumerate(attn[1:]):\n",
        "                    attn_dict[idxs[i].item()].append(values.squeeze(0).tolist())\n",
        "\n",
        "            if (iter==0) | (((iter+1) % 10) == 0) | (iter==len(dataloader)-1):\n",
        "                print(f'[{iter+1}/{len(dataloader)}] elapsed time: {second2date(time.time()-start)}', flush= True)\n",
        "                start = time.time()\n",
        "\n",
        "    attn_mean, attn_std = [], []\n",
        "    for key, values in attn_dict.items():\n",
        "        values = np.array(values)\n",
        "        if len(values) == 0:\n",
        "            mu = [0] * len(model.encoder.layers)\n",
        "            std = [0] * len(model.encoder.layers)\n",
        "        else:\n",
        "            mu = values.mean(axis= 0).tolist()\n",
        "            std = values.std(axis= 0).tolist()\n",
        "        attn_mean.append(mu)\n",
        "        attn_std.append(std)\n",
        "    del attn_dict\n",
        "\n",
        "    return attn_mean, attn_std\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    pmodel = nn.Linear(128, 2)\n",
        "    z = torch.rand(6, 128)\n",
        "    target = torch.ones(6, 2)\n",
        "\n",
        "    best_z = prop_optimize(z, target, pmodel)\n",
        "    print(best_z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nElAuTqTYrkw"
      },
      "outputs": [],
      "source": [
        "# type(uni_fragments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42FxaqmgBHy7"
      },
      "source": [
        "# From here, our original codes appear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T0iAXzSYmdZ"
      },
      "source": [
        "## \"Generate\" function for MOBO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIRW-1WuYwxg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from joblib import Parallel, delayed\n",
        "import time\n",
        "\n",
        "def generate_for_bo(\n",
        "        z_candidates: torch.Tensor,\n",
        "        labels: np.ndarray,\n",
        "        frag_ecfps: torch.Tensor,\n",
        "        ndummys: torch.Tensor,\n",
        "        model: nn.Module,\n",
        "        max_nfrags: int = 30,\n",
        "        useChiral: bool = True,\n",
        "        n_jobs: int = -1,\n",
        "        device: torch.device = torch.device(\"cpu\"),\n",
        "        seed: int = 0\n",
        "    ):\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    labels = np.array(labels)\n",
        "    z_candidates = z_candidates.to(device)\n",
        "    model.eval()\n",
        "    if pmodel:\n",
        "        pmodel.eval()\n",
        "\n",
        "    dec_smiles, pred_list, valid_mask = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # decode latent -> molecular tree\n",
        "        tree_list = model.sequential_decode(\n",
        "            z_candidates,\n",
        "            frag_ecfps,\n",
        "            ndummys,\n",
        "            max_nfrags=max_nfrags,\n",
        "            free_n=False\n",
        "        )\n",
        "\n",
        "        # property prediction\n",
        "        if pmodel:\n",
        "            pred_tensor = pmodel(z_candidates)\n",
        "            pred_list = pred_tensor.cpu().numpy().tolist()\n",
        "        else:\n",
        "            pred_list = None\n",
        "\n",
        "        # constructMol: fragment IDs + adjacency -> SMILES\n",
        "        frag_idxs_list, adjs_list = zip(*[\n",
        "            (\n",
        "                tree.dgl_graph.ndata[\"fid\"].squeeze(-1).tolist(),\n",
        "                tree.adjacency_matrix().tolist()\n",
        "            ) for tree in tree_list\n",
        "        ])\n",
        "\n",
        "        smiles_out = Parallel(n_jobs=n_jobs)(\n",
        "            delayed(constructMol)(\n",
        "                # labels[idxs].tolist(),  # fragment labels\n",
        "                labels[idxs],  # fragment labels\n",
        "                adj,\n",
        "                useChiral=useChiral\n",
        "            )\n",
        "            for idxs, adj in zip(frag_idxs_list, adjs_list)\n",
        "        )\n",
        "        dec_smiles = Parallel(n_jobs= n_jobs)(\n",
        "            delayed(constructMol)(\n",
        "                # labels[idxs].tolist(),\n",
        "                labels[idxs],\n",
        "                adj,\n",
        "                useChiral= useChiral\n",
        "                )\n",
        "            for idxs, adj in zip(frag_idxs_list, adjs_list))\n",
        "        for smi in smiles_out:\n",
        "            if smi is None:\n",
        "                dec_smiles.append(None)\n",
        "                valid_mask.append(False)\n",
        "            else:\n",
        "                # dec_smiles.append(smi)\n",
        "                valid_mask.append(True)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"dec_smiles: \", dec_smiles)\n",
        "    # print(\"smiles_out: \", smiles_out)\n",
        "    return dec_smiles, pred_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfiAn2cKTKc5"
      },
      "source": [
        "## changing directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDQy6YJ0TKJn"
      },
      "outputs": [],
      "source": [
        "experiment_number = \"try_it_to_valify\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eQfY6I7THwN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03793126-578d-473c-dcb2-b8e59b5d2493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/try_it_to_valify/try_it_to_valify_logs\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "path=rf\"/content/drive/{experiment_number}/{experiment_number}_logs\"\n",
        "\n",
        "if os.path.exists(path)==False:\n",
        "  os.makedirs(path)\n",
        "  os.chdir(path)\n",
        "else:\n",
        "  os.chdir(path)\n",
        "\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwGi8Hk_kEjP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyO7FyAGkNS0"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iqVQ0IrkNFO"
      },
      "source": [
        "## preparation to call generative models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4MdHvzQkFkR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c471208e-1615-4efa-d618-e2a68ade17f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---2026-01-30 10:27:55.555487: start.---\n",
            "GPU [0] is available: True\n",
            "\n",
            "load: /content/extracted/Polymer_standardized_struct/input_data/params.yml\n",
            "data: /results/data/Polymer_standardized_struct.csv, useChiral: False, n_jobs: 24\n",
            "fragments: 1955, feature: 2048, tree: (32, 8), prop: None\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "# set parser\n",
        "parser = argparse.ArgumentParser(description='please enter paths')\n",
        "parser.add_argument('--yml', type=str, help='yml file')\n",
        "parser.add_argument('--load_epoch', type=int, default=None)\n",
        "parser.add_argument('--max_nfrags', type=int, default=None)\n",
        "parser.add_argument('--N', type=int, default=5)\n",
        "parser.add_argument('--k', type=int, default=10000)\n",
        "parser.add_argument('--t', type=float, default=1.0)\n",
        "parser.add_argument('--gpu', type=int, default=0)\n",
        "parser.add_argument('--n_jobs', type=int, default=1)\n",
        "parser.add_argument('--free_n', action='store_true')\n",
        "parser.add_argument('--recon', action='store_true', help='reconstruction mode', default=False)\n",
        "parser.add_argument('--gen', action='store_true', help='generation mode', default=True)\n",
        "\n",
        "\n",
        "args, _ = parser.parse_known_args([\n",
        "    \"--yml\", \"/content/extracted/Polymer_standardized_struct/input_data/params.yml\",\n",
        "\n",
        "    \"--N\", \"5\",\n",
        "    \"--k\", \"10000\",\n",
        "    \"--gpu\", \"0\",\n",
        "    \"--n_jobs\", \"24\"\n",
        "])\n",
        "import datetime\n",
        "import gc\n",
        "import pickle\n",
        "import sys\n",
        "import time\n",
        "import warnings\n",
        "from joblib import Parallel, delayed\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yaml\n",
        "# import moses\n",
        "from rdkit import Chem, RDLogger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "lg = RDLogger.logger()\n",
        "lg.setLevel(RDLogger.CRITICAL)\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "\n",
        "\n",
        "\n",
        "if args.recon == args.gen:\n",
        "    args.recon = args.gen = True\n",
        "\n",
        "yml_file = args.yml\n",
        "\n",
        "start = time.time()\n",
        "print(f'---{datetime.datetime.now()}: start.---', flush= True)\n",
        "\n",
        "## check environments\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "    torch.cuda.set_device(args.gpu)\n",
        "else:\n",
        "    device = 'cpu'\n",
        "print(f'GPU [{args.gpu}] is available: {torch.cuda.is_available()}\\n', flush= True)\n",
        "\n",
        "## load hyperparameters\n",
        "with open(yml_file) as yml:\n",
        "    params = yaml.safe_load(yml)\n",
        "print(f'load: {yml_file}', flush= True)\n",
        "\n",
        "# # path\n",
        "\n",
        "result_path= # directory where you want to save your results\n",
        "data_path = \"/results/data/Polymer_standardized_struct.csv\"\n",
        "frag_path = \"/content/extracted/Polymer_standardized_struct/input_data/fragments.csv\"\n",
        "\n",
        "\n",
        "# hyperparameters for decomposition and tree-fragments\n",
        "decomp_params = params['decomp']\n",
        "n_bits = decomp_params['n_bits']\n",
        "max_nfrags = decomp_params['max_nfrags'] if args.max_nfrags is None else args.max_nfrags\n",
        "dupl_bits = decomp_params['dupl_bits']\n",
        "radius = decomp_params['radius']\n",
        "max_depth = decomp_params['max_depth']\n",
        "max_degree = decomp_params['max_degree']\n",
        "useChiral = decomp_params['useChiral']\n",
        "ignore_double = decomp_params['ignore_double']\n",
        "ignore_dummy = decomp_params['ignore_dummy']\n",
        "\n",
        "# hyperparameters for model\n",
        "model_params = params['model']\n",
        "d_model = model_params['d_model']\n",
        "d_ff = model_params['d_ff']\n",
        "num_layers = model_params['nlayer']\n",
        "num_heads = model_params['nhead']\n",
        "activation = model_params['activation']\n",
        "latent_dim = model_params['latent']\n",
        "feat_dim = model_params['feat']\n",
        "props = model_params['property']\n",
        "pnames = list(props.keys())\n",
        "ploss = model_params['ploss']\n",
        "\n",
        "# hyperparameters for training\n",
        "train_params = params['train']\n",
        "batch_size = train_params['batch_size']\n",
        "# batch_size = 128\n",
        "\n",
        "## load data\n",
        "df_frag = pd.read_csv(frag_path)\n",
        "uni_fragments = df_frag['SMILES'].tolist()\n",
        "freq_list = df_frag['frequency'].tolist()\n",
        "try:\n",
        "    with open(os.path.join(result_path, 'input_data', '/content/extracted/Polymer_standardized_struct/input_data/csr_ecfps.pkl'), 'rb') as f:\n",
        "\n",
        "        frag_ecfps = pickle.load(f).toarray()\n",
        "        frag_ecfps = torch.from_numpy(frag_ecfps).float()\n",
        "    assert frag_ecfps.shape[0] == len(uni_fragments)\n",
        "    assert frag_ecfps.shape[1] == (n_bits + dupl_bits)\n",
        "except Exception as e:\n",
        "    print(e, flush= True)\n",
        "    frag_ecfps = torch.tensor(SmilesToMorganFingetPrints(uni_fragments[1:], n_bits= n_bits, dupl_bits= dupl_bits, radius= radius,\n",
        "                                                        ignore_dummy= ignore_dummy, useChiral= useChiral, n_jobs= args.n_jobs)).float()\n",
        "    frag_ecfps = torch.vstack([frag_ecfps.new_zeros(1, n_bits+dupl_bits), frag_ecfps])      # padding feature is zero vector\n",
        "ndummys = torch.tensor(df_frag['ndummys'].tolist()).long()\n",
        "prop_dim = sum(list(props.values())) if pnames else None\n",
        "print(f'data: {data_path}, useChiral: {useChiral}, n_jobs: {args.n_jobs}', flush= True)\n",
        "print(f'fragments: {len(uni_fragments)}, feature: {frag_ecfps.shape[-1]}, tree: ({max_depth}, {max_degree}), prop: {prop_dim}', flush= True)\n",
        "\n",
        "# load model\n",
        "num_labels = frag_ecfps.shape[0]\n",
        "if prop_dim:\n",
        "    pmodel = propLinear(latent_dim, prop_dim).to(device)\n",
        "    if args.load_epoch:\n",
        "        pmodel.load_state_dict(torch.load(os.path.join(result_path, 'models', f'pmodel_iter{args.load_epoch}.pth'), map_location= device))\n",
        "    else:\n",
        "        pmodel.load_state_dict(torch.load(os.path.join(result_path, 'models', f'pmodel_best.pth'), map_location= device))\n",
        "\n",
        "    pmodel.eval()\n",
        "else:\n",
        "    pmodel = None\n",
        "model = FRATTVAE(num_labels, max_depth, max_degree, feat_dim, latent_dim,\n",
        "               d_model, d_ff, num_layers, num_heads, activation).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StwNYhf7w2x4"
      },
      "source": [
        "### $n_{D}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHvB8dpaU0RD"
      },
      "source": [
        "#### our original predictor  $\\mathit{N} \\alpha$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A9r29FO8vPW"
      },
      "source": [
        "#### transplanted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veOLue0po-UQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "493a5f65-3ac5-45af-f01d-a3c997d7fd5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to find the pandas get_adjustment() function to patch\n",
            "Failed to patch pandas - PandasTools will have limited functionality\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit.Chem import Crippen\n",
        "from pickle import load\n",
        "import numpy as np\n",
        "from sklearn.linear_model import  Ridge, Lasso\n",
        "from rdkit import RDLogger\n",
        "import datetime\n",
        "from rdkit import Chem\n",
        "from IPython.display import HTML\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit import rdBase, Chem, DataStructs\n",
        "from rdkit.Chem import AllChem, Draw, Descriptors, PandasTools\n",
        "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
        "import rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF9-0OLj8vPW"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "def N_predictor(SMILES, path_model_alpha, path_model_V, constant):\n",
        "\n",
        "\n",
        "    loaded_model_V = sm.load(path_model_V)\n",
        "\n",
        "    loaded_model_alpha = sm.load(path_model_alpha)\n",
        "\n",
        "\n",
        "\n",
        "    Volume_list_test=[]\n",
        "\n",
        "    false_list_test=[]\n",
        "\n",
        "    data_frame_trying=pd.DataFrame([])\n",
        "    data_frame_smiles=pd.DataFrame([SMILES], columns=[\"SMILES\"])\n",
        "    data_frame_trying=pd.concat([data_frame_trying, data_frame_smiles], axis=1)\n",
        "    smiles=data_frame_trying[\"SMILES\"].to_list()[0]\n",
        "    try:\n",
        "        params = Chem.SmilesParserParams()\n",
        "        params.removeHs = False\n",
        "        m = Chem.MolFromSmiles(smiles,params)\n",
        "        mol= Chem.AddHs(m)\n",
        "        AllChem.EmbedMolecule(mol,useRandomCoords=True)\n",
        "        Volume_list_test.append(AllChem.ComputeMolVolume(mol))\n",
        "\n",
        "    except:\n",
        "        try:\n",
        "            params = Chem.SmilesParserParams()\n",
        "            params.removeHs = False\n",
        "            m = Chem.MolFromSmiles(smiles,params)\n",
        "            mol= Chem.AddHs(m)\n",
        "            AllChem.EmbedMolecule(mol,maxAttempts=5000)\n",
        "            Volume_list_test.append(AllChem.ComputeMolVolume(mol))\n",
        "        except RuntimeError:\n",
        "            false_list_test.append(smiles)\n",
        "    print(\"Volume_list_test\", Volume_list_test)\n",
        "    print(\"false_list_test\", false_list_test)\n",
        "\n",
        "    df_volumelist_test=pd.DataFrame(Volume_list_test, columns=[\"rdkit-Calculated_Volume\"])\n",
        "    data_frame_trying=pd.concat([data_frame_trying, df_volumelist_test], axis=1)\n",
        "\n",
        "    PandasTools.AddMoleculeColumnToFrame(data_frame_trying,'SMILES','Molecule',includeFingerprints=True)\n",
        "    data_frame_trying.head()\n",
        "\n",
        "\n",
        "    descriptors_list2=pd.DataFrame(Descriptors._descList)\n",
        "    a1=descriptors_list2[0]\n",
        "    calc = MoleculeDescriptors.MolecularDescriptorCalculator(a1)\n",
        "    descs = [calc.CalcDescriptors(mol) for mol in data_frame_trying[\"Molecule\"]]\n",
        "\n",
        "    df_deicriptors=pd.DataFrame(descs)\n",
        "    df_deicriptors.head()\n",
        "\n",
        "    # for i in range(0, 210, 1):\n",
        "    for i in range(len(a1)):\n",
        "        df_deicriptors=df_deicriptors.rename(columns={i:a1[i]})\n",
        "        # print(a1[i])\n",
        "    df_deicriptors.head()\n",
        "\n",
        "\n",
        "    data_frame_trying=pd.concat([data_frame_trying, df_deicriptors], axis=1)\n",
        "    df = data_frame_trying.copy()\n",
        "    new_column_train = pd.DataFrame(df[\"fr_unbrch_alkane\"]*df[\"rdkit-Calculated_Volume\"], columns=[\"unbrch-Vol\"])\n",
        "    df = pd.concat([df, new_column_train], axis=1)\n",
        "\n",
        "    adopt_list_alpha =['NumSaturatedRings',\n",
        "                      'MolMR',\n",
        "                      'fr_NH0',\n",
        "                      'fr_NH1',\n",
        "                      'fr_NH2',\n",
        "                      'fr_allylic_oxid',\n",
        "                      'fr_ester',\n",
        "                      'fr_ketone',\n",
        "                      'fr_methoxy',\n",
        "                      'fr_sulfone',\n",
        "                      'unbrch-Vol'\n",
        "                  ]\n",
        "    adopt_list_V = ['fr_C_O_noCOO',\n",
        "                     'fr_allylic_oxid',\n",
        "                     'fr_benzene',\n",
        "                     'fr_ester',\n",
        "                     'fr_sulfone',\n",
        "                     'rdkit-Calculated_Volume',\n",
        "                     'unbrch-Vol'\n",
        "                   ]\n",
        "    df_alpha =df[adopt_list_alpha]\n",
        "    df_V = df[adopt_list_V]\n",
        "    df_alpha =sm.add_constant(df_alpha, has_constant='add')\n",
        "    df_V = sm.add_constant(df_V, has_constant='add')\n",
        "\n",
        "\n",
        "\n",
        "    predictions_alpha = loaded_model_alpha.predict(df_alpha)\n",
        "    print(predictions_alpha)\n",
        "\n",
        "    predictions_V = loaded_model_V.predict(df_V)\n",
        "    print(predictions_V)\n",
        "\n",
        "\n",
        "\n",
        "    alpha_over_V_test=predictions_alpha/predictions_V*constant\n",
        "\n",
        "    n_predcited_test=np.nan_to_num(np.sqrt((1+2*alpha_over_V_test)/(1-alpha_over_V_test)), nan=0)\n",
        "\n",
        "    return n_predcited_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7nUMDeSHdfy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "988f4fe6-c8fe-4855-8bdf-dc55fe752bd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/try_it_to_valify/try_it_to_valify_logs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PA2vXKKto-UR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4069819-2987-4c62-d702-b74333eaee83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to patch pandas - unable to change molecule rendering\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Volume_list_test [100.48000000000002]\n",
            "false_list_test []\n",
            "0    1.222457\n",
            "dtype: float64\n",
            "0    89.847624\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.53831161])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "nD = N_predictor(\"C1CCCCC1\",\n",
        "                \"/content/model_alpha_VIF_2025-10-13.pkl\",\n",
        "                \"/content/model_V_VIF_2025-10-13.pkl\",\n",
        "\n",
        "            23)\n",
        "nD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAV98lzfo-UR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1ef9c3a2-862a-4f13-99b1-28e1257bf25d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.14.5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "import statsmodels\n",
        "statsmodels.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mbk7ECgzo-UR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f5f0defc-d9bb-4a74-a461-b026e7448b73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.26.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0Eli8kJo-UR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a537d5fd-8257-438d-bed1-5563ff518d79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkRB3Ggf8vPX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emxjS_MErlbh"
      },
      "source": [
        "#### new_Nalpha_calcrator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0vYiteLrqAC"
      },
      "outputs": [],
      "source": [
        "def Nalpha_calcurator(smiles_list, path_model_alpha, path_model_V, constant):\n",
        "\n",
        "    i=0\n",
        "    filtered_smiles_list, fail_idx_list, fail_smiles_list \\\n",
        "        = filter_valid_with_timeout(smiles_list)\n",
        "    print(\"fail_smiles_list_Nalpha\",  fail_smiles_list)\n",
        "\n",
        "    list_nD=[]\n",
        "    if not filtered_smiles_list:\n",
        "        return -30.0 * torch.ones(len(smiles_list))\n",
        "    for i in range(len(filtered_smiles_list)):\n",
        "        smiles_chosen = filtered_smiles_list[i]\n",
        "        if i in fail_idx_list:\n",
        "            nD = -30*np.ones(1)\n",
        "            nD_predicted = nD\n",
        "        else:\n",
        "            nD_predicted=N_predictor(smiles_chosen, path_model_alpha, path_model_V, constant)\n",
        "\n",
        "\n",
        "        X=nD_predicted\n",
        "        list_nD.append(X)\n",
        "    _Nalpha_tensor=torch.from_numpy(np.array(list_nD))\n",
        "\n",
        "    Nalpha_tensor = _Nalpha_tensor\n",
        "\n",
        "    return Nalpha_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWn57lhhDn05"
      },
      "source": [
        "### HOMO-LUMO calculation by gpu4pyscf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIH4wdAKy8mm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "80dd87e5-3b2f-4d81-878d-9ca52a98c5f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/try_it_to_valify/try_it_to_valify_logs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHgyC3K3o-US"
      },
      "source": [
        "#### HOMO_LUMO_Gap_predictor(SMILES) gpu4pyscf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0JsvdnTctMT"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from pyscf import gto, scf\n",
        "from gpu4pyscf import scf as gpu_scf\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from pyscf import gto\n",
        "from gpu4pyscf import dft\n",
        "from pyscf.geomopt import geometric_solver\n",
        "# import pubchempy as pcp\n",
        "def HOMO_LUMO_predictor_GPU4pyscf(smiles):\n",
        "    # --- SMILES to #D structure ---\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    mol = Chem.AddHs(mol)\n",
        "    AllChem.EmbedMolecule(mol, randomSeed=1)\n",
        "    AllChem.MMFFOptimizeMolecule(mol)\n",
        "\n",
        "    # --- XYZ ---\n",
        "    xyz_block = Chem.MolToXYZBlock(mol).splitlines()[2:]\n",
        "    xyz_str = \"\\n\".join(xyz_block)\n",
        "\n",
        "    print(\"使用するXYZデータ:\\n\", xyz_str)\n",
        "\n",
        "    # --- PySCF分子を構築 ---\n",
        "    mol_pyscf = gto.M(\n",
        "        atom=xyz_str,   # ←ここが重要：ヘッダー除去済み\n",
        "        basis=\"sto-3g\"\n",
        "    )\n",
        "    start_gpu = time.time()\n",
        "    mf = dft.RKS(mol_pyscf, xc='B3LYP').density_fit().to_gpu()\n",
        "    mf.chkfile = path + '.chk'\n",
        "    mf.verbose = 1\n",
        "    energies = [] # エネルギー記録用\n",
        "    geometries = [] # 座標記録用\n",
        "    def cb(envs): mf = envs['g_scanner'].base # 現在の計算オブジェクトを取得 energies.append(mf.e_tot) # エネルギーをリストに追加 geometries.append(mol.atom_coords(unit=\"ANG\")) # ジオメトリーをリストに追加\n",
        "    conv_params = { 'convergence_energy': 1e-5, 'convergence_grms': 3e-4, 'convergence_gmax': 4.5e-4, 'convergence_drms': 1.2e-3, 'convergence_dmax': 1.8e-3\n",
        "    }\n",
        "    # 構造最適化実行\n",
        "\n",
        "    geometric_solver.optimize(mf, callback=cb, **conv_params)\n",
        "    # GPU計算\n",
        "    end_gpu = time.time()\n",
        "    gpu_time = end_gpu - start_gpu\n",
        "\n",
        "    print(f\"GPU計算時間: {gpu_time:.2f}秒\")\n",
        "    # 最適化後のジオメトリーを取得\n",
        "    final_geometry = mol_pyscf.atom_coords(unit=\"ANG\")\n",
        "    # SCF計算の再実行\n",
        "    mf = dft.RKS(mol_pyscf)\n",
        "    mf.chkfile = 'checkpoint_file.chk'\n",
        "    mf.xc = 'B3LYP'\n",
        "    mf.kernel()\n",
        "    # 計算結果の検証\n",
        "    if mf.mo_occ is not None and len(mf.mo_occ) > 0:\n",
        "        print(\"SCF calculation completed successfully.\")\n",
        "        print(f\"Number of occupied orbitals: {sum(mf.mo_occ > 0)}\")\n",
        "    else:\n",
        "        raise ValueError( \"SCF calculation failed or mo_occ is not properly assigned.\" )\n",
        "    # HOMOおよびLUMOのインデックスを取得\n",
        "    homo_index = (mf.mo_occ > 0).nonzero()[0][-1]\n",
        "    lumo_index = (mf.mo_occ == 0).nonzero()[0][0]\n",
        "    hartree_to_ev = 27.2114\n",
        "    homo = mf.mo_energy[homo_index]*hartree_to_ev\n",
        "    lumo = mf.mo_energy[lumo_index]*hartree_to_ev\n",
        "    gap = lumo-homo\n",
        "    gap = gap.get()\n",
        "    gap = torch.from_numpy(gap)\n",
        "    return gap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRXHCqvZo-US"
      },
      "outputs": [],
      "source": [
        "def GAP_calcurator(smiles_list):\n",
        "\n",
        "    filtered_smiles_list, fail_idx_list, fail_smiles_list \\\n",
        "        = filter_valid_with_timeout(smiles_list)\n",
        "    print(\"fail_smiles_list\",  fail_smiles_list)\n",
        "\n",
        "\n",
        "\n",
        "    list_GAP=[]\n",
        "    if not filtered_smiles_list:\n",
        "        print(\"len(filtered_smiles_list): \", len(filtered_smiles_list))\n",
        "        return -30.0 * torch.ones(len(smiles_list))\n",
        "\n",
        "    for number_chosen in range(len(smiles_list)):\n",
        "        if number_chosen in fail_idx_list:\n",
        "\n",
        "            GAP = -30*np.ones(1)\n",
        "        else:\n",
        "\n",
        "            smiles_chosen = filtered_smiles_list[number_chosen]\n",
        "\n",
        "            print(\"smiles_chosen: \", smiles_chosen)\n",
        "\n",
        "            GAP=HOMO_LUMO_predictor_GPU4pyscf(smiles_chosen).detach().numpy()\n",
        "            GAP = GAP*np.ones(1)\n",
        "\n",
        "        print(\"GAP: \", GAP)\n",
        "        print(\"GAP type: \", type(GAP))\n",
        "        list_GAP.append(GAP)\n",
        "    print(\"list_GAP: \", list_GAP)\n",
        "    _GAP_tensor=torch.from_numpy(np.array(list_GAP))\n",
        "    GAP_tensor = _GAP_tensor\n",
        "\n",
        "\n",
        "    print(\"_GAP_tensor: \", _GAP_tensor)\n",
        "\n",
        "\n",
        "    return GAP_tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkxN6cGtdafI"
      },
      "source": [
        "## obj_func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXEzykmK23Qt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "35ba1edf-04c1-4fa9-c909-68a1ffa4da4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/try_it_to_valify/try_it_to_valify_logs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4qIKN39MTR9"
      },
      "source": [
        "#### obj_func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8ZJO9yxa14S"
      },
      "outputs": [],
      "source": [
        "\n",
        "def obj_func(z, vae, q):\n",
        "\n",
        "    z = z.to(torch.float32)\n",
        "\n",
        "\n",
        "    z = z.detach().cpu()[:q, :256].cuda()\n",
        "\n",
        "\n",
        "    results_picker = []\n",
        "\n",
        "    result_collector = torch.tensor([]).to(\"cuda\")\n",
        "    smiles_list = []\n",
        "    # for i in z.size()[0]:\n",
        "    for i in range(q):\n",
        "        # print(f\"{i} of {q} (q = {q})in the roop has started generation\")\n",
        "        z_chosen = z[i:i+1, :256]\n",
        "        # print(\"z_chosen:  \", z_chosen)\n",
        "        dataloader = DataLoader(\n",
        "            TensorDataset(z_chosen), batch_size=batch_size, shuffle=False\n",
        "        )\n",
        "\n",
        "        dec_smiles, pred_list = generate_for_bo(\n",
        "            z_chosen,\n",
        "            labels=uni_fragments,\n",
        "            frag_ecfps=frag_ecfps,\n",
        "            ndummys=torch.tensor(df_frag[\"ndummys\"].tolist()).long(),\n",
        "            model=model,\n",
        "            max_nfrags=30,\n",
        "            useChiral=True,\n",
        "            n_jobs=-1,\n",
        "            device=torch.device(\"cuda\")\n",
        "            if torch.cuda.is_available()\n",
        "            else torch.device(\"cpu\"),\n",
        "            seed=0,\n",
        "        )\n",
        "\n",
        "\n",
        "        smiles_list.append(dec_smiles)\n",
        "\n",
        "    Nalpha = Nalpha_calcurator(smiles_list,\n",
        "                               \"/content/model_alpha_VIF_2025-10-13.pkl\",\n",
        "                               \"/content/model_V_VIF_2025-10-13.pkl\",\n",
        "                                2.3e1).double().squeeze(-1)\n",
        "\n",
        "    GAP = GAP_calcurator(smiles_list).double()\n",
        "\n",
        "    for j in range(q):\n",
        "        Nalpha_chosen = Nalpha[j]\n",
        "        Nalpha_chosen = Nalpha_chosen.reshape(1, 1)\n",
        "\n",
        "        GAP_chosen = GAP[j]\n",
        "        GAP_chosen = GAP_chosen.reshape(1, 1)\n",
        "\n",
        "        result_tensor_concatnated = torch.cat([Nalpha_chosen, GAP_chosen], dim=-1).double().to(\"cuda\")\n",
        "        if j== 0:\n",
        "            result_collector = result_tensor_concatnated.double().to(\"cuda\")\n",
        "        else:\n",
        "            result_collector = torch.cat([result_collector, result_tensor_concatnated], dim=-1).double().to(\"cuda\")\n",
        "    result_collector = result_collector.double().to(\"cuda\")\n",
        "\n",
        "\n",
        "    if torch.cuda.is_available:\n",
        "\n",
        "        return result_collector.double().to(\"cuda\"), smiles_list\n",
        "    else:\n",
        "        return result_collector.double(), smiles_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmycGvtxahfc"
      },
      "source": [
        "## MOBO roupes implemented by BoTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfl9n1jZhAda"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import torch\n",
        "import math\n",
        "from botorch.optim import optimize_acqf\n",
        "from botorch.acquisition import UpperConfidenceBound\n",
        "# from botorch.models import SingleTaskGP\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from botorch.utils.transforms import (standardize,\n",
        "                                      normalize,\n",
        "                                      unnormalize)\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "\n",
        "\n",
        "from botorch.utils.multi_objective.box_decompositions import NondominatedPartitioning\n",
        "from botorch.acquisition.multi_objective.logei import qLogNoisyExpectedHypervolumeImprovement\n",
        "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from botorch.models import SingleTaskGP, ModelListGP\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit.Chem import Crippen\n",
        "from pickle import load\n",
        "import numpy as np\n",
        "from sklearn.linear_model import  Ridge, Lasso\n",
        "from rdkit import RDLogger\n",
        "import datetime\n",
        "from rdkit import Chem\n",
        "from IPython.display import HTML\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit import rdBase, Chem, DataStructs\n",
        "from rdkit.Chem import AllChem, Draw, Descriptors, PandasTools\n",
        "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
        "import rdkit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLV5h2lno-UT"
      },
      "source": [
        "#### preparation of repeating_detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fecCNtMoo-UT"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "import networkx as nx\n",
        "from networkx.algorithms import isomorphism\n",
        "from collections import defaultdict\n",
        "\n",
        "def mol_to_nx(mol):\n",
        "    \"\"\"RDKit Mol -> NetworkX Graph\"\"\"\n",
        "    G = nx.Graph()\n",
        "    for atom in mol.GetAtoms():\n",
        "        idx = atom.GetIdx()\n",
        "        G.add_node(idx,\n",
        "                   atom_symbol=atom.GetSymbol(),\n",
        "                   aromatic=atom.GetIsAromatic(),\n",
        "                   atomic_num=atom.GetAtomicNum())\n",
        "    for bond in mol.GetBonds():\n",
        "        a, b = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "        btype = str(bond.GetBondType())\n",
        "        G.add_edge(a, b, bond_type=btype)\n",
        "    return G\n",
        "\n",
        "def get_ring_systems(mol):\n",
        "    \"\"\"\n",
        "    With the help of ChatGPT\n",
        "    \"\"\"\n",
        "    ri = mol.GetRingInfo()\n",
        "    atom_rings = [set(r) for r in ri.AtomRings()]\n",
        "    ring_graph = nx.Graph()\n",
        "    for i in range(len(atom_rings)):\n",
        "        ring_graph.add_node(i)\n",
        "    for i in range(len(atom_rings)):\n",
        "        for j in range(i + 1, len(atom_rings)):\n",
        "            if atom_rings[i] & atom_rings[j]:  # 原子を共有しているなら融合\n",
        "                ring_graph.add_edge(i, j)\n",
        "    # 連結成分ごとに fused ring system をまとめる\n",
        "    ring_systems = []\n",
        "    for comp in nx.connected_components(ring_graph):\n",
        "        atoms_in_system = set().union(*[atom_rings[i] for i in comp])\n",
        "        ring_systems.append(sorted(list(atoms_in_system)))\n",
        "    return ring_systems\n",
        "\n",
        "def wl_hash_subgraph(G, node_indices):\n",
        "    subG = G.subgraph(node_indices).copy()\n",
        "    try:\n",
        "        h = nx.weisfeiler_lehman_graph_hash(subG, node_attr='atom_symbol', edge_attr='bond_type')\n",
        "    except TypeError:\n",
        "        h = nx.weisfeiler_lehman_graph_hash(subG)\n",
        "    return h, subG\n",
        "\n",
        "def is_isomorphic(G1, G2):\n",
        "    nm = isomorphism.categorical_node_match(['atom_symbol', 'aromatic'], [None, None])\n",
        "    em = isomorphism.categorical_edge_match('bond_type', None)\n",
        "    GM = isomorphism.GraphMatcher(G1, G2, node_match=nm, edge_match=em)\n",
        "    return GM.is_isomorphic()\n",
        "\n",
        "\n",
        "def subgraph_to_smiles(mol, atom_indices):\n",
        "    atom_set = set(atom_indices)\n",
        "    emol = Chem.EditableMol(Chem.Mol())\n",
        "\n",
        "\n",
        "    atom_map = {}\n",
        "    for old_idx in atom_indices:\n",
        "        old_atom = mol.GetAtomWithIdx(old_idx)\n",
        "        new_atom = Chem.Atom(old_atom.GetSymbol())\n",
        "        new_atom.SetIsAromatic(old_atom.GetIsAromatic())\n",
        "        new_idx = emol.AddAtom(new_atom)\n",
        "        atom_map[old_idx] = new_idx\n",
        "\n",
        "    # Add bonding if needed\n",
        "    for bond in mol.GetBonds():\n",
        "        a1, a2 = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "        if a1 in atom_set and a2 in atom_set:\n",
        "            emol.AddBond(atom_map[a1], atom_map[a2], bond.GetBondType())\n",
        "\n",
        "    submol = emol.GetMol()\n",
        "    Chem.SanitizeMol(submol)\n",
        "\n",
        "    # canonical SMILES to close the rings\n",
        "    smi = Chem.MolToSmiles(submol, canonical=True)\n",
        "    return smi\n",
        "\n",
        "def extract_fused_ring_systems_with_smiles(smiles, verbose=True):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        raise ValueError(\"Invalid SMILES\")\n",
        "\n",
        "    G = mol_to_nx(mol)\n",
        "    ring_systems = get_ring_systems(mol)\n",
        "    if verbose:\n",
        "        print(f\"Found {len(ring_systems)} ring systems\")\n",
        "\n",
        "    groups = defaultdict(list)\n",
        "    cache = {}\n",
        "    for rs_atoms in ring_systems:\n",
        "        h, subG = wl_hash_subgraph(G, rs_atoms)\n",
        "        cache[h] = subG\n",
        "        groups[h].append(rs_atoms)\n",
        "\n",
        "    motifs = []\n",
        "    for h, ring_lists in groups.items():\n",
        "        buckets = []\n",
        "        for atoms in ring_lists:\n",
        "            sg = G.subgraph(atoms).copy()\n",
        "            placed = False\n",
        "            for b in buckets:\n",
        "                rep_atoms = b[0]\n",
        "                rep_sg = G.subgraph(rep_atoms).copy()\n",
        "                if is_isomorphic(rep_sg, sg):\n",
        "                    b.append(atoms)\n",
        "                    placed = True\n",
        "                    break\n",
        "            if not placed:\n",
        "                buckets.append([atoms])\n",
        "\n",
        "        for b in buckets:\n",
        "            rep_atoms = b[0]\n",
        "            rep_smi = subgraph_to_smiles(mol, rep_atoms)\n",
        "            motifs.append({\n",
        "                \"count\": len(b),\n",
        "                \"atom_indices\": b,\n",
        "                \"smiles\": rep_smi,\n",
        "                \"ring_size\": len(rep_atoms),\n",
        "            })\n",
        "\n",
        "    if verbose:\n",
        "        for m in motifs:\n",
        "            print(f\"Motif: {m['smiles']}  (count={m['count']}, atoms={m['atom_indices'][0]})\")\n",
        "    return motifs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgFk9mlio-UT"
      },
      "source": [
        "#### filter_valid sanitizing generated molecule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5ci9gpibpSV"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import math\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.Descriptors import ExactMolWt\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "def trying_roop_of_filter_valid(each_smiles):\n",
        "    success_smiles = []\n",
        "    # fail_idx_ = []\n",
        "    fail_smiles = []\n",
        "    try:\n",
        "        smiles = Chem.MolToSmiles(Chem.MolFromSmiles(each_smiles))\n",
        "        Mn=ExactMolWt(Chem.MolFromSmiles(smiles))\n",
        "        if Mn<100:\n",
        "            # Delete error-causing molecule beforehand\n",
        "            mol = Chem.AddHs(Chem.MolFromSmiles(smiles))\n",
        "            target_atom_symbol = \"Si\"  # The symbol of the atom you are searching for\n",
        "            found_atoms = []\n",
        "\n",
        "            for atom in mol.GetAtoms():\n",
        "                if atom.GetSymbol() == target_atom_symbol:\n",
        "                    found_atoms.append(atom)\n",
        "                    # fail_idx_list.append(each_idx)\n",
        "                    fail_smiles.append(each_smiles)\n",
        "                    success_smiles.append(\"C\")\n",
        "                    continue\n",
        "\n",
        "            if not found_atoms:\n",
        "                # print(f\"No {target_atom_symbol} atoms found in the SMILES string.\")\n",
        "                ring_info = mol.GetRingInfo()\n",
        "                # counting ring number\n",
        "                num_atoms = mol.GetNumAtoms()\n",
        "\n",
        "                list_num_rings=[]\n",
        "                for i in range(num_atoms):\n",
        "                    for j in enumerate(ring_info.AtomRingSizes(i)):\n",
        "                        # print(j[1])\n",
        "                        list_num_rings.append(j[1])\n",
        "                if list_num_rings ==[]:\n",
        "                    success_smiles.append(smiles)\n",
        "                else:\n",
        "                    max_ring_size=max(list_num_rings)\n",
        "\n",
        "                    if max_ring_size<8:\n",
        "                        AllChem.EmbedMolecule(mol)\n",
        "                        AllChem.ComputeMolVolume(mol)\n",
        "\n",
        "                        success_smiles.append(smiles)\n",
        "\n",
        "        else: #Mn>1000\n",
        "            motifs = extract_fused_ring_systems_with_smiles(smiles)\n",
        "            smiles_fragments = motifs[0][\"smiles\"]\n",
        "            print(\"smiles_fragments: \", smiles_fragments)\n",
        "            mol = Chem.AddHs(Chem.MolFromSmiles(smiles_fragments))\n",
        "            found_atoms = []\n",
        "\n",
        "            for atom in mol.GetAtoms():\n",
        "\n",
        "                target_atom_symbol = \"Si\"\n",
        "                if atom.GetSymbol() == target_atom_symbol:\n",
        "                    found_atoms.append(atom)\n",
        "                    # fail_idx_list.append(each_idx)\n",
        "                    fail_smiles.append(smiles_fragments)\n",
        "                    success_smiles.append(\"C\")\n",
        "                    continue\n",
        "            if not found_atoms:\n",
        "\n",
        "                ring_info = mol.GetRingInfo()\n",
        "\n",
        "                num_atoms = mol.GetNumAtoms()\n",
        "\n",
        "                list_num_rings=[]\n",
        "                for i in range(num_atoms):\n",
        "                    for j in enumerate(ring_info.AtomRingSizes(i)):\n",
        "\n",
        "                        list_num_rings.append(j[1])\n",
        "                if list_num_rings ==[]:\n",
        "                    success_smiles.append(smiles_fragments)\n",
        "                else:\n",
        "                    max_ring_size=max(list_num_rings)\n",
        "\n",
        "                    if max_ring_size<8:\n",
        "                        AllChem.EmbedMolecule(mol)\n",
        "                        AllChem.ComputeMolVolume(mol)\n",
        "\n",
        "                        success_smiles.append(smiles_fragments)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    except:\n",
        "        success_smiles.append(\"C\")\n",
        "        fail_smiles.append(each_smiles)\n",
        "    return success_smiles, fail_smiles\n",
        "\n",
        "def filter_valid(smiles_list):\n",
        "    print(\"before_filter: \", smiles_list)\n",
        "    success_list = []\n",
        "    fail_idx_list = []\n",
        "    fail_smiles_list = []\n",
        "    if len(smiles_list)==1:\n",
        "        each_idx = 0\n",
        "        each_smiles = smiles_list[0][0] if type(smiles_list[0][0]) == \"str\" else  smiles_list[0][0][0]\n",
        "        success_list, fail_smiles_list = trying_roop_of_filter_valid(each_smiles)\n",
        "\n",
        "    else:\n",
        "        for each_idx, each_smiles in enumerate(smiles_list):\n",
        "\n",
        "            success_list_sub, fail_smiles_list_sub = trying_roop_of_filter_valid(each_smiles[0])\n",
        "            if success_list_sub == []:\n",
        "                fail_idx_list.append(each_idx)\n",
        "                fail_smiles_list.append(each_smiles[0])\n",
        "\n",
        "            else:\n",
        "\n",
        "              success_list.append(success_list_sub[0])\n",
        "\n",
        "    print(\"success_list: \", success_list)\n",
        "    return success_list, fail_idx_list,fail_smiles_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrYqRxV6o-UU"
      },
      "outputs": [],
      "source": [
        "from timeout_decorator import timeout, TimeoutError\n",
        "\n",
        "@timeout_decorator.timeout(60)\n",
        "def filter_valid_with_timeout(smiles_list):\n",
        "    try:\n",
        "        success_list, fail_idx_list,fail_smiles_list = filter_valid(smiles_list)\n",
        "        return success_list, fail_idx_list,fail_smiles_list\n",
        "    except timeout_decorator.timeout_decorator.TimeoutError:\n",
        "        return list([\"C\", \"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",]), np.arange(0, len(smiles_list), 1).tolist(), smiles_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo_ieUnNcqHI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "189c72de-4fae-4f13-8907-5165a9a06c49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FRATTVAE(\n",
              "  (embed): Embedding(1, 512)\n",
              "  (fc_ecfp): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "    (1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  )\n",
              "  (PE): TreePositionalEncoding(\n",
              "    (fc): Linear(in_features=512, out_features=512, bias=True)\n",
              "  )\n",
              "  (encoder): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc_vae): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (1): Linear(in_features=256, out_features=512, bias=True)\n",
              "  )\n",
              "  (fc_memory): Linear(in_features=256, out_features=512, bias=True)\n",
              "  (decoder): TransformerDecoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc_dec): Linear(in_features=512, out_features=1955, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7frT4Hmo-UU"
      },
      "source": [
        "####  distance_constraint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYc30uULKrE0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.manual_seed(0)\n",
        "def distance_constraint(X):\n",
        "    eps = 0.1\n",
        "    return torch.min(torch.norm(X - 1, dim=-1)) - eps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vmVpC-Xo-UU"
      },
      "source": [
        "#### optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOdYpidHatC5",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75dd14c2-7bad-45d3-b13b-75897728e406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiple_tensor.size():  torch.Size([1, 2])\n",
            "Multiple_tensor.device:  cuda:0\n",
            "Multiple_tensor.shape: torch.Size([1, 2])\n",
            "z_tensor.shape: torch.Size([1, 256])\n",
            "z_tensor.device: cuda:0\n",
            "M:  2\n",
            "ref_point.device:  cuda:0\n",
            "bounds.device:  cuda:0\n",
            "Loop 1 starts\n",
            "dec_smiles:  ['CN1C(=O)c2cc3c(c(-c4c5c(c(-c6c7c(c(-c8c9c(c(-c%10c%11c(c(-c%12c%13c(c(-c%14c%15c(c(-c%16c%17c(c(-c%18c%19c(c(-c%20c%21c(c(-c%22c%23c(c(-c%24c%25c(c(-c%26c%27c(c(-c%28c%29c(c(-c%30c%31c(c(-c%32c%33c(c(-c%34c%35c(c(-c%36c%37c(c(-c%38c%39c(c(-c%40c%41c(c(-c%42c%43c(c(-c%44c%45c(c(-c%46c%47c(c(-c%48c%49c(c(-c%50c%51c(c(-c%52c%53c(c(-c%54c%55c(c(-c%56c%57c(c(-c%58c%59c(c(-c%60c%61c(cc%62c%60C(=O)C(C)(C)C%62O)C(=O)N(C)C%61=O)c%60c%58C(=O)C(C)(C)C%60O)C(=O)N(C)C%59=O)c%58c%56C(=O)C(C)(C)C%58O)C(=O)N(C)C%57=O)c%56c%54C(=O)C(C)(C)C%56O)C(=O)N(C)C%55=O)c%54c%52C(=O)C(C)(C)C%54O)C(=O)N(C)C%53=O)c%52c%50C(=O)C(C)(C)C%52O)C(=O)N(C)C%51=O)c%50c%48C(=O)C(C)(C)C%50O)C(=O)N(C)C%49=O)c%48c%46C(=O)C(C)(C)C%48O)C(=O)N(C)C%47=O)c%46c%44C(=O)C(C)(C)C%46O)C(=O)N(C)C%45=O)c%44c%42C(=O)C(C)(C)C%44O)C(=O)N(C)C%43=O)c%42c%40C(=O)C(C)(C)C%42O)C(=O)N(C)C%41=O)c%40c%38C(=O)C(C)(C)C%40O)C(=O)N(C)C%39=O)c%38c%36C(=O)C(C)(C)C%38O)C(=O)N(C)C%37=O)c%36c%34C(=O)C(C)(C)C%36O)C(=O)N(C)C%35=O)c%34c%32C(=O)C(C)(C)C%34O)C(=O)N(C)C%33=O)c%32c%30C(=O)C(C)(C)C%32O)C(=O)N(C)C%31=O)c%30c%28C(=O)C(C)(C)C%30O)C(=O)N(C)C%29=O)c%28c%26C(=O)C(C)(C)C%28O)C(=O)N(C)C%27=O)c%26c%24C(=O)C(C)(C)C%26O)C(=O)N(C)C%25=O)c%24c%22C(=O)C(C)(C)C%24O)C(=O)N(C)C%23=O)c%22c%20C(=O)C(C)(C)C%22O)C(=O)N(C)C%21=O)c%20c%18C(=O)C(C)(C)C%20O)C(=O)N(C)C%19=O)c%18c%16C(=O)C(C)(C)C%18O)C(=O)N(C)C%17=O)c%16c%14C(=O)C(C)(C)C%16O)C(=O)N(C)C%15=O)c%14c%12C(=O)C(C)(C)C%14O)C(=O)N(C)C%13=O)c%12c%10C(=O)C(C)(C)C%12O)C(=O)N(C)C%11=O)c%10c8C(=O)C(C)(C)C%10O)C(=O)N(C)C9=O)c8c6C(=O)C(C)(C)C8O)C(=O)N(C)C7=O)c6c4C(=O)C(C)(C)C6O)C(=O)N(C)C5=O)c2C1=O)C(=O)C(C)(C)C3O']\n",
            "dec_smiles:  ['[CH2][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH2]']\n",
            "dec_smiles:  ['CC1(C)COc2cn(-n3cc4c(c3)OCC(C)(C)CO4)cc2OC1']\n",
            "dec_smiles:  ['c1cc2cc3sc(-c4cc5cc6sccc6c(-c6cc7cc8sccc8c(-c8cc9cc%10sccc%10c(-c%10cc%11cc%12sccc%12c(-c%12cc%13cc%14sccc%14c(-c%14cc%15cc%16sccc%16c(-c%16cc%17cc%18sccc%18c(-c%18cc%19cc%20sccc%20c(-c%20cc%21cc%22sccc%22c(-c%22cc%23cc%24sccc%24c(-c%24cc%25cc%26sccc%26c(-c%26cc%27cc%28sccc%28c(-c%28cc%29cc%30sccc%30c(-c%30cc%31cc%32sccc%32c(-c%32cc%33cc%34sccc%34c(-c%34cc%35cc%36sccc%36c(-c%36cc%37cc%38sccc%38c(-c%38cc%39cc%40sccc%40c(-c%40cc%41cc%42sccc%42c(-c%42cc%43cc%44sccc%44c(-c%44cc%45cc%46sccc%46c(-c%46cc%47cc%48sccc%48c(-c%48cc%49cc%50sccc%50c(-c%50cc%51cc%52sccc%52c(-c%52cc%53cc%54sccc%54c(-c%54cc%55cc%56sccc%56c(-c%56cc%57cc%58sccc%58c(-c%58cc%59cc%60sccc%60c(-c%60cc%61cc%62sccc%62cc%61s%60)c%59s%58)c%57s%56)c%55s%54)c%53s%52)c%51s%50)c%49s%48)c%47s%46)c%45s%44)c%43s%42)c%41s%40)c%39s%38)c%37s%36)c%35s%34)c%33s%32)c%31s%30)c%29s%28)c%27s%26)c%25s%24)c%23s%22)c%21s%20)c%19s%18)c%17s%16)c%15s%14)c%13s%12)c%11s%10)c9s8)c7s6)c5s4)cc3cc2s1']\n",
            "dec_smiles:  ['Cn1c2c(c3c1c1c(n3C)=NC=[SH]1)[SH]=CN=2']\n",
            "dec_smiles:  ['Fc1c2cc(-c3cc4c(F)c5scc(-c6cc7c(F)c8scc(-c9cc%10c(F)c%11scc(-c%12cc%13c(F)c%14scc(-c%15cc%16c(F)c%17scc(-c%18cc%19c(F)c%20scc(-c%21cc%22c(F)c%23scc(-c%24cc%25c(F)c%26scc(-c%27cc%28c(F)c%29scc(-c%30cc%31c(F)c%32scc(-c%33cc%34c(F)c%35scc(-c%36cc%37c(F)c%38scc(-c%39cc%40c(F)c%41scc(-c%42cc%43c(F)c%44scc(-c%45cc%46c(F)c%47scc(-c%48cc%49c(F)c%50scc(-c%51cc%52c(F)c%53scc(-c%54cc%55c(F)c%56scc(-c%57cc%58c(F)c%59scc(-c%60cc%61c(F)c%62scc(-c%63cc%64c(F)c%65scc(-c%66cc%67c(F)c%68scc(-c%69cc%70c(F)c%71scc(-c%72cc%73c(F)c%74scc(-c%75cc%76c(F)c%77scc(-c%78cc%79c(F)c%80scc(-c%81cc%82c(F)c%83scc(-c%84cc%85c(F)c%86scc(-c%87cc%88c(F)c%89sccc%89c(F)c%88s%87)c%86c(F)c%85s%84)c%83c(F)c%82s%81)c%80c(F)c%79s%78)c%77c(F)c%76s%75)c%74c(F)c%73s%72)c%71c(F)c%70s%69)c%68c(F)c%67s%66)c%65c(F)c%64s%63)c%62c(F)c%61s%60)c%59c(F)c%58s%57)c%56c(F)c%55s%54)c%53c(F)c%52s%51)c%50c(F)c%49s%48)c%47c(F)c%46s%45)c%44c(F)c%43s%42)c%41c(F)c%40s%39)c%38c(F)c%37s%36)c%35c(F)c%34s%33)c%32c(F)c%31s%30)c%29c(F)c%28s%27)c%26c(F)c%25s%24)c%23c(F)c%22s%21)c%20c(F)c%19s%18)c%17c(F)c%16s%15)c%14c(F)c%13s%12)c%11c(F)c%10s9)c8c(F)c7s6)c5c(F)c4s3)sc2c(F)c2ccsc12']\n",
            "dec_smiles:  ['C1=CSC(C2=CSC(C3=CSC(C4=CSC(C5=CSC(C6=CSC(C7=CSC(C8=CSC(C9=CSC(C%10=CSC(C%11=CSC(C%12=CSC(C%13=CSC(C%14=CSC(C%15=CSC(C%16=CSC(C%17=CSC(C%18=CSC(C%19=CSC(C%20=CSC(C%21=CSC(C%22=CSC(C%23=CSC(C%24=CSC(C%25=CSC(C%26=CSC(C%27=CSC(C%28=CSC(C%29=CSC(C%30CC=CS%30)C%29)C%28)C%27)C%26)C%25)C%24)C%23)C%22)C%21)C%20)C%19)C%18)C%17)C%16)C%15)C%14)C%13)C%12)C%11)C%10)C9)C8)C7)C6)C5)C4)C3)C2)C1']\n",
            "dec_smiles:  ['c1cc2c(-c3cc4c(-c5cc6c(-c7cc8c(-c9cc%10c(-c%11cc%12c(-c%13cc%14c(-c%15cc%16c(-c%17cc%18c(-c%19cc%20c(-c%21cc%22c(-c%23cc%24c(-c%25cc%26c(-c%27cc%28c(-c%29cc%30c(-c%31cc%32c(-c%33cc%34c(-c%35cc%36c(-c%37cc%38c(-c%39cc%40c(-c%41cc%42c(-c%43cc%44c(-c%45cc%46c(-c%47cc%48c(-c%49cc%50c(-c%51cc%52c(-c%53cc%54c(-c%55cc%56c(-c%57cc%58c(-c%59c%60ccsc%60cc%60ccsc%59%60)c%59sccc%59cc%58s%57)c%57sccc%57cc%56s%55)c%55sccc%55cc%54s%53)c%53sccc%53cc%52s%51)c%51sccc%51cc%50s%49)c%49sccc%49cc%48s%47)c%47sccc%47cc%46s%45)c%45sccc%45cc%44s%43)c%43sccc%43cc%42s%41)c%41sccc%41cc%40s%39)c%39sccc%39cc%38s%37)c%37sccc%37cc%36s%35)c%35sccc%35cc%34s%33)c%33sccc%33cc%32s%31)c%31sccc%31cc%30s%29)c%29sccc%29cc%28s%27)c%27sccc%27cc%26s%25)c%25sccc%25cc%24s%23)c%23sccc%23cc%22s%21)c%21sccc%21cc%20s%19)c%19sccc%19cc%18s%17)c%17sccc%17cc%16s%15)c%15sccc%15cc%14s%13)c%13sccc%13cc%12s%11)c%11sccc%11cc%10s9)c9sccc9cc8s7)c7sccc7cc6s5)c5sccc5cc4s3)c3sccc3cc2s1']\n",
            "before_filter:  [['CN1C(=O)c2cc3c(c(-c4c5c(c(-c6c7c(c(-c8c9c(c(-c%10c%11c(c(-c%12c%13c(c(-c%14c%15c(c(-c%16c%17c(c(-c%18c%19c(c(-c%20c%21c(c(-c%22c%23c(c(-c%24c%25c(c(-c%26c%27c(c(-c%28c%29c(c(-c%30c%31c(c(-c%32c%33c(c(-c%34c%35c(c(-c%36c%37c(c(-c%38c%39c(c(-c%40c%41c(c(-c%42c%43c(c(-c%44c%45c(c(-c%46c%47c(c(-c%48c%49c(c(-c%50c%51c(c(-c%52c%53c(c(-c%54c%55c(c(-c%56c%57c(c(-c%58c%59c(c(-c%60c%61c(cc%62c%60C(=O)C(C)(C)C%62O)C(=O)N(C)C%61=O)c%60c%58C(=O)C(C)(C)C%60O)C(=O)N(C)C%59=O)c%58c%56C(=O)C(C)(C)C%58O)C(=O)N(C)C%57=O)c%56c%54C(=O)C(C)(C)C%56O)C(=O)N(C)C%55=O)c%54c%52C(=O)C(C)(C)C%54O)C(=O)N(C)C%53=O)c%52c%50C(=O)C(C)(C)C%52O)C(=O)N(C)C%51=O)c%50c%48C(=O)C(C)(C)C%50O)C(=O)N(C)C%49=O)c%48c%46C(=O)C(C)(C)C%48O)C(=O)N(C)C%47=O)c%46c%44C(=O)C(C)(C)C%46O)C(=O)N(C)C%45=O)c%44c%42C(=O)C(C)(C)C%44O)C(=O)N(C)C%43=O)c%42c%40C(=O)C(C)(C)C%42O)C(=O)N(C)C%41=O)c%40c%38C(=O)C(C)(C)C%40O)C(=O)N(C)C%39=O)c%38c%36C(=O)C(C)(C)C%38O)C(=O)N(C)C%37=O)c%36c%34C(=O)C(C)(C)C%36O)C(=O)N(C)C%35=O)c%34c%32C(=O)C(C)(C)C%34O)C(=O)N(C)C%33=O)c%32c%30C(=O)C(C)(C)C%32O)C(=O)N(C)C%31=O)c%30c%28C(=O)C(C)(C)C%30O)C(=O)N(C)C%29=O)c%28c%26C(=O)C(C)(C)C%28O)C(=O)N(C)C%27=O)c%26c%24C(=O)C(C)(C)C%26O)C(=O)N(C)C%25=O)c%24c%22C(=O)C(C)(C)C%24O)C(=O)N(C)C%23=O)c%22c%20C(=O)C(C)(C)C%22O)C(=O)N(C)C%21=O)c%20c%18C(=O)C(C)(C)C%20O)C(=O)N(C)C%19=O)c%18c%16C(=O)C(C)(C)C%18O)C(=O)N(C)C%17=O)c%16c%14C(=O)C(C)(C)C%16O)C(=O)N(C)C%15=O)c%14c%12C(=O)C(C)(C)C%14O)C(=O)N(C)C%13=O)c%12c%10C(=O)C(C)(C)C%12O)C(=O)N(C)C%11=O)c%10c8C(=O)C(C)(C)C%10O)C(=O)N(C)C9=O)c8c6C(=O)C(C)(C)C8O)C(=O)N(C)C7=O)c6c4C(=O)C(C)(C)C6O)C(=O)N(C)C5=O)c2C1=O)C(=O)C(C)(C)C3O'], ['[CH2][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH2]'], ['CC1(C)COc2cn(-n3cc4c(c3)OCC(C)(C)CO4)cc2OC1'], ['c1cc2cc3sc(-c4cc5cc6sccc6c(-c6cc7cc8sccc8c(-c8cc9cc%10sccc%10c(-c%10cc%11cc%12sccc%12c(-c%12cc%13cc%14sccc%14c(-c%14cc%15cc%16sccc%16c(-c%16cc%17cc%18sccc%18c(-c%18cc%19cc%20sccc%20c(-c%20cc%21cc%22sccc%22c(-c%22cc%23cc%24sccc%24c(-c%24cc%25cc%26sccc%26c(-c%26cc%27cc%28sccc%28c(-c%28cc%29cc%30sccc%30c(-c%30cc%31cc%32sccc%32c(-c%32cc%33cc%34sccc%34c(-c%34cc%35cc%36sccc%36c(-c%36cc%37cc%38sccc%38c(-c%38cc%39cc%40sccc%40c(-c%40cc%41cc%42sccc%42c(-c%42cc%43cc%44sccc%44c(-c%44cc%45cc%46sccc%46c(-c%46cc%47cc%48sccc%48c(-c%48cc%49cc%50sccc%50c(-c%50cc%51cc%52sccc%52c(-c%52cc%53cc%54sccc%54c(-c%54cc%55cc%56sccc%56c(-c%56cc%57cc%58sccc%58c(-c%58cc%59cc%60sccc%60c(-c%60cc%61cc%62sccc%62cc%61s%60)c%59s%58)c%57s%56)c%55s%54)c%53s%52)c%51s%50)c%49s%48)c%47s%46)c%45s%44)c%43s%42)c%41s%40)c%39s%38)c%37s%36)c%35s%34)c%33s%32)c%31s%30)c%29s%28)c%27s%26)c%25s%24)c%23s%22)c%21s%20)c%19s%18)c%17s%16)c%15s%14)c%13s%12)c%11s%10)c9s8)c7s6)c5s4)cc3cc2s1'], ['Cn1c2c(c3c1c1c(n3C)=NC=[SH]1)[SH]=CN=2'], ['Fc1c2cc(-c3cc4c(F)c5scc(-c6cc7c(F)c8scc(-c9cc%10c(F)c%11scc(-c%12cc%13c(F)c%14scc(-c%15cc%16c(F)c%17scc(-c%18cc%19c(F)c%20scc(-c%21cc%22c(F)c%23scc(-c%24cc%25c(F)c%26scc(-c%27cc%28c(F)c%29scc(-c%30cc%31c(F)c%32scc(-c%33cc%34c(F)c%35scc(-c%36cc%37c(F)c%38scc(-c%39cc%40c(F)c%41scc(-c%42cc%43c(F)c%44scc(-c%45cc%46c(F)c%47scc(-c%48cc%49c(F)c%50scc(-c%51cc%52c(F)c%53scc(-c%54cc%55c(F)c%56scc(-c%57cc%58c(F)c%59scc(-c%60cc%61c(F)c%62scc(-c%63cc%64c(F)c%65scc(-c%66cc%67c(F)c%68scc(-c%69cc%70c(F)c%71scc(-c%72cc%73c(F)c%74scc(-c%75cc%76c(F)c%77scc(-c%78cc%79c(F)c%80scc(-c%81cc%82c(F)c%83scc(-c%84cc%85c(F)c%86scc(-c%87cc%88c(F)c%89sccc%89c(F)c%88s%87)c%86c(F)c%85s%84)c%83c(F)c%82s%81)c%80c(F)c%79s%78)c%77c(F)c%76s%75)c%74c(F)c%73s%72)c%71c(F)c%70s%69)c%68c(F)c%67s%66)c%65c(F)c%64s%63)c%62c(F)c%61s%60)c%59c(F)c%58s%57)c%56c(F)c%55s%54)c%53c(F)c%52s%51)c%50c(F)c%49s%48)c%47c(F)c%46s%45)c%44c(F)c%43s%42)c%41c(F)c%40s%39)c%38c(F)c%37s%36)c%35c(F)c%34s%33)c%32c(F)c%31s%30)c%29c(F)c%28s%27)c%26c(F)c%25s%24)c%23c(F)c%22s%21)c%20c(F)c%19s%18)c%17c(F)c%16s%15)c%14c(F)c%13s%12)c%11c(F)c%10s9)c8c(F)c7s6)c5c(F)c4s3)sc2c(F)c2ccsc12'], ['C1=CSC(C2=CSC(C3=CSC(C4=CSC(C5=CSC(C6=CSC(C7=CSC(C8=CSC(C9=CSC(C%10=CSC(C%11=CSC(C%12=CSC(C%13=CSC(C%14=CSC(C%15=CSC(C%16=CSC(C%17=CSC(C%18=CSC(C%19=CSC(C%20=CSC(C%21=CSC(C%22=CSC(C%23=CSC(C%24=CSC(C%25=CSC(C%26=CSC(C%27=CSC(C%28=CSC(C%29=CSC(C%30CC=CS%30)C%29)C%28)C%27)C%26)C%25)C%24)C%23)C%22)C%21)C%20)C%19)C%18)C%17)C%16)C%15)C%14)C%13)C%12)C%11)C%10)C9)C8)C7)C6)C5)C4)C3)C2)C1'], ['c1cc2c(-c3cc4c(-c5cc6c(-c7cc8c(-c9cc%10c(-c%11cc%12c(-c%13cc%14c(-c%15cc%16c(-c%17cc%18c(-c%19cc%20c(-c%21cc%22c(-c%23cc%24c(-c%25cc%26c(-c%27cc%28c(-c%29cc%30c(-c%31cc%32c(-c%33cc%34c(-c%35cc%36c(-c%37cc%38c(-c%39cc%40c(-c%41cc%42c(-c%43cc%44c(-c%45cc%46c(-c%47cc%48c(-c%49cc%50c(-c%51cc%52c(-c%53cc%54c(-c%55cc%56c(-c%57cc%58c(-c%59c%60ccsc%60cc%60ccsc%59%60)c%59sccc%59cc%58s%57)c%57sccc%57cc%56s%55)c%55sccc%55cc%54s%53)c%53sccc%53cc%52s%51)c%51sccc%51cc%50s%49)c%49sccc%49cc%48s%47)c%47sccc%47cc%46s%45)c%45sccc%45cc%44s%43)c%43sccc%43cc%42s%41)c%41sccc%41cc%40s%39)c%39sccc%39cc%38s%37)c%37sccc%37cc%36s%35)c%35sccc%35cc%34s%33)c%33sccc%33cc%32s%31)c%31sccc%31cc%30s%29)c%29sccc%29cc%28s%27)c%27sccc%27cc%26s%25)c%25sccc%25cc%24s%23)c%23sccc%23cc%22s%21)c%21sccc%21cc%20s%19)c%19sccc%19cc%18s%17)c%17sccc%17cc%16s%15)c%15sccc%15cc%14s%13)c%13sccc%13cc%12s%11)c%11sccc%11cc%10s9)c9sccc9cc8s7)c7sccc7cc6s5)c5sccc5cc4s3)c3sccc3cc2s1']]\n",
            "Found 30 ring systems\n",
            "Motif: c1c2c(cc3c1CNC3)CCC2  (count=30, atoms=[1, 2, 4, 5, 6, 7, 8, 560, 561, 563, 565, 568])\n",
            "smiles_fragments:  c1c2c(cc3c1CNC3)CCC2\n",
            "Found 0 ring systems\n",
            "Found 2 ring systems\n",
            "Found 30 ring systems\n",
            "Motif: c1cc2cc3sccc3cc2s1  (count=30, atoms=[0, 1, 2, 3, 4, 5, 6, 355, 356, 357, 358, 359])\n",
            "smiles_fragments:  c1cc2cc3sccc3cc2s1\n",
            "Found 1 ring systems\n",
            "Found 30 ring systems\n",
            "Motif: c1cc2cc3sccc3cc2s1  (count=30, atoms=[1, 2, 3, 4, 411, 412, 413, 415, 416, 417, 418, 419])\n",
            "smiles_fragments:  c1cc2cc3sccc3cc2s1\n",
            "Found 30 ring systems\n",
            "Motif: C1=CSCC1  (count=30, atoms=[0, 1, 2, 3, 149])\n",
            "smiles_fragments:  C1=CSCC1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to patch pandas - unable to change molecule rendering\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30 ring systems\n",
            "Motif: c1cc2cc3sccc3cc2s1  (count=30, atoms=[0, 1, 2, 3, 352, 353, 354, 355, 356, 357, 358, 359])\n",
            "smiles_fragments:  c1cc2cc3sccc3cc2s1\n",
            "success_list:  ['c1c2c(cc3c1CNC3)CCC2', 'C', 'C', 'c1cc2cc3sccc3cc2s1', 'C', 'c1cc2cc3sccc3cc2s1', 'C1=CSCC1', 'c1cc2cc3sccc3cc2s1']\n",
            "fail_smiles_list_Nalpha []\n",
            "Volume_list_test [157.44800000000004]\n",
            "false_list_test []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to patch pandas - unable to change molecule rendering\n",
            "Failed to patch pandas - unable to change molecule rendering\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    2.258842\n",
            "dtype: float64\n",
            "0    142.712044\n",
            "dtype: float64\n",
            "Volume_list_test [28.784000000000006]\n",
            "false_list_test []\n",
            "0    0.25118\n",
            "dtype: float64\n",
            "0    17.511638\n",
            "dtype: float64\n",
            "Volume_list_test [28.736000000000008]\n",
            "false_list_test []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to patch pandas - unable to change molecule rendering\n",
            "Failed to patch pandas - unable to change molecule rendering\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    0.25118\n",
            "dtype: float64\n",
            "0    17.463209\n",
            "dtype: float64\n",
            "Volume_list_test [152.93600000000004]\n",
            "false_list_test []\n",
            "0    2.621383\n",
            "dtype: float64\n",
            "0    138.159768\n",
            "dtype: float64\n",
            "Volume_list_test [28.744000000000007]\n",
            "false_list_test []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to patch pandas - unable to change molecule rendering\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    0.25118\n",
            "dtype: float64\n",
            "0    17.471281\n",
            "dtype: float64\n",
            "Volume_list_test [154.12800000000004]\n",
            "false_list_test []\n",
            "0    2.621383\n",
            "dtype: float64\n",
            "0    139.362408\n",
            "dtype: float64\n",
            "Volume_list_test [80.57600000000002]\n",
            "false_list_test []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to patch pandas - unable to change molecule rendering\n",
            "Failed to patch pandas - unable to change molecule rendering\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    1.153354\n",
            "dtype: float64\n",
            "0    69.711904\n",
            "dtype: float64\n",
            "Volume_list_test [153.01600000000005]\n",
            "false_list_test []\n",
            "0    2.621383\n",
            "dtype: float64\n",
            "0    138.240482\n",
            "dtype: float64\n",
            "before_filter:  [['CN1C(=O)c2cc3c(c(-c4c5c(c(-c6c7c(c(-c8c9c(c(-c%10c%11c(c(-c%12c%13c(c(-c%14c%15c(c(-c%16c%17c(c(-c%18c%19c(c(-c%20c%21c(c(-c%22c%23c(c(-c%24c%25c(c(-c%26c%27c(c(-c%28c%29c(c(-c%30c%31c(c(-c%32c%33c(c(-c%34c%35c(c(-c%36c%37c(c(-c%38c%39c(c(-c%40c%41c(c(-c%42c%43c(c(-c%44c%45c(c(-c%46c%47c(c(-c%48c%49c(c(-c%50c%51c(c(-c%52c%53c(c(-c%54c%55c(c(-c%56c%57c(c(-c%58c%59c(c(-c%60c%61c(cc%62c%60C(=O)C(C)(C)C%62O)C(=O)N(C)C%61=O)c%60c%58C(=O)C(C)(C)C%60O)C(=O)N(C)C%59=O)c%58c%56C(=O)C(C)(C)C%58O)C(=O)N(C)C%57=O)c%56c%54C(=O)C(C)(C)C%56O)C(=O)N(C)C%55=O)c%54c%52C(=O)C(C)(C)C%54O)C(=O)N(C)C%53=O)c%52c%50C(=O)C(C)(C)C%52O)C(=O)N(C)C%51=O)c%50c%48C(=O)C(C)(C)C%50O)C(=O)N(C)C%49=O)c%48c%46C(=O)C(C)(C)C%48O)C(=O)N(C)C%47=O)c%46c%44C(=O)C(C)(C)C%46O)C(=O)N(C)C%45=O)c%44c%42C(=O)C(C)(C)C%44O)C(=O)N(C)C%43=O)c%42c%40C(=O)C(C)(C)C%42O)C(=O)N(C)C%41=O)c%40c%38C(=O)C(C)(C)C%40O)C(=O)N(C)C%39=O)c%38c%36C(=O)C(C)(C)C%38O)C(=O)N(C)C%37=O)c%36c%34C(=O)C(C)(C)C%36O)C(=O)N(C)C%35=O)c%34c%32C(=O)C(C)(C)C%34O)C(=O)N(C)C%33=O)c%32c%30C(=O)C(C)(C)C%32O)C(=O)N(C)C%31=O)c%30c%28C(=O)C(C)(C)C%30O)C(=O)N(C)C%29=O)c%28c%26C(=O)C(C)(C)C%28O)C(=O)N(C)C%27=O)c%26c%24C(=O)C(C)(C)C%26O)C(=O)N(C)C%25=O)c%24c%22C(=O)C(C)(C)C%24O)C(=O)N(C)C%23=O)c%22c%20C(=O)C(C)(C)C%22O)C(=O)N(C)C%21=O)c%20c%18C(=O)C(C)(C)C%20O)C(=O)N(C)C%19=O)c%18c%16C(=O)C(C)(C)C%18O)C(=O)N(C)C%17=O)c%16c%14C(=O)C(C)(C)C%16O)C(=O)N(C)C%15=O)c%14c%12C(=O)C(C)(C)C%14O)C(=O)N(C)C%13=O)c%12c%10C(=O)C(C)(C)C%12O)C(=O)N(C)C%11=O)c%10c8C(=O)C(C)(C)C%10O)C(=O)N(C)C9=O)c8c6C(=O)C(C)(C)C8O)C(=O)N(C)C7=O)c6c4C(=O)C(C)(C)C6O)C(=O)N(C)C5=O)c2C1=O)C(=O)C(C)(C)C3O'], ['[CH2][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH2]'], ['CC1(C)COc2cn(-n3cc4c(c3)OCC(C)(C)CO4)cc2OC1'], ['c1cc2cc3sc(-c4cc5cc6sccc6c(-c6cc7cc8sccc8c(-c8cc9cc%10sccc%10c(-c%10cc%11cc%12sccc%12c(-c%12cc%13cc%14sccc%14c(-c%14cc%15cc%16sccc%16c(-c%16cc%17cc%18sccc%18c(-c%18cc%19cc%20sccc%20c(-c%20cc%21cc%22sccc%22c(-c%22cc%23cc%24sccc%24c(-c%24cc%25cc%26sccc%26c(-c%26cc%27cc%28sccc%28c(-c%28cc%29cc%30sccc%30c(-c%30cc%31cc%32sccc%32c(-c%32cc%33cc%34sccc%34c(-c%34cc%35cc%36sccc%36c(-c%36cc%37cc%38sccc%38c(-c%38cc%39cc%40sccc%40c(-c%40cc%41cc%42sccc%42c(-c%42cc%43cc%44sccc%44c(-c%44cc%45cc%46sccc%46c(-c%46cc%47cc%48sccc%48c(-c%48cc%49cc%50sccc%50c(-c%50cc%51cc%52sccc%52c(-c%52cc%53cc%54sccc%54c(-c%54cc%55cc%56sccc%56c(-c%56cc%57cc%58sccc%58c(-c%58cc%59cc%60sccc%60c(-c%60cc%61cc%62sccc%62cc%61s%60)c%59s%58)c%57s%56)c%55s%54)c%53s%52)c%51s%50)c%49s%48)c%47s%46)c%45s%44)c%43s%42)c%41s%40)c%39s%38)c%37s%36)c%35s%34)c%33s%32)c%31s%30)c%29s%28)c%27s%26)c%25s%24)c%23s%22)c%21s%20)c%19s%18)c%17s%16)c%15s%14)c%13s%12)c%11s%10)c9s8)c7s6)c5s4)cc3cc2s1'], ['Cn1c2c(c3c1c1c(n3C)=NC=[SH]1)[SH]=CN=2'], ['Fc1c2cc(-c3cc4c(F)c5scc(-c6cc7c(F)c8scc(-c9cc%10c(F)c%11scc(-c%12cc%13c(F)c%14scc(-c%15cc%16c(F)c%17scc(-c%18cc%19c(F)c%20scc(-c%21cc%22c(F)c%23scc(-c%24cc%25c(F)c%26scc(-c%27cc%28c(F)c%29scc(-c%30cc%31c(F)c%32scc(-c%33cc%34c(F)c%35scc(-c%36cc%37c(F)c%38scc(-c%39cc%40c(F)c%41scc(-c%42cc%43c(F)c%44scc(-c%45cc%46c(F)c%47scc(-c%48cc%49c(F)c%50scc(-c%51cc%52c(F)c%53scc(-c%54cc%55c(F)c%56scc(-c%57cc%58c(F)c%59scc(-c%60cc%61c(F)c%62scc(-c%63cc%64c(F)c%65scc(-c%66cc%67c(F)c%68scc(-c%69cc%70c(F)c%71scc(-c%72cc%73c(F)c%74scc(-c%75cc%76c(F)c%77scc(-c%78cc%79c(F)c%80scc(-c%81cc%82c(F)c%83scc(-c%84cc%85c(F)c%86scc(-c%87cc%88c(F)c%89sccc%89c(F)c%88s%87)c%86c(F)c%85s%84)c%83c(F)c%82s%81)c%80c(F)c%79s%78)c%77c(F)c%76s%75)c%74c(F)c%73s%72)c%71c(F)c%70s%69)c%68c(F)c%67s%66)c%65c(F)c%64s%63)c%62c(F)c%61s%60)c%59c(F)c%58s%57)c%56c(F)c%55s%54)c%53c(F)c%52s%51)c%50c(F)c%49s%48)c%47c(F)c%46s%45)c%44c(F)c%43s%42)c%41c(F)c%40s%39)c%38c(F)c%37s%36)c%35c(F)c%34s%33)c%32c(F)c%31s%30)c%29c(F)c%28s%27)c%26c(F)c%25s%24)c%23c(F)c%22s%21)c%20c(F)c%19s%18)c%17c(F)c%16s%15)c%14c(F)c%13s%12)c%11c(F)c%10s9)c8c(F)c7s6)c5c(F)c4s3)sc2c(F)c2ccsc12'], ['C1=CSC(C2=CSC(C3=CSC(C4=CSC(C5=CSC(C6=CSC(C7=CSC(C8=CSC(C9=CSC(C%10=CSC(C%11=CSC(C%12=CSC(C%13=CSC(C%14=CSC(C%15=CSC(C%16=CSC(C%17=CSC(C%18=CSC(C%19=CSC(C%20=CSC(C%21=CSC(C%22=CSC(C%23=CSC(C%24=CSC(C%25=CSC(C%26=CSC(C%27=CSC(C%28=CSC(C%29=CSC(C%30CC=CS%30)C%29)C%28)C%27)C%26)C%25)C%24)C%23)C%22)C%21)C%20)C%19)C%18)C%17)C%16)C%15)C%14)C%13)C%12)C%11)C%10)C9)C8)C7)C6)C5)C4)C3)C2)C1'], ['c1cc2c(-c3cc4c(-c5cc6c(-c7cc8c(-c9cc%10c(-c%11cc%12c(-c%13cc%14c(-c%15cc%16c(-c%17cc%18c(-c%19cc%20c(-c%21cc%22c(-c%23cc%24c(-c%25cc%26c(-c%27cc%28c(-c%29cc%30c(-c%31cc%32c(-c%33cc%34c(-c%35cc%36c(-c%37cc%38c(-c%39cc%40c(-c%41cc%42c(-c%43cc%44c(-c%45cc%46c(-c%47cc%48c(-c%49cc%50c(-c%51cc%52c(-c%53cc%54c(-c%55cc%56c(-c%57cc%58c(-c%59c%60ccsc%60cc%60ccsc%59%60)c%59sccc%59cc%58s%57)c%57sccc%57cc%56s%55)c%55sccc%55cc%54s%53)c%53sccc%53cc%52s%51)c%51sccc%51cc%50s%49)c%49sccc%49cc%48s%47)c%47sccc%47cc%46s%45)c%45sccc%45cc%44s%43)c%43sccc%43cc%42s%41)c%41sccc%41cc%40s%39)c%39sccc%39cc%38s%37)c%37sccc%37cc%36s%35)c%35sccc%35cc%34s%33)c%33sccc%33cc%32s%31)c%31sccc%31cc%30s%29)c%29sccc%29cc%28s%27)c%27sccc%27cc%26s%25)c%25sccc%25cc%24s%23)c%23sccc%23cc%22s%21)c%21sccc%21cc%20s%19)c%19sccc%19cc%18s%17)c%17sccc%17cc%16s%15)c%15sccc%15cc%14s%13)c%13sccc%13cc%12s%11)c%11sccc%11cc%10s9)c9sccc9cc8s7)c7sccc7cc6s5)c5sccc5cc4s3)c3sccc3cc2s1']]\n",
            "Found 30 ring systems\n",
            "Motif: c1c2c(cc3c1CNC3)CCC2  (count=30, atoms=[1, 2, 4, 5, 6, 7, 8, 560, 561, 563, 565, 568])\n",
            "smiles_fragments:  c1c2c(cc3c1CNC3)CCC2\n",
            "Found 0 ring systems\n",
            "Found 2 ring systems\n",
            "Found 30 ring systems\n",
            "Motif: c1cc2cc3sccc3cc2s1  (count=30, atoms=[0, 1, 2, 3, 4, 5, 6, 355, 356, 357, 358, 359])\n",
            "smiles_fragments:  c1cc2cc3sccc3cc2s1\n",
            "Found 1 ring systems\n",
            "Found 30 ring systems\n",
            "Motif: c1cc2cc3sccc3cc2s1  (count=30, atoms=[1, 2, 3, 4, 411, 412, 413, 415, 416, 417, 418, 419])\n",
            "smiles_fragments:  c1cc2cc3sccc3cc2s1\n",
            "Found 30 ring systems\n",
            "Motif: C1=CSCC1  (count=30, atoms=[0, 1, 2, 3, 149])\n",
            "smiles_fragments:  C1=CSCC1\n",
            "Found 30 ring systems\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "geometric-optimize called with the following command line:\n",
            "/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-010f6a21-b892-41de-b6ba-3ab3f0afa510.json\n",
            "\n",
            "                                        \u001b[91m())))))))))))))))/\u001b[0m                     \n",
            "                                    \u001b[91m())))))))))))))))))))))))),\u001b[0m                \n",
            "                                \u001b[91m*)))))))))))))))))))))))))))))))))\u001b[0m             \n",
            "                        \u001b[94m#,\u001b[0m    \u001b[91m()))))))))/\u001b[0m                \u001b[91m.)))))))))),\u001b[0m          \n",
            "                      \u001b[94m#%%%%,\u001b[0m  \u001b[91m())))))\u001b[0m                        \u001b[91m.))))))))*\u001b[0m        \n",
            "                      \u001b[94m*%%%%%%,\u001b[0m  \u001b[91m))\u001b[0m              \u001b[93m..\u001b[0m              \u001b[91m,))))))).\u001b[0m      \n",
            "                        \u001b[94m*%%%%%%,\u001b[0m         \u001b[93m***************/.\u001b[0m        \u001b[91m.)))))))\u001b[0m     \n",
            "                \u001b[94m#%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m    \u001b[93m/*********************.\u001b[0m       \u001b[91m)))))))\u001b[0m    \n",
            "              \u001b[94m.%%%%%%#\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m*******/,\u001b[0m     \u001b[93m**********,\u001b[0m      \u001b[91m.))))))\u001b[0m   \n",
            "                \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m**\u001b[0m              \u001b[93m********\u001b[0m      \u001b[91m.))))))\u001b[0m  \n",
            "          \u001b[94m##\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m                  \u001b[93m,******\u001b[0m      \u001b[91m/)))))\u001b[0m  \n",
            "        \u001b[94m%%%%%%\u001b[0m      \u001b[94m.%%%%%%#\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m    \u001b[92m,/////.\u001b[0m       \u001b[93m******\u001b[0m      \u001b[91m))))))\u001b[0m \n",
            "      \u001b[94m#%\u001b[0m      \u001b[94m%%\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[92m////////,\u001b[0m      \u001b[93m*****/\u001b[0m     \u001b[91m,)))))\u001b[0m \n",
            "    \u001b[94m#%%\u001b[0m  \u001b[94m%%%\u001b[0m  \u001b[94m%%%#\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m  \u001b[92m///////.\u001b[0m     \u001b[93m/*****\u001b[0m      \u001b[91m))))).\u001b[0m\n",
            "  \u001b[94m#%%%%.\u001b[0m      \u001b[94m%%%%%#\u001b[0m      \u001b[94m/%%%%%%*\u001b[0m      \u001b[94m#%%%%%%\u001b[0m   \u001b[92m/////)\u001b[0m     \u001b[93m******\u001b[0m      \u001b[91m))))),\u001b[0m\n",
            "    \u001b[94m#%%%%##%\u001b[0m  \u001b[94m%%%#\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m  \u001b[92m///////.\u001b[0m     \u001b[93m/*****\u001b[0m      \u001b[91m))))).\u001b[0m\n",
            "      \u001b[94m##\u001b[0m     \u001b[94m%%%\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[92m////////.\u001b[0m      \u001b[93m*****/\u001b[0m     \u001b[91m,)))))\u001b[0m \n",
            "        \u001b[94m#%%%%#\u001b[0m      \u001b[94m/%%%%%%/\u001b[0m      \u001b[94m(%%%%%%\u001b[0m      \u001b[92m/)/)//\u001b[0m       \u001b[93m******\u001b[0m      \u001b[91m))))))\u001b[0m \n",
            "          \u001b[94m##\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m                  \u001b[93m*******\u001b[0m      \u001b[91m))))))\u001b[0m  \n",
            "                \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m**.\u001b[0m             \u001b[93m/*******\u001b[0m      \u001b[91m.))))))\u001b[0m  \n",
            "              \u001b[94m*%%%%%%/\u001b[0m      \u001b[94m(%%%%%%\u001b[0m   \u001b[93m********/*..,*/*********\u001b[0m       \u001b[91m*))))))\u001b[0m   \n",
            "                \u001b[94m#%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m    \u001b[93m*********************/\u001b[0m        \u001b[91m)))))))\u001b[0m    \n",
            "                        \u001b[94m*%%%%%%,\u001b[0m         \u001b[93m,**************/\u001b[0m         \u001b[91m,))))))/\u001b[0m     \n",
            "                      \u001b[94m(%%%%%%\u001b[0m   \u001b[91m()\u001b[0m                              \u001b[91m))))))))\u001b[0m       \n",
            "                      \u001b[94m#%%%%,\u001b[0m  \u001b[91m())))))\u001b[0m                        \u001b[91m,)))))))),\u001b[0m        \n",
            "                        \u001b[94m#,\u001b[0m    \u001b[91m())))))))))\u001b[0m                \u001b[91m,)))))))))).\u001b[0m          \n",
            "                                 \u001b[91m()))))))))))))))))))))))))))))))/\u001b[0m             \n",
            "                                    \u001b[91m())))))))))))))))))))))))).\u001b[0m                \n",
            "                                         \u001b[91m())))))))))))))),\u001b[0m                     \n",
            "\n",
            "-=# \u001b[1;94m geomeTRIC started. Version: 1.1 \u001b[0m #=-\n",
            "Current date and time: 2026-01-30 11:00:40\n",
            "#========================================================#\n",
            "#| \u001b[92m    Arguments passed to driver run_optimizer():     \u001b[0m |#\n",
            "#========================================================#\n",
            "convergence_dmax          0.0018 \n",
            "convergence_drms          0.0012 \n",
            "convergence_energy        1e-05 \n",
            "convergence_gmax          0.00045 \n",
            "convergence_grms          0.0003 \n",
            "customengine              <pyscf.geomopt.geometric_solver.PySCFEngine object at 0x789a27b05790> \n",
            "input                     /tmp/tmpe0d7o032/2082e26c-715e-4c07-b712-bcd3a89cb06c \n",
            "logIni                    /usr/local/lib/python3.11/dist-packages/pyscf/geomopt/log.ini \n",
            "maxiter                   100 \n",
            "----------------------------------------------------------\n",
            "Custom engine selected.\n",
            "Bonds will be generated from interatomic distances less than 1.20 times sum of covalent radii\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Motif: c1cc2cc3sccc3cc2s1  (count=30, atoms=[0, 1, 2, 3, 352, 353, 354, 355, 356, 357, 358, 359])\n",
            "smiles_fragments:  c1cc2cc3sccc3cc2s1\n",
            "success_list:  ['c1c2c(cc3c1CNC3)CCC2', 'C', 'C', 'c1cc2cc3sccc3cc2s1', 'C', 'c1cc2cc3sccc3cc2s1', 'C1=CSCC1', 'c1cc2cc3sccc3cc2s1']\n",
            "fail_smiles_list []\n",
            "smiles_chosen:  c1c2c(cc3c1CNC3)CCC2\n",
            "使用するXYZデータ:\n",
            " C      0.135234   -1.389876   -0.242017\n",
            "C     -1.015654   -0.699035    0.105594\n",
            "C     -0.983971    0.669247    0.441833\n",
            "C      0.199640    1.391539    0.441483\n",
            "C      1.346735    0.697641    0.090843\n",
            "C      1.315221   -0.663309   -0.243596\n",
            "C      2.695013   -1.107472   -0.598683\n",
            "N      3.595775   -0.021950   -0.130612\n",
            "C      2.748330    1.195056   -0.032858\n",
            "C     -2.351560    1.152261    0.815135\n",
            "C     -3.234618    0.053054    0.207787\n",
            "C     -2.406949   -1.239812    0.227317\n",
            "H      0.112762   -2.442030   -0.499342\n",
            "H      0.225879    2.443042    0.701102\n",
            "H      2.789059   -1.221265   -1.683682\n",
            "H      2.956073   -2.050870   -0.109279\n",
            "H      3.858219   -0.262984    0.825503\n",
            "H      3.045054    1.791983    0.835071\n",
            "H      2.858889    1.794313   -0.942630\n",
            "H     -2.453939    1.185805    1.904631\n",
            "H     -2.581682    2.131274    0.385695\n",
            "H     -4.188817   -0.053930    0.733056\n",
            "H     -3.467353    0.314466   -0.834069\n",
            "H     -2.674968   -1.897406   -0.604295\n",
            "H     -2.522372   -1.769741    1.178350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "75 internal coordinates being used (instead of 75 Cartesians)\n",
            "Internal coordinate system (atoms numbered from 1):\n",
            "Distance 1-2\n",
            "Distance 1-6\n",
            "Distance 1-13\n",
            "Distance 2-3\n",
            "Distance 2-12\n",
            "Distance 3-4\n",
            "Distance 3-10\n",
            "Distance 4-5\n",
            "Distance 4-14\n",
            "Distance 5-6\n",
            "Distance 5-9\n",
            "Distance 6-7\n",
            "Distance 7-8\n",
            "Distance 7-15\n",
            "Distance 7-16\n",
            "Distance 8-9\n",
            "Distance 8-17\n",
            "Distance 9-18\n",
            "Distance 9-19\n",
            "Distance 10-11\n",
            "Distance 10-20\n",
            "Distance 10-21\n",
            "Distance 11-12\n",
            "Distance 11-22\n",
            "Distance 11-23\n",
            "Distance 12-24\n",
            "Distance 12-25\n",
            "Angle 2-1-13\n",
            "Angle 6-1-13\n",
            "Angle 1-2-12\n",
            "Angle 3-2-12\n",
            "Angle 2-3-10\n",
            "Angle 4-3-10\n",
            "Angle 3-4-14\n",
            "Angle 5-4-14\n",
            "Angle 4-5-9\n",
            "Angle 6-5-9\n",
            "Angle 1-6-7\n",
            "Angle 5-6-7\n",
            "Angle 6-7-8\n",
            "Angle 6-7-15\n",
            "Angle 6-7-16\n",
            "Angle 8-7-15\n",
            "Angle 8-7-16\n",
            "Angle 15-7-16\n",
            "Angle 7-8-9\n",
            "Angle 7-8-17\n",
            "Angle 9-8-17\n",
            "Angle 5-9-8\n",
            "Angle 5-9-18\n",
            "Angle 5-9-19\n",
            "Angle 8-9-18\n",
            "Angle 8-9-19\n",
            "Angle 18-9-19\n",
            "Angle 3-10-11\n",
            "Angle 3-10-20\n",
            "Angle 3-10-21\n",
            "Angle 11-10-20\n",
            "Angle 11-10-21\n",
            "Angle 20-10-21\n",
            "Angle 10-11-12\n",
            "Angle 10-11-22\n",
            "Angle 10-11-23\n",
            "Angle 12-11-22\n",
            "Angle 12-11-23\n",
            "Angle 22-11-23\n",
            "Angle 2-12-11\n",
            "Angle 2-12-24\n",
            "Angle 2-12-25\n",
            "Angle 11-12-24\n",
            "Angle 11-12-25\n",
            "Angle 24-12-25\n",
            "Out-of-Plane 1-2-6-13\n",
            "Out-of-Plane 2-1-3-12\n",
            "Out-of-Plane 3-2-4-10\n",
            "Out-of-Plane 4-3-5-14\n",
            "Out-of-Plane 5-4-6-9\n",
            "Out-of-Plane 6-1-5-7\n",
            "Dihedral 6-1-2-3\n",
            "Dihedral 6-1-2-12\n",
            "Dihedral 13-1-2-3\n",
            "Dihedral 13-1-2-12\n",
            "Dihedral 2-1-6-5\n",
            "Dihedral 2-1-6-7\n",
            "Dihedral 13-1-6-5\n",
            "Dihedral 13-1-6-7\n",
            "Dihedral 1-2-3-4\n",
            "Dihedral 1-2-3-10\n",
            "Dihedral 12-2-3-4\n",
            "Dihedral 12-2-3-10\n",
            "Dihedral 1-2-12-11\n",
            "Dihedral 1-2-12-24\n",
            "Dihedral 1-2-12-25\n",
            "Dihedral 3-2-12-11\n",
            "Dihedral 3-2-12-24\n",
            "Dihedral 3-2-12-25\n",
            "Dihedral 2-3-4-5\n",
            "Dihedral 2-3-4-14\n",
            "Dihedral 10-3-4-5\n",
            "Dihedral 10-3-4-14\n",
            "Dihedral 2-3-10-11\n",
            "Dihedral 2-3-10-20\n",
            "Dihedral 2-3-10-21\n",
            "Dihedral 4-3-10-11\n",
            "Dihedral 4-3-10-20\n",
            "Dihedral 4-3-10-21\n",
            "Dihedral 3-4-5-6\n",
            "Dihedral 3-4-5-9\n",
            "Dihedral 14-4-5-6\n",
            "Dihedral 14-4-5-9\n",
            "Dihedral 4-5-6-1\n",
            "Dihedral 4-5-6-7\n",
            "Dihedral 9-5-6-1\n",
            "Dihedral 9-5-6-7\n",
            "Dihedral 4-5-9-8\n",
            "Dihedral 4-5-9-18\n",
            "Dihedral 4-5-9-19\n",
            "Dihedral 6-5-9-8\n",
            "Dihedral 6-5-9-18\n",
            "Dihedral 6-5-9-19\n",
            "Dihedral 1-6-7-8\n",
            "Dihedral 1-6-7-15\n",
            "Dihedral 1-6-7-16\n",
            "Dihedral 5-6-7-8\n",
            "Dihedral 5-6-7-15\n",
            "Dihedral 5-6-7-16\n",
            "Dihedral 6-7-8-9\n",
            "Dihedral 6-7-8-17\n",
            "Dihedral 15-7-8-9\n",
            "Dihedral 15-7-8-17\n",
            "Dihedral 16-7-8-9\n",
            "Dihedral 16-7-8-17\n",
            "Dihedral 7-8-9-5\n",
            "Dihedral 7-8-9-18\n",
            "Dihedral 7-8-9-19\n",
            "Dihedral 17-8-9-5\n",
            "Dihedral 17-8-9-18\n",
            "Dihedral 17-8-9-19\n",
            "Dihedral 3-10-11-12\n",
            "Dihedral 3-10-11-22\n",
            "Dihedral 3-10-11-23\n",
            "Dihedral 20-10-11-12\n",
            "Dihedral 20-10-11-22\n",
            "Dihedral 20-10-11-23\n",
            "Dihedral 21-10-11-12\n",
            "Dihedral 21-10-11-22\n",
            "Dihedral 21-10-11-23\n",
            "Dihedral 10-11-12-2\n",
            "Dihedral 10-11-12-24\n",
            "Dihedral 10-11-12-25\n",
            "Dihedral 22-11-12-2\n",
            "Dihedral 22-11-12-24\n",
            "Dihedral 22-11-12-25\n",
            "Dihedral 23-11-12-2\n",
            "Dihedral 23-11-12-24\n",
            "Dihedral 23-11-12-25\n",
            "Translation-X 1-25\n",
            "Translation-Y 1-25\n",
            "Translation-Z 1-25\n",
            "Rotation-A 1-25\n",
            "Rotation-B 1-25\n",
            "Rotation-C 1-25\n",
            "<class 'geometric.internal.Distance'> : 27\n",
            "<class 'geometric.internal.Angle'> : 45\n",
            "<class 'geometric.internal.OutOfPlane'> : 6\n",
            "<class 'geometric.internal.Dihedral'> : 78\n",
            "<class 'geometric.internal.TranslationX'> : 1\n",
            "<class 'geometric.internal.TranslationY'> : 1\n",
            "<class 'geometric.internal.TranslationZ'> : 1\n",
            "<class 'geometric.internal.RotationA'> : 1\n",
            "<class 'geometric.internal.RotationB'> : 1\n",
            "<class 'geometric.internal.RotationC'> : 1\n",
            "> ===== Optimization Info: ====\n",
            "> Job type: Energy minimization\n",
            "> Maximum number of optimization cycles: 100\n",
            "> Initial / maximum trust radius (Angstrom): 0.100 / 0.300\n",
            "> Convergence Criteria:\n",
            "> Will converge when all 5 criteria are reached:\n",
            ">  |Delta-E| < 1.00e-05\n",
            ">  RMS-Grad  < 3.00e-04\n",
            ">  Max-Grad  < 4.50e-04\n",
            ">  RMS-Disp  < 1.20e-03\n",
            ">  Max-Disp  < 1.80e-03\n",
            "> === End Optimization Info ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARN: Mole.unit (angstrom) is changed to Bohr\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Step    0 : Gradient = 1.710e-02/4.279e-02 (rms/max) Energy = -475.8684393024\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30750e-02 2.31395e-02 ... 4.74332e-01 4.79953e-01 4.80014e-01\n",
            "Step    1 : Displace = \u001b[0m1.046e-01\u001b[0m/\u001b[0m1.527e-01\u001b[0m (rms/max) Trust = 1.000e-01 (=) Grad = \u001b[0m6.220e-03\u001b[0m/\u001b[0m1.328e-02\u001b[0m (rms/max) E (change) = -475.8840854834 (\u001b[0m-1.565e-02\u001b[0m) Quality = \u001b[0m0.698\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30750e-02 2.31395e-02 ... 4.74417e-01 4.79953e-01 5.37899e-01\n",
            "Step    2 : Displace = \u001b[0m4.489e-02\u001b[0m/\u001b[0m7.755e-02\u001b[0m (rms/max) Trust = 1.000e-01 (=) Grad = \u001b[0m7.126e-03\u001b[0m/\u001b[0m1.712e-02\u001b[0m (rms/max) E (change) = -475.8840687640 (\u001b[91m+1.672e-05\u001b[0m) Quality = \u001b[91m-0.004\u001b[0m\n",
            "Hessian Eigenvalues: 2.29985e-02 2.30750e-02 2.31395e-02 ... 4.74395e-01 4.79953e-01 6.50903e-01\n",
            "Step    3 : Displace = \u001b[0m2.071e-02\u001b[0m/\u001b[0m4.678e-02\u001b[0m (rms/max) Trust = 2.244e-02 (\u001b[91m-\u001b[0m) Grad = \u001b[0m1.535e-03\u001b[0m/\u001b[0m4.349e-03\u001b[0m (rms/max) E (change) = -475.8867043767 (\u001b[0m-2.636e-03\u001b[0m) Quality = \u001b[0m1.017\u001b[0m\n",
            "Hessian Eigenvalues: 2.29212e-02 2.30011e-02 2.30750e-02 ... 4.79743e-01 4.79954e-01 6.43501e-01\n",
            "Step    4 : Displace = \u001b[0m6.478e-03\u001b[0m/\u001b[0m1.701e-02\u001b[0m (rms/max) Trust = 3.174e-02 (\u001b[92m+\u001b[0m) Grad = \u001b[0m6.663e-04\u001b[0m/\u001b[0m2.035e-03\u001b[0m (rms/max) E (change) = -475.8868425238 (\u001b[0m-1.381e-04\u001b[0m) Quality = \u001b[0m1.568\u001b[0m\n",
            "Hessian Eigenvalues: 7.30395e-03 2.30088e-02 2.30750e-02 ... 4.77060e-01 4.79956e-01 6.67475e-01\n",
            "Step    5 : Displace = \u001b[0m1.973e-02\u001b[0m/\u001b[0m5.283e-02\u001b[0m (rms/max) Trust = 4.489e-02 (\u001b[92m+\u001b[0m) Grad = \u001b[0m9.787e-04\u001b[0m/\u001b[0m2.349e-03\u001b[0m (rms/max) E (change) = -475.8870302170 (\u001b[0m-1.877e-04\u001b[0m) Quality = \u001b[0m1.265\u001b[0m\n",
            "Hessian Eigenvalues: 4.20353e-03 2.30085e-02 2.30750e-02 ... 4.79955e-01 4.81262e-01 6.70106e-01\n",
            "Step    6 : Displace = \u001b[0m1.544e-02\u001b[0m/\u001b[0m3.530e-02\u001b[0m (rms/max) Trust = 6.348e-02 (\u001b[92m+\u001b[0m) Grad = \u001b[0m1.143e-03\u001b[0m/\u001b[0m2.915e-03\u001b[0m (rms/max) E (change) = -475.8871197325 (\u001b[0m-8.952e-05\u001b[0m) Quality = \u001b[0m1.568\u001b[0m\n",
            "Hessian Eigenvalues: 2.25249e-03 2.30103e-02 2.30750e-02 ... 4.78923e-01 4.80242e-01 6.59350e-01\n",
            "Step    7 : Displace = \u001b[0m2.700e-02\u001b[0m/\u001b[0m5.665e-02\u001b[0m (rms/max) Trust = 8.978e-02 (\u001b[92m+\u001b[0m) Grad = \u001b[0m7.212e-04\u001b[0m/\u001b[0m1.815e-03\u001b[0m (rms/max) E (change) = -475.8872234355 (\u001b[0m-1.037e-04\u001b[0m) Quality = \u001b[0m1.221\u001b[0m\n",
            "Hessian Eigenvalues: 2.12534e-03 2.30088e-02 2.30750e-02 ... 4.77731e-01 4.80775e-01 6.60927e-01\n",
            "Step    8 : Displace = \u001b[0m9.672e-03\u001b[0m/\u001b[0m2.124e-02\u001b[0m (rms/max) Trust = 1.270e-01 (\u001b[92m+\u001b[0m) Grad = \u001b[0m3.230e-04\u001b[0m/\u001b[0m8.261e-04\u001b[0m (rms/max) E (change) = -475.8872445615 (\u001b[0m-2.113e-05\u001b[0m) Quality = \u001b[0m0.986\u001b[0m\n",
            "Hessian Eigenvalues: 2.05990e-03 1.50260e-02 2.30225e-02 ... 4.77306e-01 5.26579e-01 6.60999e-01\n",
            "Step    9 : Displace = \u001b[0m6.007e-03\u001b[0m/\u001b[0m1.294e-02\u001b[0m (rms/max) Trust = 1.796e-01 (\u001b[92m+\u001b[0m) Grad = \u001b[0m3.175e-04\u001b[0m/\u001b[0m7.283e-04\u001b[0m (rms/max) E (change) = -475.8872516916 (\u001b[92m-7.130e-06\u001b[0m) Quality = \u001b[0m0.571\u001b[0m\n",
            "Hessian Eigenvalues: 2.20898e-03 1.17841e-02 2.30223e-02 ... 4.77961e-01 6.59881e-01 6.82917e-01\n",
            "Step   10 : Displace = \u001b[0m2.231e-03\u001b[0m/\u001b[0m4.660e-03\u001b[0m (rms/max) Trust = 1.796e-01 (=) Grad = \u001b[92m1.340e-04\u001b[0m/\u001b[92m3.576e-04\u001b[0m (rms/max) E (change) = -475.8872571655 (\u001b[92m-5.474e-06\u001b[0m) Quality = \u001b[0m1.314\u001b[0m\n",
            "Hessian Eigenvalues: 2.36800e-03 9.40757e-03 2.11957e-02 ... 4.77041e-01 6.59899e-01 7.23688e-01\n",
            "Step   11 : Displace = \u001b[0m2.278e-03\u001b[0m/\u001b[0m4.271e-03\u001b[0m (rms/max) Trust = 2.539e-01 (\u001b[92m+\u001b[0m) Grad = \u001b[92m1.042e-04\u001b[0m/\u001b[92m2.934e-04\u001b[0m (rms/max) E (change) = -475.8872596885 (\u001b[92m-2.523e-06\u001b[0m) Quality = \u001b[0m1.128\u001b[0m\n",
            "Hessian Eigenvalues: 2.30601e-03 4.39255e-03 1.83435e-02 ... 4.77971e-01 6.59917e-01 8.27833e-01\n",
            "Step   12 : Displace = \u001b[0m4.387e-03\u001b[0m/\u001b[0m1.053e-02\u001b[0m (rms/max) Trust = 3.000e-01 (\u001b[92m+\u001b[0m) Grad = \u001b[92m1.884e-04\u001b[0m/\u001b[0m4.851e-04\u001b[0m (rms/max) E (change) = -475.8872612137 (\u001b[92m-1.525e-06\u001b[0m) Quality = \u001b[0m0.601\u001b[0m\n",
            "Hessian Eigenvalues: 1.74456e-03 4.13985e-03 1.73461e-02 ... 5.97191e-01 6.60034e-01 8.00378e-01\n",
            "Step   13 : Displace = \u001b[0m2.474e-03\u001b[0m/\u001b[0m6.218e-03\u001b[0m (rms/max) Trust = 3.000e-01 (=) Grad = \u001b[92m1.178e-04\u001b[0m/\u001b[92m2.664e-04\u001b[0m (rms/max) E (change) = -475.8872629939 (\u001b[92m-1.780e-06\u001b[0m) Quality = \u001b[0m1.218\u001b[0m\n",
            "Hessian Eigenvalues: 1.25536e-03 3.98611e-03 1.35537e-02 ... 6.59535e-01 7.02580e-01 7.37931e-01\n",
            "Step   14 : Displace = \u001b[0m3.811e-03\u001b[0m/\u001b[0m8.901e-03\u001b[0m (rms/max) Trust = 3.000e-01 (=) Grad = \u001b[92m7.273e-05\u001b[0m/\u001b[92m1.319e-04\u001b[0m (rms/max) E (change) = -475.8872642561 (\u001b[92m-1.262e-06\u001b[0m) Quality = \u001b[0m0.764\u001b[0m\n",
            "Hessian Eigenvalues: 1.12885e-03 3.80245e-03 1.10840e-02 ... 6.59936e-01 6.97931e-01 8.39190e-01\n",
            "Step   15 : Displace = \u001b[0m1.592e-03\u001b[0m/\u001b[0m2.906e-03\u001b[0m (rms/max) Trust = 3.000e-01 (=) Grad = \u001b[92m4.079e-05\u001b[0m/\u001b[92m1.070e-04\u001b[0m (rms/max) E (change) = -475.8872644043 (\u001b[92m-1.482e-07\u001b[0m) Quality = \u001b[0m0.369\u001b[0m\n",
            "Hessian Eigenvalues: 1.20927e-03 3.33222e-03 9.37059e-03 ... 6.60090e-01 6.87055e-01 7.64083e-01\n",
            "Step   16 : Displace = \u001b[92m6.965e-04\u001b[0m/\u001b[0m2.034e-03\u001b[0m (rms/max) Trust = 3.000e-01 (=) Grad = \u001b[92m1.281e-05\u001b[0m/\u001b[92m3.206e-05\u001b[0m (rms/max) E (change) = -475.8872644513 (\u001b[92m-4.700e-08\u001b[0m) Quality = \u001b[0m0.401\u001b[0m\n",
            "Hessian Eigenvalues: 1.26012e-03 3.08057e-03 9.19010e-03 ... 6.60227e-01 6.87814e-01 7.23579e-01\n",
            "Step   17 : Displace = \u001b[92m2.716e-04\u001b[0m/\u001b[92m5.735e-04\u001b[0m (rms/max) Trust = 3.000e-01 (=) Grad = \u001b[92m6.857e-06\u001b[0m/\u001b[92m1.433e-05\u001b[0m (rms/max) E (change) = -475.8872644877 (\u001b[92m-3.639e-08\u001b[0m) Quality = \u001b[0m1.655\u001b[0m\n",
            "Hessian Eigenvalues: 1.26012e-03 3.08057e-03 9.19010e-03 ... 6.60227e-01 6.87814e-01 7.23579e-01\n",
            "Converged! =D\n",
            "\n",
            "    #==========================================================================#\n",
            "    #| If this code has benefited your research, please support us by citing: |#\n",
            "    #|                                                                        |#\n",
            "    #| Wang, L.-P.; Song, C.C. (2016) \"Geometry optimization made simple with |#\n",
            "    #| translation and rotation coordinates\", J. Chem, Phys. 144, 214108.     |#\n",
            "    #| http://dx.doi.org/10.1063/1.4952956                                    |#\n",
            "    #==========================================================================#\n",
            "    Time elapsed since start of run_optimizer: 65.238 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU計算時間: 65.30秒\n",
            "converged SCF energy = -475.865141072575\n",
            "SCF calculation completed successfully.\n",
            "Number of occupied orbitals: 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "geometric-optimize called with the following command line:\n",
            "/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-010f6a21-b892-41de-b6ba-3ab3f0afa510.json\n",
            "\n",
            "                                        \u001b[91m())))))))))))))))/\u001b[0m                     \n",
            "                                    \u001b[91m())))))))))))))))))))))))),\u001b[0m                \n",
            "                                \u001b[91m*)))))))))))))))))))))))))))))))))\u001b[0m             \n",
            "                        \u001b[94m#,\u001b[0m    \u001b[91m()))))))))/\u001b[0m                \u001b[91m.)))))))))),\u001b[0m          \n",
            "                      \u001b[94m#%%%%,\u001b[0m  \u001b[91m())))))\u001b[0m                        \u001b[91m.))))))))*\u001b[0m        \n",
            "                      \u001b[94m*%%%%%%,\u001b[0m  \u001b[91m))\u001b[0m              \u001b[93m..\u001b[0m              \u001b[91m,))))))).\u001b[0m      \n",
            "                        \u001b[94m*%%%%%%,\u001b[0m         \u001b[93m***************/.\u001b[0m        \u001b[91m.)))))))\u001b[0m     \n",
            "                \u001b[94m#%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m    \u001b[93m/*********************.\u001b[0m       \u001b[91m)))))))\u001b[0m    \n",
            "              \u001b[94m.%%%%%%#\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m*******/,\u001b[0m     \u001b[93m**********,\u001b[0m      \u001b[91m.))))))\u001b[0m   \n",
            "                \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m**\u001b[0m              \u001b[93m********\u001b[0m      \u001b[91m.))))))\u001b[0m  \n",
            "          \u001b[94m##\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m                  \u001b[93m,******\u001b[0m      \u001b[91m/)))))\u001b[0m  \n",
            "        \u001b[94m%%%%%%\u001b[0m      \u001b[94m.%%%%%%#\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m    \u001b[92m,/////.\u001b[0m       \u001b[93m******\u001b[0m      \u001b[91m))))))\u001b[0m \n",
            "      \u001b[94m#%\u001b[0m      \u001b[94m%%\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[92m////////,\u001b[0m      \u001b[93m*****/\u001b[0m     \u001b[91m,)))))\u001b[0m \n",
            "    \u001b[94m#%%\u001b[0m  \u001b[94m%%%\u001b[0m  \u001b[94m%%%#\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m  \u001b[92m///////.\u001b[0m     \u001b[93m/*****\u001b[0m      \u001b[91m))))).\u001b[0m\n",
            "  \u001b[94m#%%%%.\u001b[0m      \u001b[94m%%%%%#\u001b[0m      \u001b[94m/%%%%%%*\u001b[0m      \u001b[94m#%%%%%%\u001b[0m   \u001b[92m/////)\u001b[0m     \u001b[93m******\u001b[0m      \u001b[91m))))),\u001b[0m\n",
            "    \u001b[94m#%%%%##%\u001b[0m  \u001b[94m%%%#\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m  \u001b[92m///////.\u001b[0m     \u001b[93m/*****\u001b[0m      \u001b[91m))))).\u001b[0m\n",
            "      \u001b[94m##\u001b[0m     \u001b[94m%%%\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[92m////////.\u001b[0m      \u001b[93m*****/\u001b[0m     \u001b[91m,)))))\u001b[0m \n",
            "        \u001b[94m#%%%%#\u001b[0m      \u001b[94m/%%%%%%/\u001b[0m      \u001b[94m(%%%%%%\u001b[0m      \u001b[92m/)/)//\u001b[0m       \u001b[93m******\u001b[0m      \u001b[91m))))))\u001b[0m \n",
            "          \u001b[94m##\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m                  \u001b[93m*******\u001b[0m      \u001b[91m))))))\u001b[0m  \n",
            "                \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m**.\u001b[0m             \u001b[93m/*******\u001b[0m      \u001b[91m.))))))\u001b[0m  \n",
            "              \u001b[94m*%%%%%%/\u001b[0m      \u001b[94m(%%%%%%\u001b[0m   \u001b[93m********/*..,*/*********\u001b[0m       \u001b[91m*))))))\u001b[0m   \n",
            "                \u001b[94m#%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m    \u001b[93m*********************/\u001b[0m        \u001b[91m)))))))\u001b[0m    \n",
            "                        \u001b[94m*%%%%%%,\u001b[0m         \u001b[93m,**************/\u001b[0m         \u001b[91m,))))))/\u001b[0m     \n",
            "                      \u001b[94m(%%%%%%\u001b[0m   \u001b[91m()\u001b[0m                              \u001b[91m))))))))\u001b[0m       \n",
            "                      \u001b[94m#%%%%,\u001b[0m  \u001b[91m())))))\u001b[0m                        \u001b[91m,)))))))),\u001b[0m        \n",
            "                        \u001b[94m#,\u001b[0m    \u001b[91m())))))))))\u001b[0m                \u001b[91m,)))))))))).\u001b[0m          \n",
            "                                 \u001b[91m()))))))))))))))))))))))))))))))/\u001b[0m             \n",
            "                                    \u001b[91m())))))))))))))))))))))))).\u001b[0m                \n",
            "                                         \u001b[91m())))))))))))))),\u001b[0m                     \n",
            "\n",
            "-=# \u001b[1;94m geomeTRIC started. Version: 1.1 \u001b[0m #=-\n",
            "Current date and time: 2026-01-30 11:01:55\n",
            "#========================================================#\n",
            "#| \u001b[92m    Arguments passed to driver run_optimizer():     \u001b[0m |#\n",
            "#========================================================#\n",
            "convergence_dmax          0.0018 \n",
            "convergence_drms          0.0012 \n",
            "convergence_energy        1e-05 \n",
            "convergence_gmax          0.00045 \n",
            "convergence_grms          0.0003 \n",
            "customengine              <pyscf.geomopt.geometric_solver.PySCFEngine object at 0x789a0d2ce9d0> \n",
            "input                     /tmp/tmptu6kbpj4/9b958b18-69f7-43a3-aeca-37573bbe8565 \n",
            "logIni                    /usr/local/lib/python3.11/dist-packages/pyscf/geomopt/log.ini \n",
            "maxiter                   100 \n",
            "----------------------------------------------------------\n",
            "Custom engine selected.\n",
            "Bonds will be generated from interatomic distances less than 1.20 times sum of covalent radii\n",
            "15 internal coordinates being used (instead of 15 Cartesians)\n",
            "Internal coordinate system (atoms numbered from 1):\n",
            "Distance 1-2\n",
            "Distance 1-3\n",
            "Distance 1-4\n",
            "Distance 1-5\n",
            "Angle 2-1-3\n",
            "Angle 2-1-4\n",
            "Angle 2-1-5\n",
            "Angle 3-1-4\n",
            "Angle 3-1-5\n",
            "Angle 4-1-5\n",
            "Translation-X 1-5\n",
            "Translation-Y 1-5\n",
            "Translation-Z 1-5\n",
            "Rotation-A 1-5\n",
            "Rotation-B 1-5\n",
            "Rotation-C 1-5\n",
            "<class 'geometric.internal.Distance'> : 4\n",
            "<class 'geometric.internal.Angle'> : 6\n",
            "<class 'geometric.internal.TranslationX'> : 1\n",
            "<class 'geometric.internal.TranslationY'> : 1\n",
            "<class 'geometric.internal.TranslationZ'> : 1\n",
            "<class 'geometric.internal.RotationA'> : 1\n",
            "<class 'geometric.internal.RotationB'> : 1\n",
            "<class 'geometric.internal.RotationC'> : 1\n",
            "> ===== Optimization Info: ====\n",
            "> Job type: Energy minimization\n",
            "> Maximum number of optimization cycles: 100\n",
            "> Initial / maximum trust radius (Angstrom): 0.100 / 0.300\n",
            "> Convergence Criteria:\n",
            "> Will converge when all 5 criteria are reached:\n",
            ">  |Delta-E| < 1.00e-05\n",
            ">  RMS-Grad  < 3.00e-04\n",
            ">  Max-Grad  < 4.50e-04\n",
            ">  RMS-Disp  < 1.20e-03\n",
            ">  Max-Disp  < 1.80e-03\n",
            "> === End Optimization Info ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAP:  [6.19228468]\n",
            "GAP type:  <class 'numpy.ndarray'>\n",
            "smiles_chosen:  C\n",
            "使用するXYZデータ:\n",
            " C      0.000000   -0.000000   -0.000000\n",
            "H      0.532518    0.750164   -0.588709\n",
            "H      0.718148   -0.588339    0.575343\n",
            "H     -0.557744   -0.659078   -0.668908\n",
            "H     -0.692923    0.497253    0.682273\n",
            "\n",
            "WARN: Mole.unit (angstrom) is changed to Bohr\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Step    0 : Gradient = 3.268e-03/3.654e-03 (rms/max) Energy = -40.0391513956\n",
            "Hessian Eigenvalues: 5.00000e-02 5.00000e-02 5.00000e-02 ... 3.45597e-01 3.45597e-01 3.45597e-01\n",
            "Step    1 : Displace = \u001b[0m5.004e-03\u001b[0m/\u001b[0m5.595e-03\u001b[0m (rms/max) Trust = 1.000e-01 (=) Grad = \u001b[0m6.571e-04\u001b[0m/\u001b[0m7.351e-04\u001b[0m (rms/max) E (change) = -40.0392126819 (\u001b[0m-6.129e-05\u001b[0m) Quality = \u001b[0m0.793\u001b[0m\n",
            "Hessian Eigenvalues: 4.99999e-02 5.00000e-02 5.00000e-02 ... 3.45597e-01 3.45597e-01 4.15092e-01\n",
            "Step    2 : Displace = \u001b[92m8.377e-04\u001b[0m/\u001b[92m9.367e-04\u001b[0m (rms/max) Trust = 1.414e-01 (\u001b[92m+\u001b[0m) Grad = \u001b[92m7.857e-06\u001b[0m/\u001b[92m9.139e-06\u001b[0m (rms/max) E (change) = -40.0392153125 (\u001b[92m-2.631e-06\u001b[0m) Quality = \u001b[0m1.011\u001b[0m\n",
            "Hessian Eigenvalues: 4.99999e-02 5.00000e-02 5.00000e-02 ... 3.45597e-01 3.45597e-01 4.15092e-01\n",
            "Converged! =D\n",
            "\n",
            "    #==========================================================================#\n",
            "    #| If this code has benefited your research, please support us by citing: |#\n",
            "    #|                                                                        |#\n",
            "    #| Wang, L.-P.; Song, C.C. (2016) \"Geometry optimization made simple with |#\n",
            "    #| translation and rotation coordinates\", J. Chem, Phys. 144, 214108.     |#\n",
            "    #| http://dx.doi.org/10.1063/1.4952956                                    |#\n",
            "    #==========================================================================#\n",
            "    Time elapsed since start of run_optimizer: 2.076 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU計算時間: 2.11秒\n",
            "converged SCF energy = -40.0388552264663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "geometric-optimize called with the following command line:\n",
            "/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-010f6a21-b892-41de-b6ba-3ab3f0afa510.json\n",
            "\n",
            "                                        \u001b[91m())))))))))))))))/\u001b[0m                     \n",
            "                                    \u001b[91m())))))))))))))))))))))))),\u001b[0m                \n",
            "                                \u001b[91m*)))))))))))))))))))))))))))))))))\u001b[0m             \n",
            "                        \u001b[94m#,\u001b[0m    \u001b[91m()))))))))/\u001b[0m                \u001b[91m.)))))))))),\u001b[0m          \n",
            "                      \u001b[94m#%%%%,\u001b[0m  \u001b[91m())))))\u001b[0m                        \u001b[91m.))))))))*\u001b[0m        \n",
            "                      \u001b[94m*%%%%%%,\u001b[0m  \u001b[91m))\u001b[0m              \u001b[93m..\u001b[0m              \u001b[91m,))))))).\u001b[0m      \n",
            "                        \u001b[94m*%%%%%%,\u001b[0m         \u001b[93m***************/.\u001b[0m        \u001b[91m.)))))))\u001b[0m     \n",
            "                \u001b[94m#%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m    \u001b[93m/*********************.\u001b[0m       \u001b[91m)))))))\u001b[0m    \n",
            "              \u001b[94m.%%%%%%#\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m*******/,\u001b[0m     \u001b[93m**********,\u001b[0m      \u001b[91m.))))))\u001b[0m   \n",
            "                \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m**\u001b[0m              \u001b[93m********\u001b[0m      \u001b[91m.))))))\u001b[0m  \n",
            "          \u001b[94m##\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m                  \u001b[93m,******\u001b[0m      \u001b[91m/)))))\u001b[0m  \n",
            "        \u001b[94m%%%%%%\u001b[0m      \u001b[94m.%%%%%%#\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m    \u001b[92m,/////.\u001b[0m       \u001b[93m******\u001b[0m      \u001b[91m))))))\u001b[0m \n",
            "      \u001b[94m#%\u001b[0m      \u001b[94m%%\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[92m////////,\u001b[0m      \u001b[93m*****/\u001b[0m     \u001b[91m,)))))\u001b[0m \n",
            "    \u001b[94m#%%\u001b[0m  \u001b[94m%%%\u001b[0m  \u001b[94m%%%#\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m  \u001b[92m///////.\u001b[0m     \u001b[93m/*****\u001b[0m      \u001b[91m))))).\u001b[0m\n",
            "  \u001b[94m#%%%%.\u001b[0m      \u001b[94m%%%%%#\u001b[0m      \u001b[94m/%%%%%%*\u001b[0m      \u001b[94m#%%%%%%\u001b[0m   \u001b[92m/////)\u001b[0m     \u001b[93m******\u001b[0m      \u001b[91m))))),\u001b[0m\n",
            "    \u001b[94m#%%%%##%\u001b[0m  \u001b[94m%%%#\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m  \u001b[92m///////.\u001b[0m     \u001b[93m/*****\u001b[0m      \u001b[91m))))).\u001b[0m\n",
            "      \u001b[94m##\u001b[0m     \u001b[94m%%%\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[92m////////.\u001b[0m      \u001b[93m*****/\u001b[0m     \u001b[91m,)))))\u001b[0m \n",
            "        \u001b[94m#%%%%#\u001b[0m      \u001b[94m/%%%%%%/\u001b[0m      \u001b[94m(%%%%%%\u001b[0m      \u001b[92m/)/)//\u001b[0m       \u001b[93m******\u001b[0m      \u001b[91m))))))\u001b[0m \n",
            "          \u001b[94m##\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m                  \u001b[93m*******\u001b[0m      \u001b[91m))))))\u001b[0m  \n",
            "                \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m**.\u001b[0m             \u001b[93m/*******\u001b[0m      \u001b[91m.))))))\u001b[0m  \n",
            "              \u001b[94m*%%%%%%/\u001b[0m      \u001b[94m(%%%%%%\u001b[0m   \u001b[93m********/*..,*/*********\u001b[0m       \u001b[91m*))))))\u001b[0m   \n",
            "                \u001b[94m#%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m    \u001b[93m*********************/\u001b[0m        \u001b[91m)))))))\u001b[0m    \n",
            "                        \u001b[94m*%%%%%%,\u001b[0m         \u001b[93m,**************/\u001b[0m         \u001b[91m,))))))/\u001b[0m     \n",
            "                      \u001b[94m(%%%%%%\u001b[0m   \u001b[91m()\u001b[0m                              \u001b[91m))))))))\u001b[0m       \n",
            "                      \u001b[94m#%%%%,\u001b[0m  \u001b[91m())))))\u001b[0m                        \u001b[91m,)))))))),\u001b[0m        \n",
            "                        \u001b[94m#,\u001b[0m    \u001b[91m())))))))))\u001b[0m                \u001b[91m,)))))))))).\u001b[0m          \n",
            "                                 \u001b[91m()))))))))))))))))))))))))))))))/\u001b[0m             \n",
            "                                    \u001b[91m())))))))))))))))))))))))).\u001b[0m                \n",
            "                                         \u001b[91m())))))))))))))),\u001b[0m                     \n",
            "\n",
            "-=# \u001b[1;94m geomeTRIC started. Version: 1.1 \u001b[0m #=-\n",
            "Current date and time: 2026-01-30 11:01:58\n",
            "#========================================================#\n",
            "#| \u001b[92m    Arguments passed to driver run_optimizer():     \u001b[0m |#\n",
            "#========================================================#\n",
            "convergence_dmax          0.0018 \n",
            "convergence_drms          0.0012 \n",
            "convergence_energy        1e-05 \n",
            "convergence_gmax          0.00045 \n",
            "convergence_grms          0.0003 \n",
            "customengine              <pyscf.geomopt.geometric_solver.PySCFEngine object at 0x789a27ba2050> \n",
            "input                     /tmp/tmp5m_b227t/e6e6d1f6-80b9-405e-88ed-7df8a99853d8 \n",
            "logIni                    /usr/local/lib/python3.11/dist-packages/pyscf/geomopt/log.ini \n",
            "maxiter                   100 \n",
            "----------------------------------------------------------\n",
            "Custom engine selected.\n",
            "Bonds will be generated from interatomic distances less than 1.20 times sum of covalent radii\n",
            "15 internal coordinates being used (instead of 15 Cartesians)\n",
            "Internal coordinate system (atoms numbered from 1):\n",
            "Distance 1-2\n",
            "Distance 1-3\n",
            "Distance 1-4\n",
            "Distance 1-5\n",
            "Angle 2-1-3\n",
            "Angle 2-1-4\n",
            "Angle 2-1-5\n",
            "Angle 3-1-4\n",
            "Angle 3-1-5\n",
            "Angle 4-1-5\n",
            "Translation-X 1-5\n",
            "Translation-Y 1-5\n",
            "Translation-Z 1-5\n",
            "Rotation-A 1-5\n",
            "Rotation-B 1-5\n",
            "Rotation-C 1-5\n",
            "<class 'geometric.internal.Distance'> : 4\n",
            "<class 'geometric.internal.Angle'> : 6\n",
            "<class 'geometric.internal.TranslationX'> : 1\n",
            "<class 'geometric.internal.TranslationY'> : 1\n",
            "<class 'geometric.internal.TranslationZ'> : 1\n",
            "<class 'geometric.internal.RotationA'> : 1\n",
            "<class 'geometric.internal.RotationB'> : 1\n",
            "<class 'geometric.internal.RotationC'> : 1\n",
            "> ===== Optimization Info: ====\n",
            "> Job type: Energy minimization\n",
            "> Maximum number of optimization cycles: 100\n",
            "> Initial / maximum trust radius (Angstrom): 0.100 / 0.300\n",
            "> Convergence Criteria:\n",
            "> Will converge when all 5 criteria are reached:\n",
            ">  |Delta-E| < 1.00e-05\n",
            ">  RMS-Grad  < 3.00e-04\n",
            ">  Max-Grad  < 4.50e-04\n",
            ">  RMS-Disp  < 1.20e-03\n",
            ">  Max-Disp  < 1.80e-03\n",
            "> === End Optimization Info ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCF calculation completed successfully.\n",
            "Number of occupied orbitals: 5\n",
            "GAP:  [22.32075793]\n",
            "GAP type:  <class 'numpy.ndarray'>\n",
            "smiles_chosen:  C\n",
            "使用するXYZデータ:\n",
            " C      0.000000   -0.000000   -0.000000\n",
            "H      0.532518    0.750164   -0.588709\n",
            "H      0.718148   -0.588339    0.575343\n",
            "H     -0.557744   -0.659078   -0.668908\n",
            "H     -0.692923    0.497253    0.682273\n",
            "\n",
            "WARN: Mole.unit (angstrom) is changed to Bohr\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Step    0 : Gradient = 3.268e-03/3.654e-03 (rms/max) Energy = -40.0391513956\n",
            "Hessian Eigenvalues: 5.00000e-02 5.00000e-02 5.00000e-02 ... 3.45597e-01 3.45597e-01 3.45597e-01\n",
            "Step    1 : Displace = \u001b[0m5.004e-03\u001b[0m/\u001b[0m5.595e-03\u001b[0m (rms/max) Trust = 1.000e-01 (=) Grad = \u001b[0m6.571e-04\u001b[0m/\u001b[0m7.351e-04\u001b[0m (rms/max) E (change) = -40.0392126819 (\u001b[0m-6.129e-05\u001b[0m) Quality = \u001b[0m0.793\u001b[0m\n",
            "Hessian Eigenvalues: 4.99999e-02 5.00000e-02 5.00000e-02 ... 3.45597e-01 3.45597e-01 4.15092e-01\n",
            "Step    2 : Displace = \u001b[92m8.377e-04\u001b[0m/\u001b[92m9.367e-04\u001b[0m (rms/max) Trust = 1.414e-01 (\u001b[92m+\u001b[0m) Grad = \u001b[92m7.857e-06\u001b[0m/\u001b[92m9.139e-06\u001b[0m (rms/max) E (change) = -40.0392153125 (\u001b[92m-2.631e-06\u001b[0m) Quality = \u001b[0m1.011\u001b[0m\n",
            "Hessian Eigenvalues: 4.99999e-02 5.00000e-02 5.00000e-02 ... 3.45597e-01 3.45597e-01 4.15092e-01\n",
            "Converged! =D\n",
            "\n",
            "    #==========================================================================#\n",
            "    #| If this code has benefited your research, please support us by citing: |#\n",
            "    #|                                                                        |#\n",
            "    #| Wang, L.-P.; Song, C.C. (2016) \"Geometry optimization made simple with |#\n",
            "    #| translation and rotation coordinates\", J. Chem, Phys. 144, 214108.     |#\n",
            "    #| http://dx.doi.org/10.1063/1.4952956                                    |#\n",
            "    #==========================================================================#\n",
            "    Time elapsed since start of run_optimizer: 1.270 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU計算時間: 1.33秒\n",
            "converged SCF energy = -40.0388552264663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "geometric-optimize called with the following command line:\n",
            "/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-010f6a21-b892-41de-b6ba-3ab3f0afa510.json\n",
            "\n",
            "                                        \u001b[91m())))))))))))))))/\u001b[0m                     \n",
            "                                    \u001b[91m())))))))))))))))))))))))),\u001b[0m                \n",
            "                                \u001b[91m*)))))))))))))))))))))))))))))))))\u001b[0m             \n",
            "                        \u001b[94m#,\u001b[0m    \u001b[91m()))))))))/\u001b[0m                \u001b[91m.)))))))))),\u001b[0m          \n",
            "                      \u001b[94m#%%%%,\u001b[0m  \u001b[91m())))))\u001b[0m                        \u001b[91m.))))))))*\u001b[0m        \n",
            "                      \u001b[94m*%%%%%%,\u001b[0m  \u001b[91m))\u001b[0m              \u001b[93m..\u001b[0m              \u001b[91m,))))))).\u001b[0m      \n",
            "                        \u001b[94m*%%%%%%,\u001b[0m         \u001b[93m***************/.\u001b[0m        \u001b[91m.)))))))\u001b[0m     \n",
            "                \u001b[94m#%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m    \u001b[93m/*********************.\u001b[0m       \u001b[91m)))))))\u001b[0m    \n",
            "              \u001b[94m.%%%%%%#\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m*******/,\u001b[0m     \u001b[93m**********,\u001b[0m      \u001b[91m.))))))\u001b[0m   \n",
            "                \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m**\u001b[0m              \u001b[93m********\u001b[0m      \u001b[91m.))))))\u001b[0m  \n",
            "          \u001b[94m##\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m                  \u001b[93m,******\u001b[0m      \u001b[91m/)))))\u001b[0m  \n",
            "        \u001b[94m%%%%%%\u001b[0m      \u001b[94m.%%%%%%#\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m    \u001b[92m,/////.\u001b[0m       \u001b[93m******\u001b[0m      \u001b[91m))))))\u001b[0m \n",
            "      \u001b[94m#%\u001b[0m      \u001b[94m%%\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[92m////////,\u001b[0m      \u001b[93m*****/\u001b[0m     \u001b[91m,)))))\u001b[0m \n",
            "    \u001b[94m#%%\u001b[0m  \u001b[94m%%%\u001b[0m  \u001b[94m%%%#\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m  \u001b[92m///////.\u001b[0m     \u001b[93m/*****\u001b[0m      \u001b[91m))))).\u001b[0m\n",
            "  \u001b[94m#%%%%.\u001b[0m      \u001b[94m%%%%%#\u001b[0m      \u001b[94m/%%%%%%*\u001b[0m      \u001b[94m#%%%%%%\u001b[0m   \u001b[92m/////)\u001b[0m     \u001b[93m******\u001b[0m      \u001b[91m))))),\u001b[0m\n",
            "    \u001b[94m#%%%%##%\u001b[0m  \u001b[94m%%%#\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m  \u001b[92m///////.\u001b[0m     \u001b[93m/*****\u001b[0m      \u001b[91m))))).\u001b[0m\n",
            "      \u001b[94m##\u001b[0m     \u001b[94m%%%\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[92m////////.\u001b[0m      \u001b[93m*****/\u001b[0m     \u001b[91m,)))))\u001b[0m \n",
            "        \u001b[94m#%%%%#\u001b[0m      \u001b[94m/%%%%%%/\u001b[0m      \u001b[94m(%%%%%%\u001b[0m      \u001b[92m/)/)//\u001b[0m       \u001b[93m******\u001b[0m      \u001b[91m))))))\u001b[0m \n",
            "          \u001b[94m##\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m                  \u001b[93m*******\u001b[0m      \u001b[91m))))))\u001b[0m  \n",
            "                \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m**.\u001b[0m             \u001b[93m/*******\u001b[0m      \u001b[91m.))))))\u001b[0m  \n",
            "              \u001b[94m*%%%%%%/\u001b[0m      \u001b[94m(%%%%%%\u001b[0m   \u001b[93m********/*..,*/*********\u001b[0m       \u001b[91m*))))))\u001b[0m   \n",
            "                \u001b[94m#%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m    \u001b[93m*********************/\u001b[0m        \u001b[91m)))))))\u001b[0m    \n",
            "                        \u001b[94m*%%%%%%,\u001b[0m         \u001b[93m,**************/\u001b[0m         \u001b[91m,))))))/\u001b[0m     \n",
            "                      \u001b[94m(%%%%%%\u001b[0m   \u001b[91m()\u001b[0m                              \u001b[91m))))))))\u001b[0m       \n",
            "                      \u001b[94m#%%%%,\u001b[0m  \u001b[91m())))))\u001b[0m                        \u001b[91m,)))))))),\u001b[0m        \n",
            "                        \u001b[94m#,\u001b[0m    \u001b[91m())))))))))\u001b[0m                \u001b[91m,)))))))))).\u001b[0m          \n",
            "                                 \u001b[91m()))))))))))))))))))))))))))))))/\u001b[0m             \n",
            "                                    \u001b[91m())))))))))))))))))))))))).\u001b[0m                \n",
            "                                         \u001b[91m())))))))))))))),\u001b[0m                     \n",
            "\n",
            "-=# \u001b[1;94m geomeTRIC started. Version: 1.1 \u001b[0m #=-\n",
            "Current date and time: 2026-01-30 11:02:00\n",
            "#========================================================#\n",
            "#| \u001b[92m    Arguments passed to driver run_optimizer():     \u001b[0m |#\n",
            "#========================================================#\n",
            "convergence_dmax          0.0018 \n",
            "convergence_drms          0.0012 \n",
            "convergence_energy        1e-05 \n",
            "convergence_gmax          0.00045 \n",
            "convergence_grms          0.0003 \n",
            "customengine              <pyscf.geomopt.geometric_solver.PySCFEngine object at 0x789a2791d7d0> \n",
            "input                     /tmp/tmpuuqh23el/ae90c018-4ec7-4735-bc3e-f7a087fcddbd \n",
            "logIni                    /usr/local/lib/python3.11/dist-packages/pyscf/geomopt/log.ini \n",
            "maxiter                   100 \n",
            "----------------------------------------------------------\n",
            "Custom engine selected.\n",
            "Bonds will be generated from interatomic distances less than 1.20 times sum of covalent radii\n",
            "54 internal coordinates being used (instead of 54 Cartesians)\n",
            "Internal coordinate system (atoms numbered from 1):\n",
            "Distance 1-2\n",
            "Distance 1-12\n",
            "Distance 1-13\n",
            "Distance 2-3\n",
            "Distance 2-14\n",
            "Distance 3-4\n",
            "Distance 3-11\n",
            "Distance 4-5\n",
            "Distance 4-15\n",
            "Distance 5-6\n",
            "Distance 5-9\n",
            "Distance 6-7\n",
            "Distance 7-8\n",
            "Distance 7-16\n",
            "Distance 8-9\n",
            "Distance 8-17\n",
            "Distance 9-10\n",
            "Distance 10-11\n",
            "Distance 10-18\n",
            "Distance 11-12\n",
            "Angle 2-1-13\n",
            "Angle 12-1-13\n",
            "Angle 1-2-14\n",
            "Angle 3-2-14\n",
            "Angle 2-3-11\n",
            "Angle 4-3-11\n",
            "Angle 3-4-15\n",
            "Angle 5-4-15\n",
            "Angle 4-5-9\n",
            "Angle 6-5-9\n",
            "Angle 5-6-7\n",
            "Angle 6-7-16\n",
            "Angle 8-7-16\n",
            "Angle 7-8-17\n",
            "Angle 9-8-17\n",
            "Angle 5-9-10\n",
            "Angle 8-9-10\n",
            "Angle 9-10-18\n",
            "Angle 11-10-18\n",
            "Angle 3-11-12\n",
            "Angle 10-11-12\n",
            "Angle 1-12-11\n",
            "Out-of-Plane 1-2-12-13\n",
            "Out-of-Plane 2-1-3-14\n",
            "Out-of-Plane 3-2-4-11\n",
            "Out-of-Plane 4-3-5-15\n",
            "Out-of-Plane 5-4-6-9\n",
            "Out-of-Plane 7-6-8-16\n",
            "Out-of-Plane 8-7-9-17\n",
            "Out-of-Plane 9-5-8-10\n",
            "Out-of-Plane 10-9-11-18\n",
            "Out-of-Plane 11-3-10-12\n",
            "Dihedral 12-1-2-3\n",
            "Dihedral 12-1-2-14\n",
            "Dihedral 13-1-2-3\n",
            "Dihedral 13-1-2-14\n",
            "Dihedral 2-1-12-11\n",
            "Dihedral 13-1-12-11\n",
            "Dihedral 1-2-3-4\n",
            "Dihedral 1-2-3-11\n",
            "Dihedral 14-2-3-4\n",
            "Dihedral 14-2-3-11\n",
            "Dihedral 2-3-4-5\n",
            "Dihedral 2-3-4-15\n",
            "Dihedral 11-3-4-5\n",
            "Dihedral 11-3-4-15\n",
            "Dihedral 2-3-11-10\n",
            "Dihedral 2-3-11-12\n",
            "Dihedral 4-3-11-10\n",
            "Dihedral 4-3-11-12\n",
            "Dihedral 3-4-5-6\n",
            "Dihedral 3-4-5-9\n",
            "Dihedral 15-4-5-6\n",
            "Dihedral 15-4-5-9\n",
            "Dihedral 4-5-6-7\n",
            "Dihedral 9-5-6-7\n",
            "Dihedral 4-5-9-8\n",
            "Dihedral 4-5-9-10\n",
            "Dihedral 6-5-9-8\n",
            "Dihedral 6-5-9-10\n",
            "Dihedral 5-6-7-8\n",
            "Dihedral 5-6-7-16\n",
            "Dihedral 6-7-8-9\n",
            "Dihedral 6-7-8-17\n",
            "Dihedral 16-7-8-9\n",
            "Dihedral 16-7-8-17\n",
            "Dihedral 7-8-9-5\n",
            "Dihedral 7-8-9-10\n",
            "Dihedral 17-8-9-5\n",
            "Dihedral 17-8-9-10\n",
            "Dihedral 5-9-10-11\n",
            "Dihedral 5-9-10-18\n",
            "Dihedral 8-9-10-11\n",
            "Dihedral 8-9-10-18\n",
            "Dihedral 9-10-11-3\n",
            "Dihedral 9-10-11-12\n",
            "Dihedral 18-10-11-3\n",
            "Dihedral 18-10-11-12\n",
            "Dihedral 3-11-12-1\n",
            "Dihedral 10-11-12-1\n",
            "Translation-X 1-18\n",
            "Translation-Y 1-18\n",
            "Translation-Z 1-18\n",
            "Rotation-A 1-18\n",
            "Rotation-B 1-18\n",
            "Rotation-C 1-18\n",
            "<class 'geometric.internal.Distance'> : 20\n",
            "<class 'geometric.internal.Angle'> : 22\n",
            "<class 'geometric.internal.OutOfPlane'> : 10\n",
            "<class 'geometric.internal.Dihedral'> : 48\n",
            "<class 'geometric.internal.TranslationX'> : 1\n",
            "<class 'geometric.internal.TranslationY'> : 1\n",
            "<class 'geometric.internal.TranslationZ'> : 1\n",
            "<class 'geometric.internal.RotationA'> : 1\n",
            "<class 'geometric.internal.RotationB'> : 1\n",
            "<class 'geometric.internal.RotationC'> : 1\n",
            "> ===== Optimization Info: ====\n",
            "> Job type: Energy minimization\n",
            "> Maximum number of optimization cycles: 100\n",
            "> Initial / maximum trust radius (Angstrom): 0.100 / 0.300\n",
            "> Convergence Criteria:\n",
            "> Will converge when all 5 criteria are reached:\n",
            ">  |Delta-E| < 1.00e-05\n",
            ">  RMS-Grad  < 3.00e-04\n",
            ">  Max-Grad  < 4.50e-04\n",
            ">  RMS-Disp  < 1.20e-03\n",
            ">  Max-Disp  < 1.80e-03\n",
            "> === End Optimization Info ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCF calculation completed successfully.\n",
            "Number of occupied orbitals: 5\n",
            "GAP:  [22.32075793]\n",
            "GAP type:  <class 'numpy.ndarray'>\n",
            "smiles_chosen:  c1cc2cc3sccc3cc2s1\n",
            "使用するXYZデータ:\n",
            " C      3.405427    0.495863    0.761687\n",
            "C      2.817129   -0.388367   -0.112160\n",
            "C      1.386366   -0.278809   -0.136694\n",
            "C      0.423207   -0.983730   -0.876993\n",
            "C     -0.940116   -0.707450   -0.740616\n",
            "S     -2.251656   -1.464687   -1.560322\n",
            "C     -3.405427   -0.495863   -0.761687\n",
            "C     -2.817129    0.388368    0.112160\n",
            "C     -1.386366    0.278809    0.136694\n",
            "C     -0.423207    0.983731    0.876993\n",
            "C      0.940115    0.707449    0.740617\n",
            "S      2.251655    1.464683    1.560325\n",
            "H      4.459379    0.619399    0.969588\n",
            "H      3.383538   -1.088997   -0.713371\n",
            "H      0.746951   -1.758559   -1.568599\n",
            "H     -4.459379   -0.619397   -0.969591\n",
            "H     -3.383538    1.088995    0.713374\n",
            "H     -0.746950    1.758563    1.568595\n",
            "\n",
            "WARN: Mole.unit (angstrom) is changed to Bohr\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Step    0 : Gradient = 3.107e-02/5.959e-02 (rms/max) Energy = -1167.5609060004\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.60031e-01 4.89360e-01 4.89634e-01\n",
            "Step    1 : Displace = \u001b[0m9.331e-02\u001b[0m/\u001b[0m1.607e-01\u001b[0m (rms/max) Trust = 1.000e-01 (=) Grad = \u001b[0m2.069e-02\u001b[0m/\u001b[0m3.963e-02\u001b[0m (rms/max) E (change) = -1167.5637972072 (\u001b[0m-2.891e-03\u001b[0m) Quality = \u001b[0m0.114\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.86518e-01 4.89383e-01 6.83127e-01\n",
            "Step    2 : Displace = \u001b[0m4.924e-02\u001b[0m/\u001b[0m8.577e-02\u001b[0m (rms/max) Trust = 4.666e-02 (\u001b[91m-\u001b[0m) Grad = \u001b[0m8.633e-03\u001b[0m/\u001b[0m1.641e-02\u001b[0m (rms/max) E (change) = -1167.5761584412 (\u001b[0m-1.236e-02\u001b[0m) Quality = \u001b[0m0.893\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.87467e-01 4.89091e-01 7.58804e-01\n",
            "Step    3 : Displace = \u001b[0m2.734e-02\u001b[0m/\u001b[0m5.225e-02\u001b[0m (rms/max) Trust = 6.598e-02 (\u001b[92m+\u001b[0m) Grad = \u001b[0m2.969e-03\u001b[0m/\u001b[0m5.568e-03\u001b[0m (rms/max) E (change) = -1167.5782046229 (\u001b[0m-2.046e-03\u001b[0m) Quality = \u001b[0m0.791\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.88760e-01 4.92742e-01 6.96537e-01\n",
            "Step    4 : Displace = \u001b[0m1.213e-02\u001b[0m/\u001b[0m2.159e-02\u001b[0m (rms/max) Trust = 9.331e-02 (\u001b[92m+\u001b[0m) Grad = \u001b[0m2.831e-03\u001b[0m/\u001b[0m6.257e-03\u001b[0m (rms/max) E (change) = -1167.5782401752 (\u001b[0m-3.555e-05\u001b[0m) Quality = \u001b[0m0.086\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.87497e-01 5.98937e-01 6.95794e-01\n",
            "Step    5 : Displace = \u001b[0m5.892e-03\u001b[0m/\u001b[0m8.986e-03\u001b[0m (rms/max) Trust = 6.063e-03 (\u001b[91m-\u001b[0m) Grad = \u001b[0m6.101e-04\u001b[0m/\u001b[0m1.123e-03\u001b[0m (rms/max) E (change) = -1167.5784607349 (\u001b[0m-2.206e-04\u001b[0m) Quality = \u001b[0m0.892\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.88298e-01 6.28784e-01 6.99134e-01\n",
            "Step    6 : Displace = \u001b[0m2.330e-03\u001b[0m/\u001b[0m3.801e-03\u001b[0m (rms/max) Trust = 8.574e-03 (\u001b[92m+\u001b[0m) Grad = \u001b[92m2.743e-04\u001b[0m/\u001b[0m5.327e-04\u001b[0m (rms/max) E (change) = -1167.5784696273 (\u001b[92m-8.892e-06\u001b[0m) Quality = \u001b[0m0.606\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.91394e-01 5.95942e-01 7.00662e-01\n",
            "Step    7 : Displace = \u001b[92m9.788e-04\u001b[0m/\u001b[0m2.036e-03\u001b[0m (rms/max) Trust = 8.574e-03 (=) Grad = \u001b[92m8.486e-05\u001b[0m/\u001b[92m1.759e-04\u001b[0m (rms/max) E (change) = -1167.5784715660 (\u001b[92m-1.939e-06\u001b[0m) Quality = \u001b[0m0.831\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 5.12850e-01 5.96164e-01 6.99090e-01\n",
            "Step    8 : Displace = \u001b[92m5.512e-04\u001b[0m/\u001b[92m8.880e-04\u001b[0m (rms/max) Trust = 1.213e-02 (\u001b[92m+\u001b[0m) Grad = \u001b[92m1.605e-04\u001b[0m/\u001b[92m3.538e-04\u001b[0m (rms/max) E (change) = -1167.5784710839 (\u001b[92m+4.822e-07\u001b[0m) Quality = \u001b[91m-0.957\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 5.12850e-01 5.96164e-01 6.99090e-01\n",
            "Converged! =D\n",
            "\n",
            "    #==========================================================================#\n",
            "    #| If this code has benefited your research, please support us by citing: |#\n",
            "    #|                                                                        |#\n",
            "    #| Wang, L.-P.; Song, C.C. (2016) \"Geometry optimization made simple with |#\n",
            "    #| translation and rotation coordinates\", J. Chem, Phys. 144, 214108.     |#\n",
            "    #| http://dx.doi.org/10.1063/1.4952956                                    |#\n",
            "    #==========================================================================#\n",
            "    Time elapsed since start of run_optimizer: 22.228 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU計算時間: 22.29秒\n",
            "converged SCF energy = -1167.55696867553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "geometric-optimize called with the following command line:\n",
            "/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-010f6a21-b892-41de-b6ba-3ab3f0afa510.json\n",
            "\n",
            "                                        \u001b[91m())))))))))))))))/\u001b[0m                     \n",
            "                                    \u001b[91m())))))))))))))))))))))))),\u001b[0m                \n",
            "                                \u001b[91m*)))))))))))))))))))))))))))))))))\u001b[0m             \n",
            "                        \u001b[94m#,\u001b[0m    \u001b[91m()))))))))/\u001b[0m                \u001b[91m.)))))))))),\u001b[0m          \n",
            "                      \u001b[94m#%%%%,\u001b[0m  \u001b[91m())))))\u001b[0m                        \u001b[91m.))))))))*\u001b[0m        \n",
            "                      \u001b[94m*%%%%%%,\u001b[0m  \u001b[91m))\u001b[0m              \u001b[93m..\u001b[0m              \u001b[91m,))))))).\u001b[0m      \n",
            "                        \u001b[94m*%%%%%%,\u001b[0m         \u001b[93m***************/.\u001b[0m        \u001b[91m.)))))))\u001b[0m     \n",
            "                \u001b[94m#%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m    \u001b[93m/*********************.\u001b[0m       \u001b[91m)))))))\u001b[0m    \n",
            "              \u001b[94m.%%%%%%#\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m*******/,\u001b[0m     \u001b[93m**********,\u001b[0m      \u001b[91m.))))))\u001b[0m   \n",
            "                \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m**\u001b[0m              \u001b[93m********\u001b[0m      \u001b[91m.))))))\u001b[0m  \n",
            "          \u001b[94m##\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m                  \u001b[93m,******\u001b[0m      \u001b[91m/)))))\u001b[0m  \n",
            "        \u001b[94m%%%%%%\u001b[0m      \u001b[94m.%%%%%%#\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m    \u001b[92m,/////.\u001b[0m       \u001b[93m******\u001b[0m      \u001b[91m))))))\u001b[0m \n",
            "      \u001b[94m#%\u001b[0m      \u001b[94m%%\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[92m////////,\u001b[0m      \u001b[93m*****/\u001b[0m     \u001b[91m,)))))\u001b[0m \n",
            "    \u001b[94m#%%\u001b[0m  \u001b[94m%%%\u001b[0m  \u001b[94m%%%#\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m  \u001b[92m///////.\u001b[0m     \u001b[93m/*****\u001b[0m      \u001b[91m))))).\u001b[0m\n",
            "  \u001b[94m#%%%%.\u001b[0m      \u001b[94m%%%%%#\u001b[0m      \u001b[94m/%%%%%%*\u001b[0m      \u001b[94m#%%%%%%\u001b[0m   \u001b[92m/////)\u001b[0m     \u001b[93m******\u001b[0m      \u001b[91m))))),\u001b[0m\n",
            "    \u001b[94m#%%%%##%\u001b[0m  \u001b[94m%%%#\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m  \u001b[92m///////.\u001b[0m     \u001b[93m/*****\u001b[0m      \u001b[91m))))).\u001b[0m\n",
            "      \u001b[94m##\u001b[0m     \u001b[94m%%%\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[92m////////.\u001b[0m      \u001b[93m*****/\u001b[0m     \u001b[91m,)))))\u001b[0m \n",
            "        \u001b[94m#%%%%#\u001b[0m      \u001b[94m/%%%%%%/\u001b[0m      \u001b[94m(%%%%%%\u001b[0m      \u001b[92m/)/)//\u001b[0m       \u001b[93m******\u001b[0m      \u001b[91m))))))\u001b[0m \n",
            "          \u001b[94m##\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m                  \u001b[93m*******\u001b[0m      \u001b[91m))))))\u001b[0m  \n",
            "                \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m**.\u001b[0m             \u001b[93m/*******\u001b[0m      \u001b[91m.))))))\u001b[0m  \n",
            "              \u001b[94m*%%%%%%/\u001b[0m      \u001b[94m(%%%%%%\u001b[0m   \u001b[93m********/*..,*/*********\u001b[0m       \u001b[91m*))))))\u001b[0m   \n",
            "                \u001b[94m#%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m    \u001b[93m*********************/\u001b[0m        \u001b[91m)))))))\u001b[0m    \n",
            "                        \u001b[94m*%%%%%%,\u001b[0m         \u001b[93m,**************/\u001b[0m         \u001b[91m,))))))/\u001b[0m     \n",
            "                      \u001b[94m(%%%%%%\u001b[0m   \u001b[91m()\u001b[0m                              \u001b[91m))))))))\u001b[0m       \n",
            "                      \u001b[94m#%%%%,\u001b[0m  \u001b[91m())))))\u001b[0m                        \u001b[91m,)))))))),\u001b[0m        \n",
            "                        \u001b[94m#,\u001b[0m    \u001b[91m())))))))))\u001b[0m                \u001b[91m,)))))))))).\u001b[0m          \n",
            "                                 \u001b[91m()))))))))))))))))))))))))))))))/\u001b[0m             \n",
            "                                    \u001b[91m())))))))))))))))))))))))).\u001b[0m                \n",
            "                                         \u001b[91m())))))))))))))),\u001b[0m                     \n",
            "\n",
            "-=# \u001b[1;94m geomeTRIC started. Version: 1.1 \u001b[0m #=-\n",
            "Current date and time: 2026-01-30 11:02:26\n",
            "#========================================================#\n",
            "#| \u001b[92m    Arguments passed to driver run_optimizer():     \u001b[0m |#\n",
            "#========================================================#\n",
            "convergence_dmax          0.0018 \n",
            "convergence_drms          0.0012 \n",
            "convergence_energy        1e-05 \n",
            "convergence_gmax          0.00045 \n",
            "convergence_grms          0.0003 \n",
            "customengine              <pyscf.geomopt.geometric_solver.PySCFEngine object at 0x789a27aa1250> \n",
            "input                     /tmp/tmp60g4ozpw/d61d4742-9dbe-446f-9864-00bba45c5e9c \n",
            "logIni                    /usr/local/lib/python3.11/dist-packages/pyscf/geomopt/log.ini \n",
            "maxiter                   100 \n",
            "----------------------------------------------------------\n",
            "Custom engine selected.\n",
            "Bonds will be generated from interatomic distances less than 1.20 times sum of covalent radii\n",
            "15 internal coordinates being used (instead of 15 Cartesians)\n",
            "Internal coordinate system (atoms numbered from 1):\n",
            "Distance 1-2\n",
            "Distance 1-3\n",
            "Distance 1-4\n",
            "Distance 1-5\n",
            "Angle 2-1-3\n",
            "Angle 2-1-4\n",
            "Angle 2-1-5\n",
            "Angle 3-1-4\n",
            "Angle 3-1-5\n",
            "Angle 4-1-5\n",
            "Translation-X 1-5\n",
            "Translation-Y 1-5\n",
            "Translation-Z 1-5\n",
            "Rotation-A 1-5\n",
            "Rotation-B 1-5\n",
            "Rotation-C 1-5\n",
            "<class 'geometric.internal.Distance'> : 4\n",
            "<class 'geometric.internal.Angle'> : 6\n",
            "<class 'geometric.internal.TranslationX'> : 1\n",
            "<class 'geometric.internal.TranslationY'> : 1\n",
            "<class 'geometric.internal.TranslationZ'> : 1\n",
            "<class 'geometric.internal.RotationA'> : 1\n",
            "<class 'geometric.internal.RotationB'> : 1\n",
            "<class 'geometric.internal.RotationC'> : 1\n",
            "> ===== Optimization Info: ====\n",
            "> Job type: Energy minimization\n",
            "> Maximum number of optimization cycles: 100\n",
            "> Initial / maximum trust radius (Angstrom): 0.100 / 0.300\n",
            "> Convergence Criteria:\n",
            "> Will converge when all 5 criteria are reached:\n",
            ">  |Delta-E| < 1.00e-05\n",
            ">  RMS-Grad  < 3.00e-04\n",
            ">  Max-Grad  < 4.50e-04\n",
            ">  RMS-Disp  < 1.20e-03\n",
            ">  Max-Disp  < 1.80e-03\n",
            "> === End Optimization Info ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCF calculation completed successfully.\n",
            "Number of occupied orbitals: 49\n",
            "GAP:  [4.66325129]\n",
            "GAP type:  <class 'numpy.ndarray'>\n",
            "smiles_chosen:  C\n",
            "使用するXYZデータ:\n",
            " C      0.000000   -0.000000   -0.000000\n",
            "H      0.532518    0.750164   -0.588709\n",
            "H      0.718148   -0.588339    0.575343\n",
            "H     -0.557744   -0.659078   -0.668908\n",
            "H     -0.692923    0.497253    0.682273\n",
            "\n",
            "WARN: Mole.unit (angstrom) is changed to Bohr\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Step    0 : Gradient = 3.268e-03/3.654e-03 (rms/max) Energy = -40.0391513956\n",
            "Hessian Eigenvalues: 5.00000e-02 5.00000e-02 5.00000e-02 ... 3.45597e-01 3.45597e-01 3.45597e-01\n",
            "Step    1 : Displace = \u001b[0m5.004e-03\u001b[0m/\u001b[0m5.595e-03\u001b[0m (rms/max) Trust = 1.000e-01 (=) Grad = \u001b[0m6.571e-04\u001b[0m/\u001b[0m7.351e-04\u001b[0m (rms/max) E (change) = -40.0392126819 (\u001b[0m-6.129e-05\u001b[0m) Quality = \u001b[0m0.793\u001b[0m\n",
            "Hessian Eigenvalues: 4.99999e-02 5.00000e-02 5.00000e-02 ... 3.45597e-01 3.45597e-01 4.15092e-01\n",
            "Step    2 : Displace = \u001b[92m8.377e-04\u001b[0m/\u001b[92m9.367e-04\u001b[0m (rms/max) Trust = 1.414e-01 (\u001b[92m+\u001b[0m) Grad = \u001b[92m7.857e-06\u001b[0m/\u001b[92m9.139e-06\u001b[0m (rms/max) E (change) = -40.0392153125 (\u001b[92m-2.631e-06\u001b[0m) Quality = \u001b[0m1.011\u001b[0m\n",
            "Hessian Eigenvalues: 4.99999e-02 5.00000e-02 5.00000e-02 ... 3.45597e-01 3.45597e-01 4.15092e-01\n",
            "Converged! =D\n",
            "\n",
            "    #==========================================================================#\n",
            "    #| If this code has benefited your research, please support us by citing: |#\n",
            "    #|                                                                        |#\n",
            "    #| Wang, L.-P.; Song, C.C. (2016) \"Geometry optimization made simple with |#\n",
            "    #| translation and rotation coordinates\", J. Chem, Phys. 144, 214108.     |#\n",
            "    #| http://dx.doi.org/10.1063/1.4952956                                    |#\n",
            "    #==========================================================================#\n",
            "    Time elapsed since start of run_optimizer: 1.272 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU計算時間: 1.32秒\n",
            "converged SCF energy = -40.0388552264663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "geometric-optimize called with the following command line:\n",
            "/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-010f6a21-b892-41de-b6ba-3ab3f0afa510.json\n",
            "\n",
            "                                        \u001b[91m())))))))))))))))/\u001b[0m                     \n",
            "                                    \u001b[91m())))))))))))))))))))))))),\u001b[0m                \n",
            "                                \u001b[91m*)))))))))))))))))))))))))))))))))\u001b[0m             \n",
            "                        \u001b[94m#,\u001b[0m    \u001b[91m()))))))))/\u001b[0m                \u001b[91m.)))))))))),\u001b[0m          \n",
            "                      \u001b[94m#%%%%,\u001b[0m  \u001b[91m())))))\u001b[0m                        \u001b[91m.))))))))*\u001b[0m        \n",
            "                      \u001b[94m*%%%%%%,\u001b[0m  \u001b[91m))\u001b[0m              \u001b[93m..\u001b[0m              \u001b[91m,))))))).\u001b[0m      \n",
            "                        \u001b[94m*%%%%%%,\u001b[0m         \u001b[93m***************/.\u001b[0m        \u001b[91m.)))))))\u001b[0m     \n",
            "                \u001b[94m#%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m    \u001b[93m/*********************.\u001b[0m       \u001b[91m)))))))\u001b[0m    \n",
            "              \u001b[94m.%%%%%%#\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m*******/,\u001b[0m     \u001b[93m**********,\u001b[0m      \u001b[91m.))))))\u001b[0m   \n",
            "                \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m**\u001b[0m              \u001b[93m********\u001b[0m      \u001b[91m.))))))\u001b[0m  \n",
            "          \u001b[94m##\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m                  \u001b[93m,******\u001b[0m      \u001b[91m/)))))\u001b[0m  \n",
            "        \u001b[94m%%%%%%\u001b[0m      \u001b[94m.%%%%%%#\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m    \u001b[92m,/////.\u001b[0m       \u001b[93m******\u001b[0m      \u001b[91m))))))\u001b[0m \n",
            "      \u001b[94m#%\u001b[0m      \u001b[94m%%\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[92m////////,\u001b[0m      \u001b[93m*****/\u001b[0m     \u001b[91m,)))))\u001b[0m \n",
            "    \u001b[94m#%%\u001b[0m  \u001b[94m%%%\u001b[0m  \u001b[94m%%%#\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m  \u001b[92m///////.\u001b[0m     \u001b[93m/*****\u001b[0m      \u001b[91m))))).\u001b[0m\n",
            "  \u001b[94m#%%%%.\u001b[0m      \u001b[94m%%%%%#\u001b[0m      \u001b[94m/%%%%%%*\u001b[0m      \u001b[94m#%%%%%%\u001b[0m   \u001b[92m/////)\u001b[0m     \u001b[93m******\u001b[0m      \u001b[91m))))),\u001b[0m\n",
            "    \u001b[94m#%%%%##%\u001b[0m  \u001b[94m%%%#\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m  \u001b[92m///////.\u001b[0m     \u001b[93m/*****\u001b[0m      \u001b[91m))))).\u001b[0m\n",
            "      \u001b[94m##\u001b[0m     \u001b[94m%%%\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[92m////////.\u001b[0m      \u001b[93m*****/\u001b[0m     \u001b[91m,)))))\u001b[0m \n",
            "        \u001b[94m#%%%%#\u001b[0m      \u001b[94m/%%%%%%/\u001b[0m      \u001b[94m(%%%%%%\u001b[0m      \u001b[92m/)/)//\u001b[0m       \u001b[93m******\u001b[0m      \u001b[91m))))))\u001b[0m \n",
            "          \u001b[94m##\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m                  \u001b[93m*******\u001b[0m      \u001b[91m))))))\u001b[0m  \n",
            "                \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m**.\u001b[0m             \u001b[93m/*******\u001b[0m      \u001b[91m.))))))\u001b[0m  \n",
            "              \u001b[94m*%%%%%%/\u001b[0m      \u001b[94m(%%%%%%\u001b[0m   \u001b[93m********/*..,*/*********\u001b[0m       \u001b[91m*))))))\u001b[0m   \n",
            "                \u001b[94m#%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m    \u001b[93m*********************/\u001b[0m        \u001b[91m)))))))\u001b[0m    \n",
            "                        \u001b[94m*%%%%%%,\u001b[0m         \u001b[93m,**************/\u001b[0m         \u001b[91m,))))))/\u001b[0m     \n",
            "                      \u001b[94m(%%%%%%\u001b[0m   \u001b[91m()\u001b[0m                              \u001b[91m))))))))\u001b[0m       \n",
            "                      \u001b[94m#%%%%,\u001b[0m  \u001b[91m())))))\u001b[0m                        \u001b[91m,)))))))),\u001b[0m        \n",
            "                        \u001b[94m#,\u001b[0m    \u001b[91m())))))))))\u001b[0m                \u001b[91m,)))))))))).\u001b[0m          \n",
            "                                 \u001b[91m()))))))))))))))))))))))))))))))/\u001b[0m             \n",
            "                                    \u001b[91m())))))))))))))))))))))))).\u001b[0m                \n",
            "                                         \u001b[91m())))))))))))))),\u001b[0m                     \n",
            "\n",
            "-=# \u001b[1;94m geomeTRIC started. Version: 1.1 \u001b[0m #=-\n",
            "Current date and time: 2026-01-30 11:02:28\n",
            "#========================================================#\n",
            "#| \u001b[92m    Arguments passed to driver run_optimizer():     \u001b[0m |#\n",
            "#========================================================#\n",
            "convergence_dmax          0.0018 \n",
            "convergence_drms          0.0012 \n",
            "convergence_energy        1e-05 \n",
            "convergence_gmax          0.00045 \n",
            "convergence_grms          0.0003 \n",
            "customengine              <pyscf.geomopt.geometric_solver.PySCFEngine object at 0x789a278569d0> \n",
            "input                     /tmp/tmpiw4dq3_q/2acbf921-93d0-462b-bbf1-35dcc43e7cd4 \n",
            "logIni                    /usr/local/lib/python3.11/dist-packages/pyscf/geomopt/log.ini \n",
            "maxiter                   100 \n",
            "----------------------------------------------------------\n",
            "Custom engine selected.\n",
            "Bonds will be generated from interatomic distances less than 1.20 times sum of covalent radii\n",
            "54 internal coordinates being used (instead of 54 Cartesians)\n",
            "Internal coordinate system (atoms numbered from 1):\n",
            "Distance 1-2\n",
            "Distance 1-12\n",
            "Distance 1-13\n",
            "Distance 2-3\n",
            "Distance 2-14\n",
            "Distance 3-4\n",
            "Distance 3-11\n",
            "Distance 4-5\n",
            "Distance 4-15\n",
            "Distance 5-6\n",
            "Distance 5-9\n",
            "Distance 6-7\n",
            "Distance 7-8\n",
            "Distance 7-16\n",
            "Distance 8-9\n",
            "Distance 8-17\n",
            "Distance 9-10\n",
            "Distance 10-11\n",
            "Distance 10-18\n",
            "Distance 11-12\n",
            "Angle 2-1-13\n",
            "Angle 12-1-13\n",
            "Angle 1-2-14\n",
            "Angle 3-2-14\n",
            "Angle 2-3-11\n",
            "Angle 4-3-11\n",
            "Angle 3-4-15\n",
            "Angle 5-4-15\n",
            "Angle 4-5-9\n",
            "Angle 6-5-9\n",
            "Angle 5-6-7\n",
            "Angle 6-7-16\n",
            "Angle 8-7-16\n",
            "Angle 7-8-17\n",
            "Angle 9-8-17\n",
            "Angle 5-9-10\n",
            "Angle 8-9-10\n",
            "Angle 9-10-18\n",
            "Angle 11-10-18\n",
            "Angle 3-11-12\n",
            "Angle 10-11-12\n",
            "Angle 1-12-11\n",
            "Out-of-Plane 1-2-12-13\n",
            "Out-of-Plane 2-1-3-14\n",
            "Out-of-Plane 3-2-4-11\n",
            "Out-of-Plane 4-3-5-15\n",
            "Out-of-Plane 5-4-6-9\n",
            "Out-of-Plane 7-6-8-16\n",
            "Out-of-Plane 8-7-9-17\n",
            "Out-of-Plane 9-5-8-10\n",
            "Out-of-Plane 10-9-11-18\n",
            "Out-of-Plane 11-3-10-12\n",
            "Dihedral 12-1-2-3\n",
            "Dihedral 12-1-2-14\n",
            "Dihedral 13-1-2-3\n",
            "Dihedral 13-1-2-14\n",
            "Dihedral 2-1-12-11\n",
            "Dihedral 13-1-12-11\n",
            "Dihedral 1-2-3-4\n",
            "Dihedral 1-2-3-11\n",
            "Dihedral 14-2-3-4\n",
            "Dihedral 14-2-3-11\n",
            "Dihedral 2-3-4-5\n",
            "Dihedral 2-3-4-15\n",
            "Dihedral 11-3-4-5\n",
            "Dihedral 11-3-4-15\n",
            "Dihedral 2-3-11-10\n",
            "Dihedral 2-3-11-12\n",
            "Dihedral 4-3-11-10\n",
            "Dihedral 4-3-11-12\n",
            "Dihedral 3-4-5-6\n",
            "Dihedral 3-4-5-9\n",
            "Dihedral 15-4-5-6\n",
            "Dihedral 15-4-5-9\n",
            "Dihedral 4-5-6-7\n",
            "Dihedral 9-5-6-7\n",
            "Dihedral 4-5-9-8\n",
            "Dihedral 4-5-9-10\n",
            "Dihedral 6-5-9-8\n",
            "Dihedral 6-5-9-10\n",
            "Dihedral 5-6-7-8\n",
            "Dihedral 5-6-7-16\n",
            "Dihedral 6-7-8-9\n",
            "Dihedral 6-7-8-17\n",
            "Dihedral 16-7-8-9\n",
            "Dihedral 16-7-8-17\n",
            "Dihedral 7-8-9-5\n",
            "Dihedral 7-8-9-10\n",
            "Dihedral 17-8-9-5\n",
            "Dihedral 17-8-9-10\n",
            "Dihedral 5-9-10-11\n",
            "Dihedral 5-9-10-18\n",
            "Dihedral 8-9-10-11\n",
            "Dihedral 8-9-10-18\n",
            "Dihedral 9-10-11-3\n",
            "Dihedral 9-10-11-12\n",
            "Dihedral 18-10-11-3\n",
            "Dihedral 18-10-11-12\n",
            "Dihedral 3-11-12-1\n",
            "Dihedral 10-11-12-1\n",
            "Translation-X 1-18\n",
            "Translation-Y 1-18\n",
            "Translation-Z 1-18\n",
            "Rotation-A 1-18\n",
            "Rotation-B 1-18\n",
            "Rotation-C 1-18\n",
            "<class 'geometric.internal.Distance'> : 20\n",
            "<class 'geometric.internal.Angle'> : 22\n",
            "<class 'geometric.internal.OutOfPlane'> : 10\n",
            "<class 'geometric.internal.Dihedral'> : 48\n",
            "<class 'geometric.internal.TranslationX'> : 1\n",
            "<class 'geometric.internal.TranslationY'> : 1\n",
            "<class 'geometric.internal.TranslationZ'> : 1\n",
            "<class 'geometric.internal.RotationA'> : 1\n",
            "<class 'geometric.internal.RotationB'> : 1\n",
            "<class 'geometric.internal.RotationC'> : 1\n",
            "> ===== Optimization Info: ====\n",
            "> Job type: Energy minimization\n",
            "> Maximum number of optimization cycles: 100\n",
            "> Initial / maximum trust radius (Angstrom): 0.100 / 0.300\n",
            "> Convergence Criteria:\n",
            "> Will converge when all 5 criteria are reached:\n",
            ">  |Delta-E| < 1.00e-05\n",
            ">  RMS-Grad  < 3.00e-04\n",
            ">  Max-Grad  < 4.50e-04\n",
            ">  RMS-Disp  < 1.20e-03\n",
            ">  Max-Disp  < 1.80e-03\n",
            "> === End Optimization Info ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCF calculation completed successfully.\n",
            "Number of occupied orbitals: 5\n",
            "GAP:  [22.32075793]\n",
            "GAP type:  <class 'numpy.ndarray'>\n",
            "smiles_chosen:  c1cc2cc3sccc3cc2s1\n",
            "使用するXYZデータ:\n",
            " C      3.405427    0.495863    0.761687\n",
            "C      2.817129   -0.388367   -0.112160\n",
            "C      1.386366   -0.278809   -0.136694\n",
            "C      0.423207   -0.983730   -0.876993\n",
            "C     -0.940116   -0.707450   -0.740616\n",
            "S     -2.251656   -1.464687   -1.560322\n",
            "C     -3.405427   -0.495863   -0.761687\n",
            "C     -2.817129    0.388368    0.112160\n",
            "C     -1.386366    0.278809    0.136694\n",
            "C     -0.423207    0.983731    0.876993\n",
            "C      0.940115    0.707449    0.740617\n",
            "S      2.251655    1.464683    1.560325\n",
            "H      4.459379    0.619399    0.969588\n",
            "H      3.383538   -1.088997   -0.713371\n",
            "H      0.746951   -1.758559   -1.568599\n",
            "H     -4.459379   -0.619397   -0.969591\n",
            "H     -3.383538    1.088995    0.713374\n",
            "H     -0.746950    1.758563    1.568595\n",
            "\n",
            "WARN: Mole.unit (angstrom) is changed to Bohr\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Step    0 : Gradient = 3.107e-02/5.959e-02 (rms/max) Energy = -1167.5609060004\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.60031e-01 4.89360e-01 4.89634e-01\n",
            "Step    1 : Displace = \u001b[0m9.331e-02\u001b[0m/\u001b[0m1.607e-01\u001b[0m (rms/max) Trust = 1.000e-01 (=) Grad = \u001b[0m2.069e-02\u001b[0m/\u001b[0m3.963e-02\u001b[0m (rms/max) E (change) = -1167.5637972072 (\u001b[0m-2.891e-03\u001b[0m) Quality = \u001b[0m0.114\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.86518e-01 4.89383e-01 6.83127e-01\n",
            "Step    2 : Displace = \u001b[0m4.924e-02\u001b[0m/\u001b[0m8.577e-02\u001b[0m (rms/max) Trust = 4.666e-02 (\u001b[91m-\u001b[0m) Grad = \u001b[0m8.633e-03\u001b[0m/\u001b[0m1.641e-02\u001b[0m (rms/max) E (change) = -1167.5761584412 (\u001b[0m-1.236e-02\u001b[0m) Quality = \u001b[0m0.893\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.87467e-01 4.89091e-01 7.58804e-01\n",
            "Step    3 : Displace = \u001b[0m2.734e-02\u001b[0m/\u001b[0m5.225e-02\u001b[0m (rms/max) Trust = 6.598e-02 (\u001b[92m+\u001b[0m) Grad = \u001b[0m2.969e-03\u001b[0m/\u001b[0m5.568e-03\u001b[0m (rms/max) E (change) = -1167.5782046229 (\u001b[0m-2.046e-03\u001b[0m) Quality = \u001b[0m0.791\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.88760e-01 4.92742e-01 6.96537e-01\n",
            "Step    4 : Displace = \u001b[0m1.213e-02\u001b[0m/\u001b[0m2.159e-02\u001b[0m (rms/max) Trust = 9.331e-02 (\u001b[92m+\u001b[0m) Grad = \u001b[0m2.831e-03\u001b[0m/\u001b[0m6.257e-03\u001b[0m (rms/max) E (change) = -1167.5782401752 (\u001b[0m-3.555e-05\u001b[0m) Quality = \u001b[0m0.086\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.87497e-01 5.98937e-01 6.95794e-01\n",
            "Step    5 : Displace = \u001b[0m5.892e-03\u001b[0m/\u001b[0m8.986e-03\u001b[0m (rms/max) Trust = 6.063e-03 (\u001b[91m-\u001b[0m) Grad = \u001b[0m6.101e-04\u001b[0m/\u001b[0m1.123e-03\u001b[0m (rms/max) E (change) = -1167.5784607349 (\u001b[0m-2.206e-04\u001b[0m) Quality = \u001b[0m0.892\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.88298e-01 6.28784e-01 6.99134e-01\n",
            "Step    6 : Displace = \u001b[0m2.330e-03\u001b[0m/\u001b[0m3.801e-03\u001b[0m (rms/max) Trust = 8.574e-03 (\u001b[92m+\u001b[0m) Grad = \u001b[92m2.743e-04\u001b[0m/\u001b[0m5.327e-04\u001b[0m (rms/max) E (change) = -1167.5784696273 (\u001b[92m-8.892e-06\u001b[0m) Quality = \u001b[0m0.606\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.91394e-01 5.95942e-01 7.00662e-01\n",
            "Step    7 : Displace = \u001b[92m9.788e-04\u001b[0m/\u001b[0m2.036e-03\u001b[0m (rms/max) Trust = 8.574e-03 (=) Grad = \u001b[92m8.486e-05\u001b[0m/\u001b[92m1.759e-04\u001b[0m (rms/max) E (change) = -1167.5784715660 (\u001b[92m-1.939e-06\u001b[0m) Quality = \u001b[0m0.831\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 5.12850e-01 5.96164e-01 6.99090e-01\n",
            "Step    8 : Displace = \u001b[92m5.512e-04\u001b[0m/\u001b[92m8.880e-04\u001b[0m (rms/max) Trust = 1.213e-02 (\u001b[92m+\u001b[0m) Grad = \u001b[92m1.605e-04\u001b[0m/\u001b[92m3.538e-04\u001b[0m (rms/max) E (change) = -1167.5784710839 (\u001b[92m+4.822e-07\u001b[0m) Quality = \u001b[91m-0.957\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 5.12850e-01 5.96164e-01 6.99090e-01\n",
            "Converged! =D\n",
            "\n",
            "    #==========================================================================#\n",
            "    #| If this code has benefited your research, please support us by citing: |#\n",
            "    #|                                                                        |#\n",
            "    #| Wang, L.-P.; Song, C.C. (2016) \"Geometry optimization made simple with |#\n",
            "    #| translation and rotation coordinates\", J. Chem, Phys. 144, 214108.     |#\n",
            "    #| http://dx.doi.org/10.1063/1.4952956                                    |#\n",
            "    #==========================================================================#\n",
            "    Time elapsed since start of run_optimizer: 26.539 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU計算時間: 26.59秒\n",
            "converged SCF energy = -1167.55696867553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "geometric-optimize called with the following command line:\n",
            "/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-010f6a21-b892-41de-b6ba-3ab3f0afa510.json\n",
            "\n",
            "                                        \u001b[91m())))))))))))))))/\u001b[0m                     \n",
            "                                    \u001b[91m())))))))))))))))))))))))),\u001b[0m                \n",
            "                                \u001b[91m*)))))))))))))))))))))))))))))))))\u001b[0m             \n",
            "                        \u001b[94m#,\u001b[0m    \u001b[91m()))))))))/\u001b[0m                \u001b[91m.)))))))))),\u001b[0m          \n",
            "                      \u001b[94m#%%%%,\u001b[0m  \u001b[91m())))))\u001b[0m                        \u001b[91m.))))))))*\u001b[0m        \n",
            "                      \u001b[94m*%%%%%%,\u001b[0m  \u001b[91m))\u001b[0m              \u001b[93m..\u001b[0m              \u001b[91m,))))))).\u001b[0m      \n",
            "                        \u001b[94m*%%%%%%,\u001b[0m         \u001b[93m***************/.\u001b[0m        \u001b[91m.)))))))\u001b[0m     \n",
            "                \u001b[94m#%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m    \u001b[93m/*********************.\u001b[0m       \u001b[91m)))))))\u001b[0m    \n",
            "              \u001b[94m.%%%%%%#\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m*******/,\u001b[0m     \u001b[93m**********,\u001b[0m      \u001b[91m.))))))\u001b[0m   \n",
            "                \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m**\u001b[0m              \u001b[93m********\u001b[0m      \u001b[91m.))))))\u001b[0m  \n",
            "          \u001b[94m##\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m                  \u001b[93m,******\u001b[0m      \u001b[91m/)))))\u001b[0m  \n",
            "        \u001b[94m%%%%%%\u001b[0m      \u001b[94m.%%%%%%#\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m    \u001b[92m,/////.\u001b[0m       \u001b[93m******\u001b[0m      \u001b[91m))))))\u001b[0m \n",
            "      \u001b[94m#%\u001b[0m      \u001b[94m%%\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[92m////////,\u001b[0m      \u001b[93m*****/\u001b[0m     \u001b[91m,)))))\u001b[0m \n",
            "    \u001b[94m#%%\u001b[0m  \u001b[94m%%%\u001b[0m  \u001b[94m%%%#\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m  \u001b[92m///////.\u001b[0m     \u001b[93m/*****\u001b[0m      \u001b[91m))))).\u001b[0m\n",
            "  \u001b[94m#%%%%.\u001b[0m      \u001b[94m%%%%%#\u001b[0m      \u001b[94m/%%%%%%*\u001b[0m      \u001b[94m#%%%%%%\u001b[0m   \u001b[92m/////)\u001b[0m     \u001b[93m******\u001b[0m      \u001b[91m))))),\u001b[0m\n",
            "    \u001b[94m#%%%%##%\u001b[0m  \u001b[94m%%%#\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m  \u001b[92m///////.\u001b[0m     \u001b[93m/*****\u001b[0m      \u001b[91m))))).\u001b[0m\n",
            "      \u001b[94m##\u001b[0m     \u001b[94m%%%\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[92m////////.\u001b[0m      \u001b[93m*****/\u001b[0m     \u001b[91m,)))))\u001b[0m \n",
            "        \u001b[94m#%%%%#\u001b[0m      \u001b[94m/%%%%%%/\u001b[0m      \u001b[94m(%%%%%%\u001b[0m      \u001b[92m/)/)//\u001b[0m       \u001b[93m******\u001b[0m      \u001b[91m))))))\u001b[0m \n",
            "          \u001b[94m##\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m                  \u001b[93m*******\u001b[0m      \u001b[91m))))))\u001b[0m  \n",
            "                \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m**.\u001b[0m             \u001b[93m/*******\u001b[0m      \u001b[91m.))))))\u001b[0m  \n",
            "              \u001b[94m*%%%%%%/\u001b[0m      \u001b[94m(%%%%%%\u001b[0m   \u001b[93m********/*..,*/*********\u001b[0m       \u001b[91m*))))))\u001b[0m   \n",
            "                \u001b[94m#%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m    \u001b[93m*********************/\u001b[0m        \u001b[91m)))))))\u001b[0m    \n",
            "                        \u001b[94m*%%%%%%,\u001b[0m         \u001b[93m,**************/\u001b[0m         \u001b[91m,))))))/\u001b[0m     \n",
            "                      \u001b[94m(%%%%%%\u001b[0m   \u001b[91m()\u001b[0m                              \u001b[91m))))))))\u001b[0m       \n",
            "                      \u001b[94m#%%%%,\u001b[0m  \u001b[91m())))))\u001b[0m                        \u001b[91m,)))))))),\u001b[0m        \n",
            "                        \u001b[94m#,\u001b[0m    \u001b[91m())))))))))\u001b[0m                \u001b[91m,)))))))))).\u001b[0m          \n",
            "                                 \u001b[91m()))))))))))))))))))))))))))))))/\u001b[0m             \n",
            "                                    \u001b[91m())))))))))))))))))))))))).\u001b[0m                \n",
            "                                         \u001b[91m())))))))))))))),\u001b[0m                     \n",
            "\n",
            "-=# \u001b[1;94m geomeTRIC started. Version: 1.1 \u001b[0m #=-\n",
            "Current date and time: 2026-01-30 11:03:01\n",
            "#========================================================#\n",
            "#| \u001b[92m    Arguments passed to driver run_optimizer():     \u001b[0m |#\n",
            "#========================================================#\n",
            "convergence_dmax          0.0018 \n",
            "convergence_drms          0.0012 \n",
            "convergence_energy        1e-05 \n",
            "convergence_gmax          0.00045 \n",
            "convergence_grms          0.0003 \n",
            "customengine              <pyscf.geomopt.geometric_solver.PySCFEngine object at 0x789a4d0a8510> \n",
            "input                     /tmp/tmp3nr9nvcj/17242dc9-3b5f-4ba3-930b-dcfc61052d27 \n",
            "logIni                    /usr/local/lib/python3.11/dist-packages/pyscf/geomopt/log.ini \n",
            "maxiter                   100 \n",
            "----------------------------------------------------------\n",
            "Custom engine selected.\n",
            "Bonds will be generated from interatomic distances less than 1.20 times sum of covalent radii\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCF calculation completed successfully.\n",
            "Number of occupied orbitals: 49\n",
            "GAP:  [4.66325129]\n",
            "GAP type:  <class 'numpy.ndarray'>\n",
            "smiles_chosen:  C1=CSCC1\n",
            "使用するXYZデータ:\n",
            " C      0.854196   -0.785156    0.013878\n",
            "C      1.499230    0.338355    0.338947\n",
            "S      0.512286    1.755546    0.269435\n",
            "C     -1.021357    0.788575    0.066704\n",
            "C     -0.587884   -0.617273   -0.350948\n",
            "H      1.338459   -1.752896   -0.014608\n",
            "H      2.547888    0.386356    0.605863\n",
            "H     -1.545716    0.761346    1.027732\n",
            "H     -1.679331    1.249221   -0.675723\n",
            "H     -1.207818   -1.368151    0.150132\n",
            "H     -0.709954   -0.755923   -1.431413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "33 internal coordinates being used (instead of 33 Cartesians)\n",
            "Internal coordinate system (atoms numbered from 1):\n",
            "Distance 1-2\n",
            "Distance 1-5\n",
            "Distance 1-6\n",
            "Distance 2-3\n",
            "Distance 2-7\n",
            "Distance 3-4\n",
            "Distance 4-5\n",
            "Distance 4-8\n",
            "Distance 4-9\n",
            "Distance 5-10\n",
            "Distance 5-11\n",
            "Angle 2-1-6\n",
            "Angle 5-1-6\n",
            "Angle 1-2-7\n",
            "Angle 3-2-7\n",
            "Angle 2-3-4\n",
            "Angle 3-4-5\n",
            "Angle 3-4-8\n",
            "Angle 3-4-9\n",
            "Angle 5-4-8\n",
            "Angle 5-4-9\n",
            "Angle 8-4-9\n",
            "Angle 1-5-4\n",
            "Angle 1-5-10\n",
            "Angle 1-5-11\n",
            "Angle 4-5-10\n",
            "Angle 4-5-11\n",
            "Angle 10-5-11\n",
            "Out-of-Plane 1-2-5-6\n",
            "Out-of-Plane 2-1-3-7\n",
            "Dihedral 5-1-2-3\n",
            "Dihedral 5-1-2-7\n",
            "Dihedral 6-1-2-3\n",
            "Dihedral 6-1-2-7\n",
            "Dihedral 2-1-5-4\n",
            "Dihedral 2-1-5-10\n",
            "Dihedral 2-1-5-11\n",
            "Dihedral 6-1-5-4\n",
            "Dihedral 6-1-5-10\n",
            "Dihedral 6-1-5-11\n",
            "Dihedral 1-2-3-4\n",
            "Dihedral 7-2-3-4\n",
            "Dihedral 2-3-4-5\n",
            "Dihedral 2-3-4-8\n",
            "Dihedral 2-3-4-9\n",
            "Dihedral 3-4-5-1\n",
            "Dihedral 3-4-5-10\n",
            "Dihedral 3-4-5-11\n",
            "Dihedral 8-4-5-1\n",
            "Dihedral 8-4-5-10\n",
            "Dihedral 8-4-5-11\n",
            "Dihedral 9-4-5-1\n",
            "Dihedral 9-4-5-10\n",
            "Dihedral 9-4-5-11\n",
            "Translation-X 1-11\n",
            "Translation-Y 1-11\n",
            "Translation-Z 1-11\n",
            "Rotation-A 1-11\n",
            "Rotation-B 1-11\n",
            "Rotation-C 1-11\n",
            "<class 'geometric.internal.Distance'> : 11\n",
            "<class 'geometric.internal.Angle'> : 17\n",
            "<class 'geometric.internal.OutOfPlane'> : 2\n",
            "<class 'geometric.internal.Dihedral'> : 24\n",
            "<class 'geometric.internal.TranslationX'> : 1\n",
            "<class 'geometric.internal.TranslationY'> : 1\n",
            "<class 'geometric.internal.TranslationZ'> : 1\n",
            "<class 'geometric.internal.RotationA'> : 1\n",
            "<class 'geometric.internal.RotationB'> : 1\n",
            "<class 'geometric.internal.RotationC'> : 1\n",
            "> ===== Optimization Info: ====\n",
            "> Job type: Energy minimization\n",
            "> Maximum number of optimization cycles: 100\n",
            "> Initial / maximum trust radius (Angstrom): 0.100 / 0.300\n",
            "> Convergence Criteria:\n",
            "> Will converge when all 5 criteria are reached:\n",
            ">  |Delta-E| < 1.00e-05\n",
            ">  RMS-Grad  < 3.00e-04\n",
            ">  Max-Grad  < 4.50e-04\n",
            ">  RMS-Disp  < 1.20e-03\n",
            ">  Max-Disp  < 1.80e-03\n",
            "> === End Optimization Info ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARN: Mole.unit (angstrom) is changed to Bohr\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Step    0 : Gradient = 1.985e-02/4.570e-02 (rms/max) Energy = -547.9236144321\n",
            "Hessian Eigenvalues: 2.30525e-02 2.35281e-02 2.46881e-02 ... 3.56153e-01 3.56917e-01 5.62864e-01\n",
            "Step    1 : Displace = \u001b[0m6.141e-02\u001b[0m/\u001b[0m1.059e-01\u001b[0m (rms/max) Trust = 1.000e-01 (=) Grad = \u001b[0m1.386e-02\u001b[0m/\u001b[0m2.898e-02\u001b[0m (rms/max) E (change) = -547.9260534226 (\u001b[0m-2.439e-03\u001b[0m) Quality = \u001b[0m0.294\u001b[0m\n",
            "Hessian Eigenvalues: 2.30353e-02 2.32767e-02 2.47210e-02 ... 3.55596e-01 4.81956e-01 5.80835e-01\n",
            "Step    2 : Displace = \u001b[0m5.103e-02\u001b[0m/\u001b[0m9.337e-02\u001b[0m (rms/max) Trust = 1.000e-01 (=) Grad = \u001b[0m8.651e-03\u001b[0m/\u001b[0m1.744e-02\u001b[0m (rms/max) E (change) = -547.9277351886 (\u001b[0m-1.682e-03\u001b[0m) Quality = \u001b[0m0.357\u001b[0m\n",
            "Hessian Eigenvalues: 2.30399e-02 2.32078e-02 2.47102e-02 ... 3.55937e-01 5.51265e-01 6.02673e-01\n",
            "Step    3 : Displace = \u001b[0m2.818e-02\u001b[0m/\u001b[0m4.395e-02\u001b[0m (rms/max) Trust = 1.000e-01 (=) Grad = \u001b[0m1.526e-03\u001b[0m/\u001b[0m3.587e-03\u001b[0m (rms/max) E (change) = -547.9295094613 (\u001b[0m-1.774e-03\u001b[0m) Quality = \u001b[0m0.925\u001b[0m\n",
            "Hessian Eigenvalues: 2.28368e-02 2.33704e-02 2.47097e-02 ... 3.56524e-01 5.22889e-01 5.90761e-01\n",
            "Step    4 : Displace = \u001b[0m7.522e-03\u001b[0m/\u001b[0m1.416e-02\u001b[0m (rms/max) Trust = 1.414e-01 (\u001b[92m+\u001b[0m) Grad = \u001b[0m4.884e-04\u001b[0m/\u001b[0m9.222e-04\u001b[0m (rms/max) E (change) = -547.9295933620 (\u001b[0m-8.390e-05\u001b[0m) Quality = \u001b[0m1.059\u001b[0m\n",
            "Hessian Eigenvalues: 1.51700e-02 2.32436e-02 2.47268e-02 ... 3.60929e-01 5.81103e-01 6.09553e-01\n",
            "Step    5 : Displace = \u001b[0m7.640e-03\u001b[0m/\u001b[0m1.189e-02\u001b[0m (rms/max) Trust = 2.000e-01 (\u001b[92m+\u001b[0m) Grad = \u001b[0m5.192e-04\u001b[0m/\u001b[0m1.056e-03\u001b[0m (rms/max) E (change) = -547.9296361792 (\u001b[0m-4.282e-05\u001b[0m) Quality = \u001b[0m1.821\u001b[0m\n",
            "Hessian Eigenvalues: 1.78683e-03 2.35266e-02 2.49004e-02 ... 4.18590e-01 5.68670e-01 6.27883e-01\n",
            "Step    6 : Displace = \u001b[0m6.365e-02\u001b[0m/\u001b[0m9.369e-02\u001b[0m (rms/max) Trust = 2.828e-01 (\u001b[92m+\u001b[0m) Grad = \u001b[0m8.650e-04\u001b[0m/\u001b[0m1.210e-03\u001b[0m (rms/max) E (change) = -547.9298656489 (\u001b[0m-2.295e-04\u001b[0m) Quality = \u001b[0m1.309\u001b[0m\n",
            "Hessian Eigenvalues: 1.07917e-03 2.35212e-02 2.49595e-02 ... 4.22298e-01 5.71540e-01 6.36960e-01\n",
            "Step    7 : Displace = \u001b[0m4.380e-02\u001b[0m/\u001b[0m6.381e-02\u001b[0m (rms/max) Trust = 3.000e-01 (\u001b[92m+\u001b[0m) Grad = \u001b[0m5.173e-04\u001b[0m/\u001b[0m7.810e-04\u001b[0m (rms/max) E (change) = -547.9299569622 (\u001b[0m-9.131e-05\u001b[0m) Quality = \u001b[0m1.457\u001b[0m\n",
            "Hessian Eigenvalues: 6.75545e-04 2.35173e-02 2.47487e-02 ... 4.01535e-01 5.71648e-01 6.22185e-01\n",
            "Step    8 : Displace = \u001b[0m3.574e-02\u001b[0m/\u001b[0m5.159e-02\u001b[0m (rms/max) Trust = 3.000e-01 (=) Grad = \u001b[92m1.319e-04\u001b[0m/\u001b[92m2.558e-04\u001b[0m (rms/max) E (change) = -547.9299931660 (\u001b[0m-3.620e-05\u001b[0m) Quality = \u001b[0m1.324\u001b[0m\n",
            "Hessian Eigenvalues: 5.22417e-04 2.35869e-02 2.44372e-02 ... 4.04134e-01 5.71565e-01 6.24376e-01\n",
            "Step    9 : Displace = \u001b[0m1.317e-02\u001b[0m/\u001b[0m1.948e-02\u001b[0m (rms/max) Trust = 3.000e-01 (=) Grad = \u001b[92m5.916e-05\u001b[0m/\u001b[92m1.217e-04\u001b[0m (rms/max) E (change) = -547.9299971195 (\u001b[92m-3.954e-06\u001b[0m) Quality = \u001b[0m1.420\u001b[0m\n",
            "Hessian Eigenvalues: 4.45793e-04 2.30883e-02 2.41441e-02 ... 4.08375e-01 5.71017e-01 6.27414e-01\n",
            "Step   10 : Displace = \u001b[0m2.964e-03\u001b[0m/\u001b[0m4.433e-03\u001b[0m (rms/max) Trust = 3.000e-01 (=) Grad = \u001b[92m2.524e-05\u001b[0m/\u001b[92m4.346e-05\u001b[0m (rms/max) E (change) = -547.9299974321 (\u001b[92m-3.126e-07\u001b[0m) Quality = \u001b[0m1.652\u001b[0m\n",
            "Hessian Eigenvalues: 4.31192e-04 1.96308e-02 2.41821e-02 ... 4.00140e-01 5.73178e-01 6.21975e-01\n",
            "Step   11 : Displace = \u001b[0m1.228e-03\u001b[0m/\u001b[0m1.925e-03\u001b[0m (rms/max) Trust = 3.000e-01 (=) Grad = \u001b[92m1.191e-05\u001b[0m/\u001b[92m1.604e-05\u001b[0m (rms/max) E (change) = -547.9299974806 (\u001b[92m-4.848e-08\u001b[0m) Quality = \u001b[0m0.571\u001b[0m\n",
            "Hessian Eigenvalues: 4.75905e-04 9.13137e-03 2.42122e-02 ... 4.13577e-01 5.76826e-01 6.35263e-01\n",
            "Step   12 : Displace = \u001b[92m1.131e-03\u001b[0m/\u001b[0m1.810e-03\u001b[0m (rms/max) Trust = 3.000e-01 (=) Grad = \u001b[92m4.994e-05\u001b[0m/\u001b[92m9.910e-05\u001b[0m (rms/max) E (change) = -547.9299973853 (\u001b[92m+9.526e-08\u001b[0m) Quality = \u001b[91m-0.615\u001b[0m\n",
            "Hessian Eigenvalues: 4.91482e-04 3.06278e-03 2.42412e-02 ... 4.39395e-01 5.83118e-01 6.63113e-01\n",
            "Step   13 : Displace = \u001b[92m5.899e-04\u001b[0m/\u001b[92m9.867e-04\u001b[0m (rms/max) Trust = 5.656e-04 (\u001b[91m-\u001b[0m) Grad = \u001b[92m1.018e-04\u001b[0m/\u001b[92m1.951e-04\u001b[0m (rms/max) E (change) = -547.9299970351 (\u001b[92m+3.502e-07\u001b[0m) Quality = \u001b[91m-1.070\u001b[0m\n",
            "Hessian Eigenvalues: 4.91482e-04 3.06278e-03 2.42412e-02 ... 4.39395e-01 5.83118e-01 6.63113e-01\n",
            "Converged! =D\n",
            "\n",
            "    #==========================================================================#\n",
            "    #| If this code has benefited your research, please support us by citing: |#\n",
            "    #|                                                                        |#\n",
            "    #| Wang, L.-P.; Song, C.C. (2016) \"Geometry optimization made simple with |#\n",
            "    #| translation and rotation coordinates\", J. Chem, Phys. 144, 214108.     |#\n",
            "    #| http://dx.doi.org/10.1063/1.4952956                                    |#\n",
            "    #==========================================================================#\n",
            "    Time elapsed since start of run_optimizer: 18.545 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU計算時間: 18.68秒\n",
            "converged SCF energy = -547.921864543301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "geometric-optimize called with the following command line:\n",
            "/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-010f6a21-b892-41de-b6ba-3ab3f0afa510.json\n",
            "\n",
            "                                        \u001b[91m())))))))))))))))/\u001b[0m                     \n",
            "                                    \u001b[91m())))))))))))))))))))))))),\u001b[0m                \n",
            "                                \u001b[91m*)))))))))))))))))))))))))))))))))\u001b[0m             \n",
            "                        \u001b[94m#,\u001b[0m    \u001b[91m()))))))))/\u001b[0m                \u001b[91m.)))))))))),\u001b[0m          \n",
            "                      \u001b[94m#%%%%,\u001b[0m  \u001b[91m())))))\u001b[0m                        \u001b[91m.))))))))*\u001b[0m        \n",
            "                      \u001b[94m*%%%%%%,\u001b[0m  \u001b[91m))\u001b[0m              \u001b[93m..\u001b[0m              \u001b[91m,))))))).\u001b[0m      \n",
            "                        \u001b[94m*%%%%%%,\u001b[0m         \u001b[93m***************/.\u001b[0m        \u001b[91m.)))))))\u001b[0m     \n",
            "                \u001b[94m#%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m    \u001b[93m/*********************.\u001b[0m       \u001b[91m)))))))\u001b[0m    \n",
            "              \u001b[94m.%%%%%%#\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m*******/,\u001b[0m     \u001b[93m**********,\u001b[0m      \u001b[91m.))))))\u001b[0m   \n",
            "                \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m**\u001b[0m              \u001b[93m********\u001b[0m      \u001b[91m.))))))\u001b[0m  \n",
            "          \u001b[94m##\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m                  \u001b[93m,******\u001b[0m      \u001b[91m/)))))\u001b[0m  \n",
            "        \u001b[94m%%%%%%\u001b[0m      \u001b[94m.%%%%%%#\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m    \u001b[92m,/////.\u001b[0m       \u001b[93m******\u001b[0m      \u001b[91m))))))\u001b[0m \n",
            "      \u001b[94m#%\u001b[0m      \u001b[94m%%\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[92m////////,\u001b[0m      \u001b[93m*****/\u001b[0m     \u001b[91m,)))))\u001b[0m \n",
            "    \u001b[94m#%%\u001b[0m  \u001b[94m%%%\u001b[0m  \u001b[94m%%%#\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m  \u001b[92m///////.\u001b[0m     \u001b[93m/*****\u001b[0m      \u001b[91m))))).\u001b[0m\n",
            "  \u001b[94m#%%%%.\u001b[0m      \u001b[94m%%%%%#\u001b[0m      \u001b[94m/%%%%%%*\u001b[0m      \u001b[94m#%%%%%%\u001b[0m   \u001b[92m/////)\u001b[0m     \u001b[93m******\u001b[0m      \u001b[91m))))),\u001b[0m\n",
            "    \u001b[94m#%%%%##%\u001b[0m  \u001b[94m%%%#\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m  \u001b[92m///////.\u001b[0m     \u001b[93m/*****\u001b[0m      \u001b[91m))))).\u001b[0m\n",
            "      \u001b[94m##\u001b[0m     \u001b[94m%%%\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[92m////////.\u001b[0m      \u001b[93m*****/\u001b[0m     \u001b[91m,)))))\u001b[0m \n",
            "        \u001b[94m#%%%%#\u001b[0m      \u001b[94m/%%%%%%/\u001b[0m      \u001b[94m(%%%%%%\u001b[0m      \u001b[92m/)/)//\u001b[0m       \u001b[93m******\u001b[0m      \u001b[91m))))))\u001b[0m \n",
            "          \u001b[94m##\u001b[0m      \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m                  \u001b[93m*******\u001b[0m      \u001b[91m))))))\u001b[0m  \n",
            "                \u001b[94m.%%%%%%/\u001b[0m      \u001b[94m*%%%%%%,\u001b[0m  \u001b[93m**.\u001b[0m             \u001b[93m/*******\u001b[0m      \u001b[91m.))))))\u001b[0m  \n",
            "              \u001b[94m*%%%%%%/\u001b[0m      \u001b[94m(%%%%%%\u001b[0m   \u001b[93m********/*..,*/*********\u001b[0m       \u001b[91m*))))))\u001b[0m   \n",
            "                \u001b[94m#%%/\u001b[0m      \u001b[94m(%%%%%%,\u001b[0m    \u001b[93m*********************/\u001b[0m        \u001b[91m)))))))\u001b[0m    \n",
            "                        \u001b[94m*%%%%%%,\u001b[0m         \u001b[93m,**************/\u001b[0m         \u001b[91m,))))))/\u001b[0m     \n",
            "                      \u001b[94m(%%%%%%\u001b[0m   \u001b[91m()\u001b[0m                              \u001b[91m))))))))\u001b[0m       \n",
            "                      \u001b[94m#%%%%,\u001b[0m  \u001b[91m())))))\u001b[0m                        \u001b[91m,)))))))),\u001b[0m        \n",
            "                        \u001b[94m#,\u001b[0m    \u001b[91m())))))))))\u001b[0m                \u001b[91m,)))))))))).\u001b[0m          \n",
            "                                 \u001b[91m()))))))))))))))))))))))))))))))/\u001b[0m             \n",
            "                                    \u001b[91m())))))))))))))))))))))))).\u001b[0m                \n",
            "                                         \u001b[91m())))))))))))))),\u001b[0m                     \n",
            "\n",
            "-=# \u001b[1;94m geomeTRIC started. Version: 1.1 \u001b[0m #=-\n",
            "Current date and time: 2026-01-30 11:03:21\n",
            "#========================================================#\n",
            "#| \u001b[92m    Arguments passed to driver run_optimizer():     \u001b[0m |#\n",
            "#========================================================#\n",
            "convergence_dmax          0.0018 \n",
            "convergence_drms          0.0012 \n",
            "convergence_energy        1e-05 \n",
            "convergence_gmax          0.00045 \n",
            "convergence_grms          0.0003 \n",
            "customengine              <pyscf.geomopt.geometric_solver.PySCFEngine object at 0x789a27b99110> \n",
            "input                     /tmp/tmp2j6vomm3/bbe105c9-8dd1-4b22-92f5-7c7a4aeb2181 \n",
            "logIni                    /usr/local/lib/python3.11/dist-packages/pyscf/geomopt/log.ini \n",
            "maxiter                   100 \n",
            "----------------------------------------------------------\n",
            "Custom engine selected.\n",
            "Bonds will be generated from interatomic distances less than 1.20 times sum of covalent radii\n",
            "54 internal coordinates being used (instead of 54 Cartesians)\n",
            "Internal coordinate system (atoms numbered from 1):\n",
            "Distance 1-2\n",
            "Distance 1-12\n",
            "Distance 1-13\n",
            "Distance 2-3\n",
            "Distance 2-14\n",
            "Distance 3-4\n",
            "Distance 3-11\n",
            "Distance 4-5\n",
            "Distance 4-15\n",
            "Distance 5-6\n",
            "Distance 5-9\n",
            "Distance 6-7\n",
            "Distance 7-8\n",
            "Distance 7-16\n",
            "Distance 8-9\n",
            "Distance 8-17\n",
            "Distance 9-10\n",
            "Distance 10-11\n",
            "Distance 10-18\n",
            "Distance 11-12\n",
            "Angle 2-1-13\n",
            "Angle 12-1-13\n",
            "Angle 1-2-14\n",
            "Angle 3-2-14\n",
            "Angle 2-3-11\n",
            "Angle 4-3-11\n",
            "Angle 3-4-15\n",
            "Angle 5-4-15\n",
            "Angle 4-5-9\n",
            "Angle 6-5-9\n",
            "Angle 5-6-7\n",
            "Angle 6-7-16\n",
            "Angle 8-7-16\n",
            "Angle 7-8-17\n",
            "Angle 9-8-17\n",
            "Angle 5-9-10\n",
            "Angle 8-9-10\n",
            "Angle 9-10-18\n",
            "Angle 11-10-18\n",
            "Angle 3-11-12\n",
            "Angle 10-11-12\n",
            "Angle 1-12-11\n",
            "Out-of-Plane 1-2-12-13\n",
            "Out-of-Plane 2-1-3-14\n",
            "Out-of-Plane 3-2-4-11\n",
            "Out-of-Plane 4-3-5-15\n",
            "Out-of-Plane 5-4-6-9\n",
            "Out-of-Plane 7-6-8-16\n",
            "Out-of-Plane 8-7-9-17\n",
            "Out-of-Plane 9-5-8-10\n",
            "Out-of-Plane 10-9-11-18\n",
            "Out-of-Plane 11-3-10-12\n",
            "Dihedral 12-1-2-3\n",
            "Dihedral 12-1-2-14\n",
            "Dihedral 13-1-2-3\n",
            "Dihedral 13-1-2-14\n",
            "Dihedral 2-1-12-11\n",
            "Dihedral 13-1-12-11\n",
            "Dihedral 1-2-3-4\n",
            "Dihedral 1-2-3-11\n",
            "Dihedral 14-2-3-4\n",
            "Dihedral 14-2-3-11\n",
            "Dihedral 2-3-4-5\n",
            "Dihedral 2-3-4-15\n",
            "Dihedral 11-3-4-5\n",
            "Dihedral 11-3-4-15\n",
            "Dihedral 2-3-11-10\n",
            "Dihedral 2-3-11-12\n",
            "Dihedral 4-3-11-10\n",
            "Dihedral 4-3-11-12\n",
            "Dihedral 3-4-5-6\n",
            "Dihedral 3-4-5-9\n",
            "Dihedral 15-4-5-6\n",
            "Dihedral 15-4-5-9\n",
            "Dihedral 4-5-6-7\n",
            "Dihedral 9-5-6-7\n",
            "Dihedral 4-5-9-8\n",
            "Dihedral 4-5-9-10\n",
            "Dihedral 6-5-9-8\n",
            "Dihedral 6-5-9-10\n",
            "Dihedral 5-6-7-8\n",
            "Dihedral 5-6-7-16\n",
            "Dihedral 6-7-8-9\n",
            "Dihedral 6-7-8-17\n",
            "Dihedral 16-7-8-9\n",
            "Dihedral 16-7-8-17\n",
            "Dihedral 7-8-9-5\n",
            "Dihedral 7-8-9-10\n",
            "Dihedral 17-8-9-5\n",
            "Dihedral 17-8-9-10\n",
            "Dihedral 5-9-10-11\n",
            "Dihedral 5-9-10-18\n",
            "Dihedral 8-9-10-11\n",
            "Dihedral 8-9-10-18\n",
            "Dihedral 9-10-11-3\n",
            "Dihedral 9-10-11-12\n",
            "Dihedral 18-10-11-3\n",
            "Dihedral 18-10-11-12\n",
            "Dihedral 3-11-12-1\n",
            "Dihedral 10-11-12-1\n",
            "Translation-X 1-18\n",
            "Translation-Y 1-18\n",
            "Translation-Z 1-18\n",
            "Rotation-A 1-18\n",
            "Rotation-B 1-18\n",
            "Rotation-C 1-18\n",
            "<class 'geometric.internal.Distance'> : 20\n",
            "<class 'geometric.internal.Angle'> : 22\n",
            "<class 'geometric.internal.OutOfPlane'> : 10\n",
            "<class 'geometric.internal.Dihedral'> : 48\n",
            "<class 'geometric.internal.TranslationX'> : 1\n",
            "<class 'geometric.internal.TranslationY'> : 1\n",
            "<class 'geometric.internal.TranslationZ'> : 1\n",
            "<class 'geometric.internal.RotationA'> : 1\n",
            "<class 'geometric.internal.RotationB'> : 1\n",
            "<class 'geometric.internal.RotationC'> : 1\n",
            "> ===== Optimization Info: ====\n",
            "> Job type: Energy minimization\n",
            "> Maximum number of optimization cycles: 100\n",
            "> Initial / maximum trust radius (Angstrom): 0.100 / 0.300\n",
            "> Convergence Criteria:\n",
            "> Will converge when all 5 criteria are reached:\n",
            ">  |Delta-E| < 1.00e-05\n",
            ">  RMS-Grad  < 3.00e-04\n",
            ">  Max-Grad  < 4.50e-04\n",
            ">  RMS-Disp  < 1.20e-03\n",
            ">  Max-Disp  < 1.80e-03\n",
            "> === End Optimization Info ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCF calculation completed successfully.\n",
            "Number of occupied orbitals: 23\n",
            "GAP:  [6.53465384]\n",
            "GAP type:  <class 'numpy.ndarray'>\n",
            "smiles_chosen:  c1cc2cc3sccc3cc2s1\n",
            "使用するXYZデータ:\n",
            " C      3.405427    0.495863    0.761687\n",
            "C      2.817129   -0.388367   -0.112160\n",
            "C      1.386366   -0.278809   -0.136694\n",
            "C      0.423207   -0.983730   -0.876993\n",
            "C     -0.940116   -0.707450   -0.740616\n",
            "S     -2.251656   -1.464687   -1.560322\n",
            "C     -3.405427   -0.495863   -0.761687\n",
            "C     -2.817129    0.388368    0.112160\n",
            "C     -1.386366    0.278809    0.136694\n",
            "C     -0.423207    0.983731    0.876993\n",
            "C      0.940115    0.707449    0.740617\n",
            "S      2.251655    1.464683    1.560325\n",
            "H      4.459379    0.619399    0.969588\n",
            "H      3.383538   -1.088997   -0.713371\n",
            "H      0.746951   -1.758559   -1.568599\n",
            "H     -4.459379   -0.619397   -0.969591\n",
            "H     -3.383538    1.088995    0.713374\n",
            "H     -0.746950    1.758563    1.568595\n",
            "\n",
            "WARN: Mole.unit (angstrom) is changed to Bohr\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Step    0 : Gradient = 3.107e-02/5.959e-02 (rms/max) Energy = -1167.5609060004\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.60031e-01 4.89360e-01 4.89634e-01\n",
            "Step    1 : Displace = \u001b[0m9.331e-02\u001b[0m/\u001b[0m1.607e-01\u001b[0m (rms/max) Trust = 1.000e-01 (=) Grad = \u001b[0m2.069e-02\u001b[0m/\u001b[0m3.963e-02\u001b[0m (rms/max) E (change) = -1167.5637972072 (\u001b[0m-2.891e-03\u001b[0m) Quality = \u001b[0m0.114\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.86518e-01 4.89383e-01 6.83127e-01\n",
            "Step    2 : Displace = \u001b[0m4.924e-02\u001b[0m/\u001b[0m8.577e-02\u001b[0m (rms/max) Trust = 4.666e-02 (\u001b[91m-\u001b[0m) Grad = \u001b[0m8.633e-03\u001b[0m/\u001b[0m1.641e-02\u001b[0m (rms/max) E (change) = -1167.5761584412 (\u001b[0m-1.236e-02\u001b[0m) Quality = \u001b[0m0.893\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.87467e-01 4.89091e-01 7.58804e-01\n",
            "Step    3 : Displace = \u001b[0m2.734e-02\u001b[0m/\u001b[0m5.225e-02\u001b[0m (rms/max) Trust = 6.598e-02 (\u001b[92m+\u001b[0m) Grad = \u001b[0m2.969e-03\u001b[0m/\u001b[0m5.568e-03\u001b[0m (rms/max) E (change) = -1167.5782046229 (\u001b[0m-2.046e-03\u001b[0m) Quality = \u001b[0m0.791\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.88760e-01 4.92742e-01 6.96537e-01\n",
            "Step    4 : Displace = \u001b[0m1.213e-02\u001b[0m/\u001b[0m2.159e-02\u001b[0m (rms/max) Trust = 9.331e-02 (\u001b[92m+\u001b[0m) Grad = \u001b[0m2.831e-03\u001b[0m/\u001b[0m6.257e-03\u001b[0m (rms/max) E (change) = -1167.5782401752 (\u001b[0m-3.555e-05\u001b[0m) Quality = \u001b[0m0.086\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.87497e-01 5.98937e-01 6.95794e-01\n",
            "Step    5 : Displace = \u001b[0m5.892e-03\u001b[0m/\u001b[0m8.986e-03\u001b[0m (rms/max) Trust = 6.063e-03 (\u001b[91m-\u001b[0m) Grad = \u001b[0m6.101e-04\u001b[0m/\u001b[0m1.123e-03\u001b[0m (rms/max) E (change) = -1167.5784607349 (\u001b[0m-2.206e-04\u001b[0m) Quality = \u001b[0m0.892\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.88298e-01 6.28784e-01 6.99134e-01\n",
            "Step    6 : Displace = \u001b[0m2.330e-03\u001b[0m/\u001b[0m3.801e-03\u001b[0m (rms/max) Trust = 8.574e-03 (\u001b[92m+\u001b[0m) Grad = \u001b[92m2.743e-04\u001b[0m/\u001b[0m5.327e-04\u001b[0m (rms/max) E (change) = -1167.5784696273 (\u001b[92m-8.892e-06\u001b[0m) Quality = \u001b[0m0.606\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 4.91394e-01 5.95942e-01 7.00662e-01\n",
            "Step    7 : Displace = \u001b[92m9.788e-04\u001b[0m/\u001b[0m2.036e-03\u001b[0m (rms/max) Trust = 8.574e-03 (=) Grad = \u001b[92m8.486e-05\u001b[0m/\u001b[92m1.759e-04\u001b[0m (rms/max) E (change) = -1167.5784715660 (\u001b[92m-1.939e-06\u001b[0m) Quality = \u001b[0m0.831\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 5.12850e-01 5.96164e-01 6.99090e-01\n",
            "Step    8 : Displace = \u001b[92m5.512e-04\u001b[0m/\u001b[92m8.880e-04\u001b[0m (rms/max) Trust = 1.213e-02 (\u001b[92m+\u001b[0m) Grad = \u001b[92m1.605e-04\u001b[0m/\u001b[92m3.538e-04\u001b[0m (rms/max) E (change) = -1167.5784710839 (\u001b[92m+4.822e-07\u001b[0m) Quality = \u001b[91m-0.957\u001b[0m\n",
            "Hessian Eigenvalues: 2.30000e-02 2.30000e-02 2.30000e-02 ... 5.12850e-01 5.96164e-01 6.99090e-01\n",
            "Converged! =D\n",
            "\n",
            "    #==========================================================================#\n",
            "    #| If this code has benefited your research, please support us by citing: |#\n",
            "    #|                                                                        |#\n",
            "    #| Wang, L.-P.; Song, C.C. (2016) \"Geometry optimization made simple with |#\n",
            "    #| translation and rotation coordinates\", J. Chem, Phys. 144, 214108.     |#\n",
            "    #| http://dx.doi.org/10.1063/1.4952956                                    |#\n",
            "    #==========================================================================#\n",
            "    Time elapsed since start of run_optimizer: 24.824 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU計算時間: 24.87秒\n",
            "converged SCF energy = -1167.55696867553\n",
            "SCF calculation completed successfully.\n",
            "Number of occupied orbitals: 49\n",
            "GAP:  [4.66325129]\n",
            "GAP type:  <class 'numpy.ndarray'>\n",
            "list_GAP:  [array([6.19228468]), array([22.32075793]), array([22.32075793]), array([4.66325129]), array([22.32075793]), array([4.66325129]), array([6.53465384]), array([4.66325129])]\n",
            "_GAP_tensor:  tensor([[ 6.1923],\n",
            "        [22.3208],\n",
            "        [22.3208],\n",
            "        [ 4.6633],\n",
            "        [22.3208],\n",
            "        [ 4.6633],\n",
            "        [ 6.5347],\n",
            "        [ 4.6633]], dtype=torch.float64)\n",
            "Multiple_tensor.shape:  torch.Size([9, 2])\n",
            "before_filter:  [['CN1C(=O)c2cc3c(c(-c4c5c(c(-c6c7c(c(-c8c9c(c(-c%10c%11c(c(-c%12c%13c(c(-c%14c%15c(c(-c%16c%17c(c(-c%18c%19c(c(-c%20c%21c(c(-c%22c%23c(c(-c%24c%25c(c(-c%26c%27c(c(-c%28c%29c(c(-c%30c%31c(c(-c%32c%33c(c(-c%34c%35c(c(-c%36c%37c(c(-c%38c%39c(c(-c%40c%41c(c(-c%42c%43c(c(-c%44c%45c(c(-c%46c%47c(c(-c%48c%49c(c(-c%50c%51c(c(-c%52c%53c(c(-c%54c%55c(c(-c%56c%57c(c(-c%58c%59c(c(-c%60c%61c(cc%62c%60C(=O)C(C)(C)C%62O)C(=O)N(C)C%61=O)c%60c%58C(=O)C(C)(C)C%60O)C(=O)N(C)C%59=O)c%58c%56C(=O)C(C)(C)C%58O)C(=O)N(C)C%57=O)c%56c%54C(=O)C(C)(C)C%56O)C(=O)N(C)C%55=O)c%54c%52C(=O)C(C)(C)C%54O)C(=O)N(C)C%53=O)c%52c%50C(=O)C(C)(C)C%52O)C(=O)N(C)C%51=O)c%50c%48C(=O)C(C)(C)C%50O)C(=O)N(C)C%49=O)c%48c%46C(=O)C(C)(C)C%48O)C(=O)N(C)C%47=O)c%46c%44C(=O)C(C)(C)C%46O)C(=O)N(C)C%45=O)c%44c%42C(=O)C(C)(C)C%44O)C(=O)N(C)C%43=O)c%42c%40C(=O)C(C)(C)C%42O)C(=O)N(C)C%41=O)c%40c%38C(=O)C(C)(C)C%40O)C(=O)N(C)C%39=O)c%38c%36C(=O)C(C)(C)C%38O)C(=O)N(C)C%37=O)c%36c%34C(=O)C(C)(C)C%36O)C(=O)N(C)C%35=O)c%34c%32C(=O)C(C)(C)C%34O)C(=O)N(C)C%33=O)c%32c%30C(=O)C(C)(C)C%32O)C(=O)N(C)C%31=O)c%30c%28C(=O)C(C)(C)C%30O)C(=O)N(C)C%29=O)c%28c%26C(=O)C(C)(C)C%28O)C(=O)N(C)C%27=O)c%26c%24C(=O)C(C)(C)C%26O)C(=O)N(C)C%25=O)c%24c%22C(=O)C(C)(C)C%24O)C(=O)N(C)C%23=O)c%22c%20C(=O)C(C)(C)C%22O)C(=O)N(C)C%21=O)c%20c%18C(=O)C(C)(C)C%20O)C(=O)N(C)C%19=O)c%18c%16C(=O)C(C)(C)C%18O)C(=O)N(C)C%17=O)c%16c%14C(=O)C(C)(C)C%16O)C(=O)N(C)C%15=O)c%14c%12C(=O)C(C)(C)C%14O)C(=O)N(C)C%13=O)c%12c%10C(=O)C(C)(C)C%12O)C(=O)N(C)C%11=O)c%10c8C(=O)C(C)(C)C%10O)C(=O)N(C)C9=O)c8c6C(=O)C(C)(C)C8O)C(=O)N(C)C7=O)c6c4C(=O)C(C)(C)C6O)C(=O)N(C)C5=O)c2C1=O)C(=O)C(C)(C)C3O'], ['[CH2][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH2]'], ['CC1(C)COc2cn(-n3cc4c(c3)OCC(C)(C)CO4)cc2OC1'], ['c1cc2cc3sc(-c4cc5cc6sccc6c(-c6cc7cc8sccc8c(-c8cc9cc%10sccc%10c(-c%10cc%11cc%12sccc%12c(-c%12cc%13cc%14sccc%14c(-c%14cc%15cc%16sccc%16c(-c%16cc%17cc%18sccc%18c(-c%18cc%19cc%20sccc%20c(-c%20cc%21cc%22sccc%22c(-c%22cc%23cc%24sccc%24c(-c%24cc%25cc%26sccc%26c(-c%26cc%27cc%28sccc%28c(-c%28cc%29cc%30sccc%30c(-c%30cc%31cc%32sccc%32c(-c%32cc%33cc%34sccc%34c(-c%34cc%35cc%36sccc%36c(-c%36cc%37cc%38sccc%38c(-c%38cc%39cc%40sccc%40c(-c%40cc%41cc%42sccc%42c(-c%42cc%43cc%44sccc%44c(-c%44cc%45cc%46sccc%46c(-c%46cc%47cc%48sccc%48c(-c%48cc%49cc%50sccc%50c(-c%50cc%51cc%52sccc%52c(-c%52cc%53cc%54sccc%54c(-c%54cc%55cc%56sccc%56c(-c%56cc%57cc%58sccc%58c(-c%58cc%59cc%60sccc%60c(-c%60cc%61cc%62sccc%62cc%61s%60)c%59s%58)c%57s%56)c%55s%54)c%53s%52)c%51s%50)c%49s%48)c%47s%46)c%45s%44)c%43s%42)c%41s%40)c%39s%38)c%37s%36)c%35s%34)c%33s%32)c%31s%30)c%29s%28)c%27s%26)c%25s%24)c%23s%22)c%21s%20)c%19s%18)c%17s%16)c%15s%14)c%13s%12)c%11s%10)c9s8)c7s6)c5s4)cc3cc2s1'], ['Cn1c2c(c3c1c1c(n3C)=NC=[SH]1)[SH]=CN=2'], ['Fc1c2cc(-c3cc4c(F)c5scc(-c6cc7c(F)c8scc(-c9cc%10c(F)c%11scc(-c%12cc%13c(F)c%14scc(-c%15cc%16c(F)c%17scc(-c%18cc%19c(F)c%20scc(-c%21cc%22c(F)c%23scc(-c%24cc%25c(F)c%26scc(-c%27cc%28c(F)c%29scc(-c%30cc%31c(F)c%32scc(-c%33cc%34c(F)c%35scc(-c%36cc%37c(F)c%38scc(-c%39cc%40c(F)c%41scc(-c%42cc%43c(F)c%44scc(-c%45cc%46c(F)c%47scc(-c%48cc%49c(F)c%50scc(-c%51cc%52c(F)c%53scc(-c%54cc%55c(F)c%56scc(-c%57cc%58c(F)c%59scc(-c%60cc%61c(F)c%62scc(-c%63cc%64c(F)c%65scc(-c%66cc%67c(F)c%68scc(-c%69cc%70c(F)c%71scc(-c%72cc%73c(F)c%74scc(-c%75cc%76c(F)c%77scc(-c%78cc%79c(F)c%80scc(-c%81cc%82c(F)c%83scc(-c%84cc%85c(F)c%86scc(-c%87cc%88c(F)c%89sccc%89c(F)c%88s%87)c%86c(F)c%85s%84)c%83c(F)c%82s%81)c%80c(F)c%79s%78)c%77c(F)c%76s%75)c%74c(F)c%73s%72)c%71c(F)c%70s%69)c%68c(F)c%67s%66)c%65c(F)c%64s%63)c%62c(F)c%61s%60)c%59c(F)c%58s%57)c%56c(F)c%55s%54)c%53c(F)c%52s%51)c%50c(F)c%49s%48)c%47c(F)c%46s%45)c%44c(F)c%43s%42)c%41c(F)c%40s%39)c%38c(F)c%37s%36)c%35c(F)c%34s%33)c%32c(F)c%31s%30)c%29c(F)c%28s%27)c%26c(F)c%25s%24)c%23c(F)c%22s%21)c%20c(F)c%19s%18)c%17c(F)c%16s%15)c%14c(F)c%13s%12)c%11c(F)c%10s9)c8c(F)c7s6)c5c(F)c4s3)sc2c(F)c2ccsc12'], ['C1=CSC(C2=CSC(C3=CSC(C4=CSC(C5=CSC(C6=CSC(C7=CSC(C8=CSC(C9=CSC(C%10=CSC(C%11=CSC(C%12=CSC(C%13=CSC(C%14=CSC(C%15=CSC(C%16=CSC(C%17=CSC(C%18=CSC(C%19=CSC(C%20=CSC(C%21=CSC(C%22=CSC(C%23=CSC(C%24=CSC(C%25=CSC(C%26=CSC(C%27=CSC(C%28=CSC(C%29=CSC(C%30CC=CS%30)C%29)C%28)C%27)C%26)C%25)C%24)C%23)C%22)C%21)C%20)C%19)C%18)C%17)C%16)C%15)C%14)C%13)C%12)C%11)C%10)C9)C8)C7)C6)C5)C4)C3)C2)C1'], ['c1cc2c(-c3cc4c(-c5cc6c(-c7cc8c(-c9cc%10c(-c%11cc%12c(-c%13cc%14c(-c%15cc%16c(-c%17cc%18c(-c%19cc%20c(-c%21cc%22c(-c%23cc%24c(-c%25cc%26c(-c%27cc%28c(-c%29cc%30c(-c%31cc%32c(-c%33cc%34c(-c%35cc%36c(-c%37cc%38c(-c%39cc%40c(-c%41cc%42c(-c%43cc%44c(-c%45cc%46c(-c%47cc%48c(-c%49cc%50c(-c%51cc%52c(-c%53cc%54c(-c%55cc%56c(-c%57cc%58c(-c%59c%60ccsc%60cc%60ccsc%59%60)c%59sccc%59cc%58s%57)c%57sccc%57cc%56s%55)c%55sccc%55cc%54s%53)c%53sccc%53cc%52s%51)c%51sccc%51cc%50s%49)c%49sccc%49cc%48s%47)c%47sccc%47cc%46s%45)c%45sccc%45cc%44s%43)c%43sccc%43cc%42s%41)c%41sccc%41cc%40s%39)c%39sccc%39cc%38s%37)c%37sccc%37cc%36s%35)c%35sccc%35cc%34s%33)c%33sccc%33cc%32s%31)c%31sccc%31cc%30s%29)c%29sccc%29cc%28s%27)c%27sccc%27cc%26s%25)c%25sccc%25cc%24s%23)c%23sccc%23cc%22s%21)c%21sccc%21cc%20s%19)c%19sccc%19cc%18s%17)c%17sccc%17cc%16s%15)c%15sccc%15cc%14s%13)c%13sccc%13cc%12s%11)c%11sccc%11cc%10s9)c9sccc9cc8s7)c7sccc7cc6s5)c5sccc5cc4s3)c3sccc3cc2s1']]\n",
            "Found 30 ring systems\n",
            "Motif: c1c2c(cc3c1CNC3)CCC2  (count=30, atoms=[1, 2, 4, 5, 6, 7, 8, 560, 561, 563, 565, 568])\n",
            "smiles_fragments:  c1c2c(cc3c1CNC3)CCC2\n",
            "Found 0 ring systems\n",
            "Found 2 ring systems\n",
            "Found 30 ring systems\n",
            "Motif: c1cc2cc3sccc3cc2s1  (count=30, atoms=[0, 1, 2, 3, 4, 5, 6, 355, 356, 357, 358, 359])\n",
            "smiles_fragments:  c1cc2cc3sccc3cc2s1\n",
            "Found 1 ring systems\n",
            "Found 30 ring systems\n",
            "Motif: c1cc2cc3sccc3cc2s1  (count=30, atoms=[1, 2, 3, 4, 411, 412, 413, 415, 416, 417, 418, 419])\n",
            "smiles_fragments:  c1cc2cc3sccc3cc2s1\n",
            "Found 30 ring systems\n",
            "Motif: C1=CSCC1  (count=30, atoms=[0, 1, 2, 3, 149])\n",
            "smiles_fragments:  C1=CSCC1\n",
            "Found 30 ring systems\n",
            "Motif: c1cc2cc3sccc3cc2s1  (count=30, atoms=[0, 1, 2, 3, 352, 353, 354, 355, 356, 357, 358, 359])\n",
            "smiles_fragments:  c1cc2cc3sccc3cc2s1\n",
            "success_list:  ['c1c2c(cc3c1CNC3)CCC2', 'C', 'C', 'c1cc2cc3sccc3cc2s1', 'C', 'c1cc2cc3sccc3cc2s1', 'C1=CSCC1', 'c1cc2cc3sccc3cc2s1']\n",
            "End of trial 1\n"
          ]
        }
      ],
      "source": [
        "# import torch\n",
        "from botorch.models import SingleTaskGP, ModelListGP\n",
        "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
        "from botorch.sampling.normal import SobolQMCNormalSampler\n",
        "\n",
        "Multiple_tensor=torch.ones(2).reshape(1, 2).double().to(\"cuda\")\n",
        "\n",
        "print(\"Multiple_tensor.size(): \", Multiple_tensor.size())\n",
        "print(\"Multiple_tensor.device: \", Multiple_tensor.device)\n",
        "\n",
        "\n",
        "if Multiple_tensor.ndim == 1:\n",
        "    Multiple_tensor = Multiple_tensor.unsqueeze(-1)\n",
        "\n",
        "z_tensor =torch.zeros(256).reshape(1,  256).double().to(\"cuda\")\n",
        "print(\"Multiple_tensor.shape:\", Multiple_tensor.shape)  # e.g., [160, M]\n",
        "print(\"z_tensor.shape:\", z_tensor.shape)  # [160, 64]\n",
        "print(\"z_tensor.device:\", z_tensor.device)\n",
        "\n",
        "# ---- GPモデリング ----\n",
        "M = Multiple_tensor.shape[1]\n",
        "print(\"M: \", M)\n",
        "gp_models = []\n",
        "for i in range(M):\n",
        "    y_i = standardize(Multiple_tensor[:, i]).unsqueeze(-1)  # [N, 1]\n",
        "    gp_models.append(SingleTaskGP(z_tensor, y_i))\n",
        "\n",
        "gp = ModelListGP(*gp_models).cuda()\n",
        "mll = SumMarginalLogLikelihood(gp.likelihood, gp)\n",
        "\n",
        "try:\n",
        "    fit_gpytorch_mll(mll)\n",
        "except Exception as e:\n",
        "    print(\"error on fit_gpytorch_mll(mll):\", e)\n",
        "\n",
        "# ---- 取得関数定義 ----\n",
        "ref_point = Multiple_tensor.min(dim=0)[0] - 0.1  # 各目的ごとにref_point設定\n",
        "print(\"ref_point.device: \", ref_point.device)\n",
        "partitioning = NondominatedPartitioning(Y=Multiple_tensor, ref_point=ref_point)\n",
        "\n",
        "bounds = torch.stack([-10*torch.ones(1).reshape(1, 1), 10*torch.ones(1).reshape(1, 1)]).double().to(\"cuda\")\n",
        "print(\"bounds.device: \", bounds.device)\n",
        "\n",
        "# acq_func = qLogExpectedHypervolumeImprovement(\n",
        "acq_func = qLogNoisyExpectedHypervolumeImprovement(\n",
        "    model=gp,\n",
        "    ref_point=ref_point.tolist(),\n",
        "    X_baseline = z_tensor.double(),\n",
        "    sampler = SobolQMCNormalSampler(sample_shape=torch.Size([128])),\n",
        "    prune_baseline=True,  # prune baseline points that have estimated zero probability of being Pareto optimal,\n",
        "    constraints=[distance_constraint],\n",
        "\n",
        ")\n",
        "variable_q = 8\n",
        "\n",
        "n_trial=1\n",
        "\n",
        "list_smiles=[]\n",
        "list_smiles_success=[]\n",
        "# ---- 最適化ループ ----\n",
        "for each_trial in range(n_trial):\n",
        "    print(f\"Loop {each_trial + 1} starts\")\n",
        "    try:\n",
        "        candidate, acq_value = optimize_acqf(\n",
        "            acq_function=acq_func,\n",
        "            bounds=torch.stack([torch.zeros(z_tensor.shape[1]), torch.ones(z_tensor.shape[1])]).double().to(\"cuda\"),\n",
        "            q=variable_q ,\n",
        "            num_restarts=5,\n",
        "            raw_samples=10,\n",
        "        )\n",
        "\n",
        "        unnormalized_candidate = unnormalize(candidate, bounds)\n",
        "\n",
        "\n",
        "        Multiple_val, each_smiles_list = obj_func(unnormalized_candidate, model, variable_q)\n",
        "\n",
        "\n",
        "        if Multiple_val.ndim == 1:\n",
        "            Multiple_val = Multiple_val.unsqueeze(-1)\n",
        "\n",
        "        z_tensor = torch.cat([z_tensor, unnormalized_candidate.squeeze(0)]).to(\"cuda\")\n",
        "        Multiple_tensor = torch.cat([Multiple_tensor, Multiple_val.reshape(variable_q, 2)], dim=0).to(\"cuda\")\n",
        "        print(\"Multiple_tensor.shape: \", Multiple_tensor.shape)\n",
        "        list_smiles.extend(each_smiles_list)\n",
        "\n",
        "        each_smiles_list_filtered_success, each_smiles_list_filtered_fail, each_smiles_list_filtered_fail_idx = filter_valid_with_timeout(each_smiles_list)\n",
        "        list_smiles_success.extend(each_smiles_list_filtered_success)\n",
        "\n",
        "        # 無限値チェック\n",
        "        if not torch.isfinite(Multiple_tensor).all():\n",
        "            print(\"NaN or Inf detected, skipping this trial\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        # ---- モデル再学習 ----\n",
        "        gp_models = []\n",
        "        for i in range(M):\n",
        "            y_i = standardize(Multiple_tensor[:, i]).unsqueeze(-1)\n",
        "            gp_models.append(SingleTaskGP(z_tensor, y_i))\n",
        "\n",
        "        gp = ModelListGP(*gp_models)\n",
        "        mll = SumMarginalLogLikelihood(gp.likelihood, gp)\n",
        "\n",
        "        try:\n",
        "            fit_gpytorch_mll(mll)\n",
        "        except Exception as e:\n",
        "            print(\"error on fit_gpytorch_mll(mll):\", e)\n",
        "\n",
        "        # ---- 取得関数更新 ----\n",
        "        bounds = torch.stack([z_tensor.min(dim=0)[0], z_tensor.max(dim=0)[0]])\n",
        "        ref_point = Multiple_tensor.min(dim=0)[0] - 0.1\n",
        "        partitioning = NondominatedPartitioning(Y=Multiple_tensor, ref_point=ref_point)\n",
        "        acq_func = qLogNoisyExpectedHypervolumeImprovement(\n",
        "            model=gp,\n",
        "            ref_point=ref_point.tolist(),\n",
        "            X_baseline = z_tensor,\n",
        "            sampler = SobolQMCNormalSampler(sample_shape=torch.Size([128])),\n",
        "            prune_baseline=True,  # prune baseline points that have estimated zero probability of being Pareto optimal\n",
        "            # partitioning=partitioning,\n",
        "        )\n",
        "        del Multiple_val, unnormalized_candidate, candidate, ref_point\n",
        "\n",
        "        torch.cuda.memory_cached()\n",
        "    except Exception as e:\n",
        "        print(\"NG\")\n",
        "        print(e)\n",
        "        continue\n",
        "    print(f\"End of trial {each_trial + 1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1aEEthQo-UU"
      },
      "outputs": [],
      "source": [
        "# aa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0b199Y3ZNKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c907682a-6284-40ba-cb79-d5760c2f7a1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.str_"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "type(np.array(uni_fragments)[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF9vu-1vo-UU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "88e0ddba-a8c3-4649-9553-b26109cef7e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/try_it_to_valify/try_it_to_valify_logs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jweWcYKcXO9p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "24d017b8-bbe8-483b-ccae-34659e931635"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         nD        GAP                                             smiles  \\\n",
              "0  1.648424   6.192285  CN1C(=O)c2cc3c(c(-c4c5c(c(-c6c7c(c(-c8c9c(c(-c...   \n",
              "1  1.573836  22.320758  [CH2][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][...   \n",
              "2  1.575779  22.320758        CC1(C)COc2cn(-n3cc4c(c3)OCC(C)(C)CO4)cc2OC1   \n",
              "3  1.822868   4.663251  c1cc2cc3sc(-c4cc5cc6sccc6c(-c6cc7cc8sccc8c(-c8...   \n",
              "4  1.575454  22.320758             Cn1c2c(c3c1c1c(n3C)=NC=[SH]1)[SH]=CN=2   \n",
              "5  1.813151   4.663251  Fc1c2cc(-c3cc4c(F)c5scc(-c6cc7c(F)c8scc(-c9cc%...   \n",
              "6  1.686064   6.534654  C1=CSC(C2=CSC(C3=CSC(C4=CSC(C5=CSC(C6=CSC(C7=C...   \n",
              "7  1.822208   4.663251  c1cc2c(-c3cc4c(-c5cc6c(-c7cc8c(-c9cc%10c(-c%11...   \n",
              "\n",
              "         smiles_success  \n",
              "0  c1c2c(cc3c1CNC3)CCC2  \n",
              "1                     C  \n",
              "2                     C  \n",
              "3    c1cc2cc3sccc3cc2s1  \n",
              "4                     C  \n",
              "5    c1cc2cc3sccc3cc2s1  \n",
              "6              C1=CSCC1  \n",
              "7    c1cc2cc3sccc3cc2s1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0e64c0b-7211-4b35-bb38-6868c1a3b200\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nD</th>\n",
              "      <th>GAP</th>\n",
              "      <th>smiles</th>\n",
              "      <th>smiles_success</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.648424</td>\n",
              "      <td>6.192285</td>\n",
              "      <td>CN1C(=O)c2cc3c(c(-c4c5c(c(-c6c7c(c(-c8c9c(c(-c...</td>\n",
              "      <td>c1c2c(cc3c1CNC3)CCC2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.573836</td>\n",
              "      <td>22.320758</td>\n",
              "      <td>[CH2][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][...</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.575779</td>\n",
              "      <td>22.320758</td>\n",
              "      <td>CC1(C)COc2cn(-n3cc4c(c3)OCC(C)(C)CO4)cc2OC1</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.822868</td>\n",
              "      <td>4.663251</td>\n",
              "      <td>c1cc2cc3sc(-c4cc5cc6sccc6c(-c6cc7cc8sccc8c(-c8...</td>\n",
              "      <td>c1cc2cc3sccc3cc2s1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.575454</td>\n",
              "      <td>22.320758</td>\n",
              "      <td>Cn1c2c(c3c1c1c(n3C)=NC=[SH]1)[SH]=CN=2</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.813151</td>\n",
              "      <td>4.663251</td>\n",
              "      <td>Fc1c2cc(-c3cc4c(F)c5scc(-c6cc7c(F)c8scc(-c9cc%...</td>\n",
              "      <td>c1cc2cc3sccc3cc2s1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.686064</td>\n",
              "      <td>6.534654</td>\n",
              "      <td>C1=CSC(C2=CSC(C3=CSC(C4=CSC(C5=CSC(C6=CSC(C7=C...</td>\n",
              "      <td>C1=CSCC1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.822208</td>\n",
              "      <td>4.663251</td>\n",
              "      <td>c1cc2c(-c3cc4c(-c5cc6c(-c7cc8c(-c9cc%10c(-c%11...</td>\n",
              "      <td>c1cc2cc3sccc3cc2s1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0e64c0b-7211-4b35-bb38-6868c1a3b200')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d0e64c0b-7211-4b35-bb38-6868c1a3b200 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d0e64c0b-7211-4b35-bb38-6868c1a3b200');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e098e0cb-b706-49ae-952b-f812f31e2a8d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e098e0cb-b706-49ae-952b-f812f31e2a8d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e098e0cb-b706-49ae-952b-f812f31e2a8d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0686d149-8538-472e-8593-337f830ef56d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_collecter')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0686d149-8538-472e-8593-337f830ef56d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result_collecter');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result_collecter",
              "summary": "{\n  \"name\": \"result_collecter\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"nD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11445765477760679,\n        \"min\": 1.5738357960819715,\n        \"max\": 1.8228680695501114,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.5738357960819715,\n          1.813151447863582,\n          1.6484243536507146\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GAP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.815278489939871,\n        \"min\": 4.663251289958564,\n        \"max\": 22.320757933581575,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          6.192284680376565,\n          22.320757933581575,\n          6.534653842595363\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smiles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"[CH2][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH][CH2]\",\n          \"Fc1c2cc(-c3cc4c(F)c5scc(-c6cc7c(F)c8scc(-c9cc%10c(F)c%11scc(-c%12cc%13c(F)c%14scc(-c%15cc%16c(F)c%17scc(-c%18cc%19c(F)c%20scc(-c%21cc%22c(F)c%23scc(-c%24cc%25c(F)c%26scc(-c%27cc%28c(F)c%29scc(-c%30cc%31c(F)c%32scc(-c%33cc%34c(F)c%35scc(-c%36cc%37c(F)c%38scc(-c%39cc%40c(F)c%41scc(-c%42cc%43c(F)c%44scc(-c%45cc%46c(F)c%47scc(-c%48cc%49c(F)c%50scc(-c%51cc%52c(F)c%53scc(-c%54cc%55c(F)c%56scc(-c%57cc%58c(F)c%59scc(-c%60cc%61c(F)c%62scc(-c%63cc%64c(F)c%65scc(-c%66cc%67c(F)c%68scc(-c%69cc%70c(F)c%71scc(-c%72cc%73c(F)c%74scc(-c%75cc%76c(F)c%77scc(-c%78cc%79c(F)c%80scc(-c%81cc%82c(F)c%83scc(-c%84cc%85c(F)c%86scc(-c%87cc%88c(F)c%89sccc%89c(F)c%88s%87)c%86c(F)c%85s%84)c%83c(F)c%82s%81)c%80c(F)c%79s%78)c%77c(F)c%76s%75)c%74c(F)c%73s%72)c%71c(F)c%70s%69)c%68c(F)c%67s%66)c%65c(F)c%64s%63)c%62c(F)c%61s%60)c%59c(F)c%58s%57)c%56c(F)c%55s%54)c%53c(F)c%52s%51)c%50c(F)c%49s%48)c%47c(F)c%46s%45)c%44c(F)c%43s%42)c%41c(F)c%40s%39)c%38c(F)c%37s%36)c%35c(F)c%34s%33)c%32c(F)c%31s%30)c%29c(F)c%28s%27)c%26c(F)c%25s%24)c%23c(F)c%22s%21)c%20c(F)c%19s%18)c%17c(F)c%16s%15)c%14c(F)c%13s%12)c%11c(F)c%10s9)c8c(F)c7s6)c5c(F)c4s3)sc2c(F)c2ccsc12\",\n          \"CN1C(=O)c2cc3c(c(-c4c5c(c(-c6c7c(c(-c8c9c(c(-c%10c%11c(c(-c%12c%13c(c(-c%14c%15c(c(-c%16c%17c(c(-c%18c%19c(c(-c%20c%21c(c(-c%22c%23c(c(-c%24c%25c(c(-c%26c%27c(c(-c%28c%29c(c(-c%30c%31c(c(-c%32c%33c(c(-c%34c%35c(c(-c%36c%37c(c(-c%38c%39c(c(-c%40c%41c(c(-c%42c%43c(c(-c%44c%45c(c(-c%46c%47c(c(-c%48c%49c(c(-c%50c%51c(c(-c%52c%53c(c(-c%54c%55c(c(-c%56c%57c(c(-c%58c%59c(c(-c%60c%61c(cc%62c%60C(=O)C(C)(C)C%62O)C(=O)N(C)C%61=O)c%60c%58C(=O)C(C)(C)C%60O)C(=O)N(C)C%59=O)c%58c%56C(=O)C(C)(C)C%58O)C(=O)N(C)C%57=O)c%56c%54C(=O)C(C)(C)C%56O)C(=O)N(C)C%55=O)c%54c%52C(=O)C(C)(C)C%54O)C(=O)N(C)C%53=O)c%52c%50C(=O)C(C)(C)C%52O)C(=O)N(C)C%51=O)c%50c%48C(=O)C(C)(C)C%50O)C(=O)N(C)C%49=O)c%48c%46C(=O)C(C)(C)C%48O)C(=O)N(C)C%47=O)c%46c%44C(=O)C(C)(C)C%46O)C(=O)N(C)C%45=O)c%44c%42C(=O)C(C)(C)C%44O)C(=O)N(C)C%43=O)c%42c%40C(=O)C(C)(C)C%42O)C(=O)N(C)C%41=O)c%40c%38C(=O)C(C)(C)C%40O)C(=O)N(C)C%39=O)c%38c%36C(=O)C(C)(C)C%38O)C(=O)N(C)C%37=O)c%36c%34C(=O)C(C)(C)C%36O)C(=O)N(C)C%35=O)c%34c%32C(=O)C(C)(C)C%34O)C(=O)N(C)C%33=O)c%32c%30C(=O)C(C)(C)C%32O)C(=O)N(C)C%31=O)c%30c%28C(=O)C(C)(C)C%30O)C(=O)N(C)C%29=O)c%28c%26C(=O)C(C)(C)C%28O)C(=O)N(C)C%27=O)c%26c%24C(=O)C(C)(C)C%26O)C(=O)N(C)C%25=O)c%24c%22C(=O)C(C)(C)C%24O)C(=O)N(C)C%23=O)c%22c%20C(=O)C(C)(C)C%22O)C(=O)N(C)C%21=O)c%20c%18C(=O)C(C)(C)C%20O)C(=O)N(C)C%19=O)c%18c%16C(=O)C(C)(C)C%18O)C(=O)N(C)C%17=O)c%16c%14C(=O)C(C)(C)C%16O)C(=O)N(C)C%15=O)c%14c%12C(=O)C(C)(C)C%14O)C(=O)N(C)C%13=O)c%12c%10C(=O)C(C)(C)C%12O)C(=O)N(C)C%11=O)c%10c8C(=O)C(C)(C)C%10O)C(=O)N(C)C9=O)c8c6C(=O)C(C)(C)C8O)C(=O)N(C)C7=O)c6c4C(=O)C(C)(C)C6O)C(=O)N(C)C5=O)c2C1=O)C(=O)C(C)(C)C3O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smiles_success\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"C\",\n          \"C1=CSCC1\",\n          \"c1c2c(cc3c1CNC3)CCC2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "\n",
        "target_tensor = Multiple_tensor.clone()\n",
        "target_array = target_tensor.to(\"cpu\").numpy()\n",
        "\n",
        "import pandas as pd\n",
        "result_collecter = pd.DataFrame([])\n",
        "result_collecter[\"nD\"] = pd.DataFrame(target_array[1:, 0])\n",
        "result_collecter[\"GAP\"] = pd.DataFrame(target_array[1:, 1])\n",
        "result_collecter[\"smiles\"] = pd.DataFrame(list_smiles)\n",
        "result_collecter[\"smiles_success\"] = pd.DataFrame(list_smiles_success)\n",
        "result_collecter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFH4bHDSYELK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qjsn_RlQXVU4"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "result_collecter.to_csv(f\"result_collecter_{datetime.date.today()}_{experiment_number}_FRATTVAE.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scNYDi6ouxe8"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}